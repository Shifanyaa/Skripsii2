2025-06-01 18:41:48,430 - INFO - Training DBN...
2025-06-01 18:41:50,664 - INFO - Starting DBN pre-training...
2025-06-01 18:41:50,680 - INFO - Pre-training RBM layer 1/3
2025-06-01 18:41:53,332 - INFO -  RBM1 Epoch 0: Loss=1.6235
2025-06-01 18:42:00,427 - INFO -  RBM1 Epoch 10: Loss=1.6028
2025-06-01 18:42:07,341 - INFO -  RBM1 Epoch 20: Loss=1.5906
2025-06-01 18:42:16,704 - INFO -  RBM1 Epoch 30: Loss=1.5491
2025-06-01 18:42:28,695 - INFO -  RBM1 Epoch 40: Loss=1.5294
2025-06-01 18:42:39,469 - INFO - Pre-training RBM layer 2/3
2025-06-01 18:42:42,081 - INFO -  RBM2 Epoch 0: Loss=0.2765
2025-06-01 18:42:48,278 - INFO -  RBM2 Epoch 10: Loss=0.2763
2025-06-01 18:42:53,677 - INFO -  RBM2 Epoch 20: Loss=0.2762
2025-06-01 18:43:00,858 - INFO -  RBM2 Epoch 30: Loss=0.2763
2025-06-01 18:43:06,917 - INFO -  RBM2 Epoch 40: Loss=0.2762
2025-06-01 18:43:10,300 - INFO - Pre-training RBM layer 3/3
2025-06-01 18:43:10,455 - INFO -  RBM3 Epoch 0: Loss=0.2733
2025-06-01 18:43:12,348 - INFO -  RBM3 Epoch 10: Loss=0.2732
2025-06-01 18:43:14,198 - INFO -  RBM3 Epoch 20: Loss=0.2731
2025-06-01 18:43:16,214 - INFO -  RBM3 Epoch 30: Loss=0.2731
2025-06-01 18:43:18,129 - INFO -  RBM3 Epoch 40: Loss=0.2731
2025-06-01 18:43:20,265 - INFO - Starting DBN fine-tuning...
2025-06-01 18:43:48,445 - INFO - Epoch 0: Train(l=0.7050,a=0.5067) | Val(l=0.6237,a=0.9272)
2025-06-01 18:43:48,633 - INFO - Epoch 1: Train(l=0.6558,a=0.6176) | Val(l=0.6235,a=0.9272)
2025-06-01 18:43:48,850 - INFO - Epoch 2: Train(l=0.6183,a=0.6749) | Val(l=0.6244,a=0.9272)
2025-06-01 18:43:49,146 - INFO - Epoch 3: Train(l=0.5888,a=0.7007) | Val(l=0.6265,a=0.9272)
2025-06-01 18:43:49,463 - INFO - Epoch 4: Train(l=0.5601,a=0.7472) | Val(l=0.6284,a=0.9272)
2025-06-01 18:43:50,332 - INFO - Epoch 5: Train(l=0.5337,a=0.7812) | Val(l=0.6299,a=0.9272)
2025-06-01 18:43:50,911 - INFO - Epoch 6: Train(l=0.5174,a=0.7993) | Val(l=0.6290,a=0.9272)
2025-06-01 18:43:51,663 - INFO - Epoch 7: Train(l=0.5052,a=0.8096) | Val(l=0.6175,a=0.9272)
2025-06-01 18:43:52,481 - INFO - Epoch 8: Train(l=0.4978,a=0.8142) | Val(l=0.5730,a=0.9272)
2025-06-01 18:43:53,171 - INFO - Epoch 9: Train(l=0.4869,a=0.8261) | Val(l=0.4698,a=0.9272)
2025-06-01 18:43:53,827 - INFO - Epoch 10: Train(l=0.4751,a=0.8375) | Val(l=0.3488,a=0.9272)
2025-06-01 18:43:54,546 - INFO - Epoch 11: Train(l=0.4585,a=0.8540) | Val(l=0.2619,a=0.9272)
2025-06-01 18:43:55,113 - INFO - Epoch 12: Train(l=0.4477,a=0.8736) | Val(l=0.2413,a=0.9272)
2025-06-01 18:43:55,622 - INFO - Epoch 13: Train(l=0.4486,a=0.8638) | Val(l=0.2621,a=0.9272)
2025-06-01 18:43:56,097 - INFO - Epoch 14: Train(l=0.4346,a=0.8741) | Val(l=0.2916,a=0.9272)
2025-06-01 18:43:56,531 - INFO - Epoch 15: Train(l=0.4243,a=0.8911) | Val(l=0.3041,a=0.9272)
2025-06-01 18:43:57,031 - INFO - Epoch 16: Train(l=0.4126,a=0.9082) | Val(l=0.3116,a=0.9272)
2025-06-01 18:43:57,549 - INFO - Epoch 17: Train(l=0.4037,a=0.9035) | Val(l=0.2436,a=0.9272)
2025-06-01 18:43:58,250 - INFO - Epoch 18: Train(l=0.4078,a=0.9040) | Val(l=0.2228,a=0.9272)
2025-06-01 18:44:00,728 - INFO - Epoch 19: Train(l=0.4021,a=0.9040) | Val(l=0.2176,a=0.9272)
2025-06-01 18:44:01,613 - INFO - Epoch 20: Train(l=0.3983,a=0.9123) | Val(l=0.2155,a=0.9272)
2025-06-01 18:44:02,369 - INFO - Epoch 21: Train(l=0.3899,a=0.9288) | Val(l=0.2144,a=0.9272)
2025-06-01 18:44:03,071 - INFO - Epoch 22: Train(l=0.3859,a=0.9257) | Val(l=0.2150,a=0.9272)
2025-06-01 18:44:03,699 - INFO - Epoch 23: Train(l=0.3820,a=0.9288) | Val(l=0.2141,a=0.9272)
2025-06-01 18:44:04,301 - INFO - Epoch 24: Train(l=0.3875,a=0.9159) | Val(l=0.2126,a=0.9272)
2025-06-01 18:44:04,849 - INFO - Epoch 25: Train(l=0.3790,a=0.9221) | Val(l=0.2140,a=0.9272)
2025-06-01 18:44:05,578 - INFO - Epoch 26: Train(l=0.3704,a=0.9267) | Val(l=0.2139,a=0.9272)
2025-06-01 18:44:06,144 - INFO - Epoch 27: Train(l=0.3701,a=0.9360) | Val(l=0.2136,a=0.9272)
2025-06-01 18:44:06,621 - INFO - Epoch 28: Train(l=0.3652,a=0.9324) | Val(l=0.2118,a=0.9272)
2025-06-01 18:44:07,027 - INFO - Epoch 29: Train(l=0.3601,a=0.9381) | Val(l=0.2128,a=0.9272)
2025-06-01 18:44:07,450 - INFO - Epoch 30: Train(l=0.3613,a=0.9345) | Val(l=0.2110,a=0.9272)
2025-06-01 18:44:07,928 - INFO - Epoch 31: Train(l=0.3595,a=0.9407) | Val(l=0.2103,a=0.9272)
2025-06-01 18:44:08,434 - INFO - Epoch 32: Train(l=0.3542,a=0.9438) | Val(l=0.2130,a=0.9272)
2025-06-01 18:44:08,896 - INFO - Epoch 33: Train(l=0.3484,a=0.9453) | Val(l=0.2130,a=0.9272)
2025-06-01 18:44:09,375 - INFO - Epoch 34: Train(l=0.3488,a=0.9422) | Val(l=0.2103,a=0.9272)
2025-06-01 18:44:09,798 - INFO - Epoch 35: Train(l=0.3472,a=0.9551) | Val(l=0.2093,a=0.9272)
2025-06-01 18:44:10,224 - INFO - Epoch 36: Train(l=0.3392,a=0.9561) | Val(l=0.2100,a=0.9272)
2025-06-01 18:44:10,647 - INFO - Epoch 37: Train(l=0.3400,a=0.9489) | Val(l=0.2106,a=0.9272)
2025-06-01 18:44:11,065 - INFO - Epoch 38: Train(l=0.3382,a=0.9525) | Val(l=0.2078,a=0.9272)
2025-06-01 18:44:11,474 - INFO - Epoch 39: Train(l=0.3294,a=0.9613) | Val(l=0.2070,a=0.9272)
2025-06-01 18:44:11,934 - INFO - Epoch 40: Train(l=0.3282,a=0.9598) | Val(l=0.2066,a=0.9272)
2025-06-01 18:44:12,373 - INFO - Epoch 41: Train(l=0.3221,a=0.9546) | Val(l=0.2117,a=0.9272)
2025-06-01 18:44:12,862 - INFO - Epoch 42: Train(l=0.3193,a=0.9603) | Val(l=0.2130,a=0.9272)
2025-06-01 18:44:13,328 - INFO - Epoch 43: Train(l=0.3197,a=0.9520) | Val(l=0.2176,a=0.9272)
2025-06-01 18:44:13,735 - INFO - Epoch 44: Train(l=0.3194,a=0.9577) | Val(l=0.2134,a=0.9272)
2025-06-01 18:44:14,157 - INFO - Epoch 45: Train(l=0.3152,a=0.9639) | Val(l=0.2397,a=0.9390)
2025-06-01 18:44:14,581 - INFO - Epoch 46: Train(l=0.3177,a=0.9592) | Val(l=0.2659,a=0.9343)
2025-06-01 18:44:15,020 - INFO - Epoch 47: Train(l=0.3155,a=0.9618) | Val(l=0.2862,a=0.9225)
2025-06-01 18:44:15,446 - INFO - Epoch 48: Train(l=0.3137,a=0.9659) | Val(l=0.2907,a=0.9178)
2025-06-01 18:44:15,932 - INFO - Epoch 49: Train(l=0.3073,a=0.9711) | Val(l=0.3177,a=0.8732)
2025-06-01 18:45:17,520 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-01 18:45:17,823 - INFO - Total training time: 209.40s
2025-06-01 18:45:17,823 - INFO - Validation MCC: 0.3924, AUC: 0.8683
2025-06-01 18:45:17,823 - INFO - Test       MCC: 0.3822, AUC: 0.8949
2025-06-01 18:54:13,248 - INFO - Training DBN...
2025-06-01 18:54:14,453 - INFO - Starting DBN pre-training...
2025-06-01 18:54:14,455 - INFO - Pre-training RBM layer 1/3
2025-06-01 18:54:16,447 - INFO -  RBM1 Epoch 0: Loss=1.6183
2025-06-01 18:54:22,825 - INFO -  RBM1 Epoch 10: Loss=1.5962
2025-06-01 18:54:29,345 - INFO -  RBM1 Epoch 20: Loss=1.5723
2025-06-01 18:54:33,906 - INFO -  RBM1 Epoch 30: Loss=1.5687
2025-06-01 18:54:37,619 - INFO -  RBM1 Epoch 40: Loss=1.5251
2025-06-01 18:54:41,995 - INFO - Pre-training RBM layer 2/3
2025-06-01 18:54:42,370 - INFO -  RBM2 Epoch 0: Loss=0.2764
2025-06-01 18:54:45,596 - INFO -  RBM2 Epoch 10: Loss=0.2763
2025-06-01 18:54:47,889 - INFO -  RBM2 Epoch 20: Loss=0.2764
2025-06-01 18:54:50,215 - INFO -  RBM2 Epoch 30: Loss=0.2762
2025-06-01 18:54:53,817 - INFO -  RBM2 Epoch 40: Loss=0.2763
2025-06-01 18:54:58,316 - INFO - Pre-training RBM layer 3/3
2025-06-01 18:55:00,798 - INFO -  RBM3 Epoch 0: Loss=0.2734
2025-06-01 18:55:04,618 - INFO -  RBM3 Epoch 10: Loss=0.2733
2025-06-01 18:55:14,891 - INFO -  RBM3 Epoch 20: Loss=0.2733
2025-06-01 18:55:20,367 - INFO -  RBM3 Epoch 30: Loss=0.2733
2025-06-01 18:55:24,932 - INFO -  RBM3 Epoch 40: Loss=0.2733
2025-06-01 18:55:28,859 - INFO - Starting DBN fine-tuning...
2025-06-01 18:55:58,531 - INFO - Epoch 0: Train(l=0.7386,a=0.5098) | Val(l=0.6596,a=0.9272)
2025-06-01 18:55:58,783 - INFO - Epoch 1: Train(l=0.6895,a=0.5862) | Val(l=0.6590,a=0.9272)
2025-06-01 18:55:59,109 - INFO - Epoch 2: Train(l=0.6568,a=0.6099) | Val(l=0.6602,a=0.9272)
2025-06-01 18:55:59,423 - INFO - Epoch 3: Train(l=0.6152,a=0.6945) | Val(l=0.6647,a=0.9272)
2025-06-01 18:56:00,461 - INFO - Epoch 4: Train(l=0.5944,a=0.7188) | Val(l=0.6749,a=0.9272)
2025-06-01 18:56:01,077 - INFO - Epoch 5: Train(l=0.5746,a=0.7487) | Val(l=0.7033,a=0.0728)
2025-06-01 18:56:02,005 - INFO - Epoch 6: Train(l=0.5552,a=0.7766) | Val(l=0.7334,a=0.0728)
2025-06-01 18:56:02,858 - INFO - Epoch 7: Train(l=0.5398,a=0.7761) | Val(l=0.7842,a=0.0728)
2025-06-01 18:56:03,584 - INFO - Epoch 8: Train(l=0.5326,a=0.7822) | Val(l=0.8500,a=0.0728)
2025-06-01 18:56:04,464 - INFO - Epoch 9: Train(l=0.5191,a=0.8034) | Val(l=0.9697,a=0.0728)
2025-06-01 18:56:05,175 - INFO - Epoch 10: Train(l=0.5101,a=0.7972) | Val(l=1.0084,a=0.0822)
2025-06-01 18:56:05,780 - INFO - Epoch 11: Train(l=0.5035,a=0.8209) | Val(l=1.0670,a=0.1009)
2025-06-01 18:56:06,309 - INFO - Epoch 12: Train(l=0.4985,a=0.8302) | Val(l=1.1545,a=0.1338)
2025-06-01 18:56:06,945 - INFO - Epoch 13: Train(l=0.4938,a=0.8333) | Val(l=1.2608,a=0.1432)
2025-06-01 18:56:07,587 - INFO - Epoch 14: Train(l=0.4880,a=0.8385) | Val(l=1.0828,a=0.2207)
2025-06-01 18:56:08,179 - INFO - Epoch 15: Train(l=0.4880,a=0.8369) | Val(l=0.9988,a=0.3146)
2025-06-01 18:56:08,736 - INFO - Epoch 16: Train(l=0.4859,a=0.8318) | Val(l=0.9402,a=0.3709)
2025-06-01 18:56:09,347 - INFO - Epoch 17: Train(l=0.4813,a=0.8488) | Val(l=0.9020,a=0.4155)
2025-06-01 18:56:09,929 - INFO - Epoch 18: Train(l=0.4788,a=0.8437) | Val(l=0.7758,a=0.5164)
2025-06-01 18:56:10,517 - INFO - Epoch 19: Train(l=0.4820,a=0.8478) | Val(l=0.7361,a=0.5681)
2025-06-01 18:56:11,142 - INFO - Epoch 20: Train(l=0.4782,a=0.8338) | Val(l=0.7158,a=0.5845)
2025-06-01 18:56:11,692 - INFO - Epoch 21: Train(l=0.4822,a=0.8328) | Val(l=0.7052,a=0.5939)
2025-06-01 18:56:12,292 - INFO - Epoch 22: Train(l=0.4749,a=0.8493) | Val(l=0.6566,a=0.6385)
2025-06-01 18:56:12,751 - INFO - Epoch 23: Train(l=0.4741,a=0.8545) | Val(l=0.6405,a=0.6479)
2025-06-01 18:56:13,198 - INFO - Epoch 24: Train(l=0.4753,a=0.8406) | Val(l=0.6313,a=0.6502)
2025-06-01 18:56:13,675 - INFO - Epoch 25: Train(l=0.4820,a=0.8375) | Val(l=0.6239,a=0.6596)
2025-06-01 18:56:14,301 - INFO - Epoch 26: Train(l=0.4671,a=0.8519) | Val(l=0.6268,a=0.6526)
2025-06-01 18:56:15,116 - INFO - Epoch 27: Train(l=0.4689,a=0.8540) | Val(l=0.6242,a=0.6573)
2025-06-01 18:56:15,879 - INFO - Epoch 28: Train(l=0.4675,a=0.8519) | Val(l=0.6180,a=0.6643)
2025-06-01 18:56:16,708 - INFO - Epoch 29: Train(l=0.4724,a=0.8519) | Val(l=0.6186,a=0.6620)
2025-06-01 18:56:17,445 - INFO - Epoch 30: Train(l=0.4696,a=0.8437) | Val(l=0.6165,a=0.6667)
2025-06-01 18:56:18,030 - INFO - Epoch 31: Train(l=0.4717,a=0.8457) | Val(l=0.6172,a=0.6596)
2025-06-01 18:56:18,581 - INFO - Epoch 32: Train(l=0.4655,a=0.8571) | Val(l=0.6194,a=0.6667)
2025-06-01 18:56:19,180 - INFO - Epoch 33: Train(l=0.4726,a=0.8411) | Val(l=0.6139,a=0.6643)
2025-06-01 18:56:19,770 - INFO - Epoch 34: Train(l=0.4672,a=0.8560) | Val(l=0.6081,a=0.6690)
2025-06-01 18:56:20,345 - INFO - Epoch 35: Train(l=0.4652,a=0.8452) | Val(l=0.6081,a=0.6690)
2025-06-01 18:56:21,329 - INFO - Epoch 36: Train(l=0.4737,a=0.8473) | Val(l=0.6109,a=0.6643)
2025-06-01 18:56:21,996 - INFO - Epoch 37: Train(l=0.4744,a=0.8498) | Val(l=0.6052,a=0.6714)
2025-06-01 18:56:22,593 - INFO - Epoch 38: Train(l=0.4713,a=0.8473) | Val(l=0.6069,a=0.6690)
2025-06-01 18:56:23,225 - INFO - Epoch 39: Train(l=0.4653,a=0.8514) | Val(l=0.6052,a=0.6690)
2025-06-01 18:56:23,772 - INFO - Epoch 40: Train(l=0.4717,a=0.8581) | Val(l=0.6046,a=0.6714)
2025-06-01 18:56:24,343 - INFO - Epoch 41: Train(l=0.4633,a=0.8519) | Val(l=0.6095,a=0.6643)
2025-06-01 18:56:24,935 - INFO - Epoch 42: Train(l=0.4736,a=0.8457) | Val(l=0.6127,a=0.6667)
2025-06-01 18:56:25,407 - INFO - Epoch 43: Train(l=0.4639,a=0.8529) | Val(l=0.6048,a=0.6737)
2025-06-01 18:56:25,880 - INFO - Epoch 44: Train(l=0.4646,a=0.8566) | Val(l=0.6140,a=0.6667)
2025-06-01 18:56:26,377 - INFO - Epoch 45: Train(l=0.4560,a=0.8715) | Val(l=0.5907,a=0.6878)
2025-06-01 18:56:26,833 - INFO - Epoch 46: Train(l=0.4732,a=0.8560) | Val(l=0.5838,a=0.6948)
2025-06-01 18:56:27,358 - INFO - Epoch 47: Train(l=0.4589,a=0.8684) | Val(l=0.5797,a=0.6995)
2025-06-01 18:56:27,820 - INFO - Epoch 48: Train(l=0.4578,a=0.8674) | Val(l=0.5778,a=0.7019)
2025-06-01 18:56:28,307 - INFO - Epoch 49: Train(l=0.4635,a=0.8560) | Val(l=0.5819,a=0.6972)
2025-06-01 19:03:16,130 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-01 19:09:02,172 - INFO - Training DBN...
2025-06-01 19:09:03,210 - INFO - Starting DBN pre-training...
2025-06-01 19:09:03,210 - INFO - Pre-training RBM layer 1/3
2025-06-01 19:09:04,356 - INFO -  RBM1 Epoch 0: Loss=1.6209
2025-06-01 19:09:06,598 - INFO -  RBM1 Epoch 10: Loss=1.5976
2025-06-01 19:09:09,515 - INFO -  RBM1 Epoch 20: Loss=1.5698
2025-06-01 19:09:12,445 - INFO -  RBM1 Epoch 30: Loss=1.5560
2025-06-01 19:09:16,427 - INFO -  RBM1 Epoch 40: Loss=1.5230
2025-06-01 19:09:20,279 - INFO -  RBM1 Epoch 50: Loss=1.5129
2025-06-01 19:09:23,186 - INFO -  RBM1 Epoch 60: Loss=1.4931
2025-06-01 19:09:25,683 - INFO -  RBM1 Epoch 70: Loss=1.4717
2025-06-01 19:09:28,661 - INFO -  RBM1 Epoch 80: Loss=1.4627
2025-06-01 19:09:32,867 - INFO -  RBM1 Epoch 90: Loss=1.4502
2025-06-01 19:09:37,124 - INFO - Pre-training RBM layer 2/3
2025-06-01 19:09:37,573 - INFO -  RBM2 Epoch 0: Loss=0.2777
2025-06-01 19:09:40,683 - INFO -  RBM2 Epoch 10: Loss=0.2776
2025-06-01 19:09:43,473 - INFO -  RBM2 Epoch 20: Loss=0.2778
2025-06-01 19:09:46,280 - INFO -  RBM2 Epoch 30: Loss=0.2777
2025-06-01 19:09:48,896 - INFO -  RBM2 Epoch 40: Loss=0.2777
2025-06-01 19:09:51,542 - INFO -  RBM2 Epoch 50: Loss=0.2778
2025-06-01 19:09:54,295 - INFO -  RBM2 Epoch 60: Loss=0.2777
2025-06-01 19:09:56,342 - INFO -  RBM2 Epoch 70: Loss=0.2777
2025-06-01 19:09:58,851 - INFO -  RBM2 Epoch 80: Loss=0.2776
2025-06-01 19:10:03,732 - INFO -  RBM2 Epoch 90: Loss=0.2777
2025-06-01 19:10:15,603 - INFO - Pre-training RBM layer 3/3
2025-06-01 19:10:16,615 - INFO -  RBM3 Epoch 0: Loss=0.2733
2025-06-01 19:10:20,345 - INFO -  RBM3 Epoch 10: Loss=0.2732
2025-06-01 19:10:23,407 - INFO -  RBM3 Epoch 20: Loss=0.2733
2025-06-01 19:10:28,069 - INFO -  RBM3 Epoch 30: Loss=0.2732
2025-06-01 19:10:31,658 - INFO -  RBM3 Epoch 40: Loss=0.2732
2025-06-01 19:10:34,787 - INFO -  RBM3 Epoch 50: Loss=0.2730
2025-06-01 19:10:38,320 - INFO -  RBM3 Epoch 60: Loss=0.2731
2025-06-01 19:10:41,530 - INFO -  RBM3 Epoch 70: Loss=0.2732
2025-06-01 19:10:45,352 - INFO -  RBM3 Epoch 80: Loss=0.2730
2025-06-01 19:10:48,084 - INFO -  RBM3 Epoch 90: Loss=0.2730
2025-06-01 19:10:49,542 - INFO - Starting DBN fine-tuning...
2025-06-01 19:11:12,825 - INFO - Epoch 0: Train(l=0.6910,a=0.5542) | Val(l=0.6928,a=0.9272)
2025-06-01 19:11:13,041 - INFO - Epoch 1: Train(l=0.6364,a=0.6445) | Val(l=0.6990,a=0.0728)
2025-06-01 19:11:13,252 - INFO - Epoch 2: Train(l=0.6013,a=0.7074) | Val(l=0.7071,a=0.0728)
2025-06-01 19:11:13,521 - INFO - Epoch 3: Train(l=0.5681,a=0.7358) | Val(l=0.7188,a=0.0728)
2025-06-01 19:11:13,787 - INFO - Epoch 4: Train(l=0.5383,a=0.7570) | Val(l=0.7392,a=0.0728)
2025-06-01 19:11:14,107 - INFO - Epoch 5: Train(l=0.5139,a=0.7797) | Val(l=0.7538,a=0.0728)
2025-06-01 19:11:14,495 - INFO - Epoch 6: Train(l=0.5134,a=0.7874) | Val(l=0.7754,a=0.0728)
2025-06-01 19:11:14,924 - INFO - Epoch 7: Train(l=0.5044,a=0.7874) | Val(l=0.8385,a=0.0728)
2025-06-01 19:11:15,413 - INFO - Epoch 8: Train(l=0.4923,a=0.8019) | Val(l=0.9783,a=0.0728)
2025-06-01 19:11:15,923 - INFO - Epoch 9: Train(l=0.4843,a=0.8039) | Val(l=1.0453,a=0.0728)
2025-06-01 19:11:16,413 - INFO - Epoch 10: Train(l=0.4788,a=0.8209) | Val(l=1.1767,a=0.0728)
2025-06-01 19:11:16,414 - INFO - Early stopping.
2025-06-01 19:11:43,147 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-01 19:12:24,122 - INFO - Validation MSE: 0.471764
2025-06-01 19:16:49,153 - INFO - Training DBN...
2025-06-01 19:16:50,135 - INFO - Starting DBN pre-training...
2025-06-01 19:16:50,136 - INFO - Pre-training RBM layer 1/3
2025-06-01 19:16:51,145 - INFO -  RBM1 Epoch 0: Loss=1.6175
2025-06-01 19:16:53,431 - INFO -  RBM1 Epoch 10: Loss=1.6099
2025-06-01 19:17:00,440 - INFO -  RBM1 Epoch 20: Loss=1.5728
2025-06-01 19:17:03,945 - INFO -  RBM1 Epoch 30: Loss=1.5533
2025-06-01 19:17:07,050 - INFO -  RBM1 Epoch 40: Loss=1.5216
2025-06-01 19:17:09,745 - INFO -  RBM1 Epoch 50: Loss=1.4992
2025-06-01 19:17:13,343 - INFO -  RBM1 Epoch 60: Loss=1.4993
2025-06-01 19:17:15,931 - INFO -  RBM1 Epoch 70: Loss=1.4739
2025-06-01 19:17:19,424 - INFO -  RBM1 Epoch 80: Loss=1.4496
2025-06-01 19:17:23,014 - INFO -  RBM1 Epoch 90: Loss=1.4511
2025-06-01 19:17:25,716 - INFO - Pre-training RBM layer 2/3
2025-06-01 19:17:25,996 - INFO -  RBM2 Epoch 0: Loss=0.2776
2025-06-01 19:17:28,239 - INFO -  RBM2 Epoch 10: Loss=0.2776
2025-06-01 19:17:33,122 - INFO -  RBM2 Epoch 20: Loss=0.2776
2025-06-01 19:17:37,781 - INFO -  RBM2 Epoch 30: Loss=0.2776
2025-06-01 19:17:43,381 - INFO -  RBM2 Epoch 40: Loss=0.2776
2025-06-01 19:17:49,255 - INFO -  RBM2 Epoch 50: Loss=0.2777
2025-06-01 19:17:55,178 - INFO -  RBM2 Epoch 60: Loss=0.2777
2025-06-01 19:17:58,873 - INFO -  RBM2 Epoch 70: Loss=0.2777
2025-06-01 19:18:03,648 - INFO -  RBM2 Epoch 80: Loss=0.2775
2025-06-01 19:18:09,509 - INFO -  RBM2 Epoch 90: Loss=0.2778
2025-06-01 19:18:12,776 - INFO - Pre-training RBM layer 3/3
2025-06-01 19:18:13,027 - INFO -  RBM3 Epoch 0: Loss=0.2734
2025-06-01 19:18:15,276 - INFO -  RBM3 Epoch 10: Loss=0.2734
2025-06-01 19:18:17,861 - INFO -  RBM3 Epoch 20: Loss=0.2733
2025-06-01 19:18:19,946 - INFO -  RBM3 Epoch 30: Loss=0.2734
2025-06-01 19:18:22,210 - INFO -  RBM3 Epoch 40: Loss=0.2733
2025-06-01 19:18:25,073 - INFO -  RBM3 Epoch 50: Loss=0.2734
2025-06-01 19:18:28,877 - INFO -  RBM3 Epoch 60: Loss=0.2732
2025-06-01 19:18:30,975 - INFO -  RBM3 Epoch 70: Loss=0.2732
2025-06-01 19:18:32,744 - INFO -  RBM3 Epoch 80: Loss=0.2732
2025-06-01 19:18:34,428 - INFO -  RBM3 Epoch 90: Loss=0.2732
2025-06-01 19:18:36,060 - INFO - Starting DBN fine-tuning...
2025-06-01 19:19:06,840 - INFO - Epoch 0: Train(l=0.7018,a=0.6125) | Val(l=0.7732,a=0.0728)
2025-06-01 19:19:07,230 - INFO - Epoch 1: Train(l=0.6485,a=0.6300) | Val(l=0.7708,a=0.0728)
2025-06-01 19:19:07,642 - INFO - Epoch 2: Train(l=0.6054,a=0.6548) | Val(l=0.7685,a=0.0728)
2025-06-01 19:19:08,140 - INFO - Epoch 3: Train(l=0.5874,a=0.6682) | Val(l=0.7690,a=0.0728)
2025-06-01 19:19:08,609 - INFO - Epoch 4: Train(l=0.5607,a=0.7012) | Val(l=0.7751,a=0.0728)
2025-06-01 19:19:09,108 - INFO - Epoch 5: Train(l=0.5448,a=0.7167) | Val(l=0.7987,a=0.0728)
2025-06-01 19:19:09,509 - INFO - Epoch 6: Train(l=0.5289,a=0.7466) | Val(l=0.8779,a=0.0728)
2025-06-01 19:19:09,957 - INFO - Epoch 7: Train(l=0.5054,a=0.7693) | Val(l=0.9181,a=0.0728)
2025-06-01 19:19:10,438 - INFO - Epoch 8: Train(l=0.4993,a=0.7776) | Val(l=0.9557,a=0.0728)
2025-06-01 19:19:10,969 - INFO - Epoch 9: Train(l=0.4857,a=0.7905) | Val(l=1.0355,a=0.0822)
2025-06-01 19:19:11,471 - INFO - Epoch 10: Train(l=0.4747,a=0.7998) | Val(l=1.2128,a=0.0845)
2025-06-01 19:19:11,922 - INFO - Epoch 11: Train(l=0.4674,a=0.8096) | Val(l=1.1533,a=0.1455)
2025-06-01 19:19:12,367 - INFO - Epoch 12: Train(l=0.4661,a=0.8137) | Val(l=1.2164,a=0.2019)
2025-06-01 19:19:12,790 - INFO - Epoch 13: Train(l=0.4602,a=0.8302) | Val(l=1.4234,a=0.1925)
2025-06-01 19:19:13,331 - INFO - Epoch 14: Train(l=0.4487,a=0.8266) | Val(l=1.4979,a=0.1784)
2025-06-01 19:19:13,805 - INFO - Epoch 15: Train(l=0.4450,a=0.8385) | Val(l=1.2288,a=0.2629)
2025-06-01 19:19:14,302 - INFO - Epoch 16: Train(l=0.4447,a=0.8426) | Val(l=1.0934,a=0.3404)
2025-06-01 19:19:14,777 - INFO - Epoch 17: Train(l=0.4460,a=0.8395) | Val(l=0.9563,a=0.4554)
2025-06-01 19:19:15,277 - INFO - Epoch 18: Train(l=0.4399,a=0.8385) | Val(l=0.9696,a=0.4390)
2025-06-01 19:19:15,788 - INFO - Epoch 19: Train(l=0.4420,a=0.8364) | Val(l=0.8554,a=0.5423)
2025-06-01 19:19:16,346 - INFO - Epoch 20: Train(l=0.4333,a=0.8504) | Val(l=0.8015,a=0.5704)
2025-06-01 19:19:16,829 - INFO - Epoch 21: Train(l=0.4407,a=0.8411) | Val(l=0.7920,a=0.5728)
2025-06-01 19:19:17,397 - INFO - Epoch 22: Train(l=0.4281,a=0.8478) | Val(l=0.7910,a=0.5681)
2025-06-01 19:19:18,778 - INFO - Epoch 23: Train(l=0.4406,a=0.8406) | Val(l=0.7472,a=0.5939)
2025-06-01 19:19:19,391 - INFO - Epoch 24: Train(l=0.4257,a=0.8545) | Val(l=0.7334,a=0.6103)
2025-06-01 19:19:19,966 - INFO - Epoch 25: Train(l=0.4275,a=0.8612) | Val(l=0.7303,a=0.6150)
2025-06-01 19:19:20,636 - INFO - Epoch 26: Train(l=0.4314,a=0.8596) | Val(l=0.7151,a=0.6268)
2025-06-01 19:19:21,389 - INFO - Epoch 27: Train(l=0.4292,a=0.8478) | Val(l=0.7235,a=0.6174)
2025-06-01 19:19:21,941 - INFO - Epoch 28: Train(l=0.4374,a=0.8473) | Val(l=0.7197,a=0.6150)
2025-06-01 19:19:22,561 - INFO - Epoch 29: Train(l=0.4319,a=0.8473) | Val(l=0.7110,a=0.6221)
2025-06-01 19:19:23,174 - INFO - Epoch 30: Train(l=0.4282,a=0.8602) | Val(l=0.7109,a=0.6221)
2025-06-01 19:19:23,806 - INFO - Epoch 31: Train(l=0.4261,a=0.8545) | Val(l=0.7113,a=0.6221)
2025-06-01 19:19:24,369 - INFO - Epoch 32: Train(l=0.4300,a=0.8571) | Val(l=0.7013,a=0.6291)
2025-06-01 19:19:24,893 - INFO - Epoch 33: Train(l=0.4226,a=0.8504) | Val(l=0.7004,a=0.6315)
2025-06-01 19:19:25,607 - INFO - Epoch 34: Train(l=0.4292,a=0.8467) | Val(l=0.6999,a=0.6291)
2025-06-01 19:19:26,274 - INFO - Epoch 35: Train(l=0.4256,a=0.8571) | Val(l=0.7082,a=0.6268)
2025-06-01 19:19:26,882 - INFO - Epoch 36: Train(l=0.4239,a=0.8622) | Val(l=0.7119,a=0.6221)
2025-06-01 19:19:27,493 - INFO - Epoch 37: Train(l=0.4255,a=0.8591) | Val(l=0.7066,a=0.6221)
2025-06-01 19:19:28,057 - INFO - Epoch 38: Train(l=0.4256,a=0.8560) | Val(l=0.7164,a=0.6197)
2025-06-01 19:19:28,591 - INFO - Epoch 39: Train(l=0.4247,a=0.8576) | Val(l=0.6965,a=0.6268)
2025-06-01 19:19:29,129 - INFO - Epoch 40: Train(l=0.4265,a=0.8529) | Val(l=0.6816,a=0.6385)
2025-06-01 19:19:29,624 - INFO - Epoch 41: Train(l=0.4212,a=0.8576) | Val(l=0.6763,a=0.6408)
2025-06-01 19:19:30,111 - INFO - Epoch 42: Train(l=0.4229,a=0.8612) | Val(l=0.6760,a=0.6432)
2025-06-01 19:19:30,546 - INFO - Epoch 43: Train(l=0.4245,a=0.8560) | Val(l=0.6770,a=0.6385)
2025-06-01 19:19:31,008 - INFO - Epoch 44: Train(l=0.4239,a=0.8535) | Val(l=0.6730,a=0.6408)
2025-06-01 19:19:31,546 - INFO - Epoch 45: Train(l=0.4218,a=0.8524) | Val(l=0.6764,a=0.6362)
2025-06-01 19:19:32,047 - INFO - Epoch 46: Train(l=0.4259,a=0.8596) | Val(l=0.6729,a=0.6432)
2025-06-01 19:19:32,522 - INFO - Epoch 47: Train(l=0.4219,a=0.8560) | Val(l=0.6765,a=0.6362)
2025-06-01 19:19:33,021 - INFO - Epoch 48: Train(l=0.4205,a=0.8602) | Val(l=0.6743,a=0.6385)
2025-06-01 19:19:33,584 - INFO - Epoch 49: Train(l=0.4238,a=0.8519) | Val(l=0.6774,a=0.6408)
2025-06-01 19:19:34,131 - INFO - Epoch 50: Train(l=0.4189,a=0.8566) | Val(l=0.6785,a=0.6362)
2025-06-01 19:19:34,648 - INFO - Epoch 51: Train(l=0.4149,a=0.8622) | Val(l=0.6715,a=0.6432)
2025-06-01 19:19:35,209 - INFO - Epoch 52: Train(l=0.4290,a=0.8509) | Val(l=0.6688,a=0.6455)
2025-06-01 19:19:35,703 - INFO - Epoch 53: Train(l=0.4176,a=0.8674) | Val(l=0.6588,a=0.6526)
2025-06-01 19:19:36,318 - INFO - Epoch 54: Train(l=0.4170,a=0.8612) | Val(l=0.6604,a=0.6455)
2025-06-01 19:19:36,900 - INFO - Epoch 55: Train(l=0.4160,a=0.8576) | Val(l=0.6595,a=0.6502)
2025-06-01 19:19:37,648 - INFO - Epoch 56: Train(l=0.4209,a=0.8576) | Val(l=0.6517,a=0.6667)
2025-06-01 19:19:38,872 - INFO - Epoch 57: Train(l=0.4232,a=0.8535) | Val(l=0.6642,a=0.6455)
2025-06-01 19:19:40,483 - INFO - Epoch 58: Train(l=0.4157,a=0.8643) | Val(l=0.6594,a=0.6502)
2025-06-01 19:19:41,967 - INFO - Epoch 59: Train(l=0.4189,a=0.8658) | Val(l=0.6571,a=0.6549)
2025-06-01 19:19:43,397 - INFO - Epoch 60: Train(l=0.4224,a=0.8602) | Val(l=0.6566,a=0.6526)
2025-06-01 19:19:44,419 - INFO - Epoch 61: Train(l=0.4137,a=0.8679) | Val(l=0.6549,a=0.6573)
2025-06-01 19:19:45,589 - INFO - Epoch 62: Train(l=0.4187,a=0.8586) | Val(l=0.6528,a=0.6596)
2025-06-01 19:19:46,453 - INFO - Epoch 63: Train(l=0.4201,a=0.8550) | Val(l=0.6547,a=0.6596)
2025-06-01 19:19:47,402 - INFO - Epoch 64: Train(l=0.4205,a=0.8617) | Val(l=0.6507,a=0.6643)
2025-06-01 19:19:48,833 - INFO - Epoch 65: Train(l=0.4219,a=0.8535) | Val(l=0.6568,a=0.6573)
2025-06-01 19:19:50,087 - INFO - Epoch 66: Train(l=0.4267,a=0.8483) | Val(l=0.6575,a=0.6549)
2025-06-01 19:19:51,955 - INFO - Epoch 67: Train(l=0.4204,a=0.8627) | Val(l=0.6535,a=0.6620)
2025-06-01 19:19:53,738 - INFO - Epoch 68: Train(l=0.4183,a=0.8633) | Val(l=0.6589,a=0.6502)
2025-06-01 19:19:55,469 - INFO - Epoch 69: Train(l=0.4188,a=0.8566) | Val(l=0.6554,a=0.6596)
2025-06-01 19:19:57,071 - INFO - Epoch 70: Train(l=0.4163,a=0.8607) | Val(l=0.6512,a=0.6667)
2025-06-01 19:19:59,151 - INFO - Epoch 71: Train(l=0.4127,a=0.8684) | Val(l=0.6442,a=0.6690)
2025-06-01 19:20:00,845 - INFO - Epoch 72: Train(l=0.4132,a=0.8689) | Val(l=0.6433,a=0.6690)
2025-06-01 19:20:02,616 - INFO - Epoch 73: Train(l=0.4224,a=0.8509) | Val(l=0.6313,a=0.6737)
2025-06-01 19:20:04,926 - INFO - Epoch 74: Train(l=0.4187,a=0.8591) | Val(l=0.6419,a=0.6714)
2025-06-01 19:20:06,216 - INFO - Epoch 75: Train(l=0.4144,a=0.8664) | Val(l=0.6526,a=0.6643)
2025-06-01 19:20:07,408 - INFO - Epoch 76: Train(l=0.4166,a=0.8576) | Val(l=0.6525,a=0.6643)
2025-06-01 19:20:10,127 - INFO - Epoch 77: Train(l=0.4171,a=0.8591) | Val(l=0.6458,a=0.6667)
2025-06-01 19:20:11,814 - INFO - Epoch 78: Train(l=0.4173,a=0.8571) | Val(l=0.6490,a=0.6643)
2025-06-01 19:20:13,348 - INFO - Epoch 79: Train(l=0.4191,a=0.8586) | Val(l=0.6498,a=0.6643)
2025-06-01 19:20:16,366 - INFO - Epoch 80: Train(l=0.4154,a=0.8627) | Val(l=0.6432,a=0.6690)
2025-06-01 19:20:18,754 - INFO - Epoch 81: Train(l=0.4200,a=0.8488) | Val(l=0.6506,a=0.6643)
2025-06-01 19:20:19,983 - INFO - Epoch 82: Train(l=0.4209,a=0.8612) | Val(l=0.6464,a=0.6667)
2025-06-01 19:20:22,621 - INFO - Epoch 83: Train(l=0.4151,a=0.8695) | Val(l=0.6426,a=0.6714)
2025-06-01 19:20:23,916 - INFO - Epoch 84: Train(l=0.4170,a=0.8591) | Val(l=0.6443,a=0.6690)
2025-06-01 19:20:25,686 - INFO - Epoch 85: Train(l=0.4218,a=0.8524) | Val(l=0.6462,a=0.6667)
2025-06-01 19:20:26,709 - INFO - Epoch 86: Train(l=0.4090,a=0.8658) | Val(l=0.6546,a=0.6620)
2025-06-01 19:20:27,576 - INFO - Epoch 87: Train(l=0.4191,a=0.8617) | Val(l=0.6559,a=0.6620)
2025-06-01 19:20:28,569 - INFO - Epoch 88: Train(l=0.4214,a=0.8596) | Val(l=0.6473,a=0.6690)
2025-06-01 19:20:29,500 - INFO - Epoch 89: Train(l=0.4165,a=0.8633) | Val(l=0.6489,a=0.6643)
2025-06-01 19:20:30,616 - INFO - Epoch 90: Train(l=0.4150,a=0.8720) | Val(l=0.6511,a=0.6643)
2025-06-01 19:20:31,645 - INFO - Epoch 91: Train(l=0.4160,a=0.8627) | Val(l=0.6543,a=0.6596)
2025-06-01 19:20:32,521 - INFO - Epoch 92: Train(l=0.4201,a=0.8576) | Val(l=0.6512,a=0.6643)
2025-06-01 19:20:33,434 - INFO - Epoch 93: Train(l=0.4146,a=0.8612) | Val(l=0.6462,a=0.6667)
2025-06-01 19:20:34,290 - INFO - Epoch 94: Train(l=0.4194,a=0.8581) | Val(l=0.6527,a=0.6643)
2025-06-01 19:20:35,173 - INFO - Epoch 95: Train(l=0.4142,a=0.8715) | Val(l=0.6534,a=0.6643)
2025-06-01 19:20:35,929 - INFO - Epoch 96: Train(l=0.4228,a=0.8591) | Val(l=0.6483,a=0.6643)
2025-06-01 19:20:36,885 - INFO - Epoch 97: Train(l=0.4214,a=0.8617) | Val(l=0.6499,a=0.6667)
2025-06-01 19:20:37,677 - INFO - Epoch 98: Train(l=0.4190,a=0.8596) | Val(l=0.6394,a=0.6714)
2025-06-01 19:20:38,438 - INFO - Epoch 99: Train(l=0.4144,a=0.8638) | Val(l=0.6424,a=0.6690)
2025-06-01 19:20:58,807 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-01 19:21:21,029 - INFO - Validation MSE: 0.222438
2025-06-01 19:27:09,672 - INFO - Training DBN...
2025-06-01 19:27:10,257 - INFO - Starting DBN pre-training...
2025-06-01 19:27:10,257 - INFO - Pre-training RBM layer 1/3
2025-06-01 19:27:10,581 - INFO -  RBM1 Epoch 0: Loss=1.6139
2025-06-01 19:27:11,425 - INFO -  RBM1 Epoch 10: Loss=1.5928
2025-06-01 19:27:12,753 - INFO -  RBM1 Epoch 20: Loss=1.5759
2025-06-01 19:27:16,572 - INFO -  RBM1 Epoch 30: Loss=1.5545
2025-06-01 19:27:19,757 - INFO -  RBM1 Epoch 40: Loss=1.5226
2025-06-01 19:27:23,659 - INFO -  RBM1 Epoch 50: Loss=1.5157
2025-06-01 19:27:26,403 - INFO -  RBM1 Epoch 60: Loss=1.4995
2025-06-01 19:27:28,344 - INFO -  RBM1 Epoch 70: Loss=1.4781
2025-06-01 19:27:30,268 - INFO -  RBM1 Epoch 80: Loss=1.4590
2025-06-01 19:27:33,050 - INFO -  RBM1 Epoch 90: Loss=1.4495
2025-06-01 19:27:35,624 - INFO - Pre-training RBM layer 2/3
2025-06-01 19:27:35,980 - INFO -  RBM2 Epoch 0: Loss=0.2777
2025-06-01 19:27:37,448 - INFO -  RBM2 Epoch 10: Loss=0.2776
2025-06-01 19:27:39,053 - INFO -  RBM2 Epoch 20: Loss=0.2778
2025-06-01 19:27:40,532 - INFO -  RBM2 Epoch 30: Loss=0.2776
2025-06-01 19:27:43,007 - INFO -  RBM2 Epoch 40: Loss=0.2778
2025-06-01 19:27:45,186 - INFO -  RBM2 Epoch 50: Loss=0.2777
2025-06-01 19:27:47,430 - INFO -  RBM2 Epoch 60: Loss=0.2779
2025-06-01 19:27:49,815 - INFO -  RBM2 Epoch 70: Loss=0.2778
2025-06-01 19:27:52,143 - INFO -  RBM2 Epoch 80: Loss=0.2779
2025-06-01 19:27:53,528 - INFO -  RBM2 Epoch 90: Loss=0.2779
2025-06-01 19:27:55,422 - INFO - Pre-training RBM layer 3/3
2025-06-01 19:27:55,653 - INFO -  RBM3 Epoch 0: Loss=0.2733
2025-06-01 19:27:56,891 - INFO -  RBM3 Epoch 10: Loss=0.2734
2025-06-01 19:27:57,551 - INFO -  RBM3 Epoch 20: Loss=0.2733
2025-06-01 19:27:58,308 - INFO -  RBM3 Epoch 30: Loss=0.2733
2025-06-01 19:27:59,251 - INFO -  RBM3 Epoch 40: Loss=0.2732
2025-06-01 19:27:59,927 - INFO -  RBM3 Epoch 50: Loss=0.2731
2025-06-01 19:28:00,580 - INFO -  RBM3 Epoch 60: Loss=0.2732
2025-06-01 19:28:01,293 - INFO -  RBM3 Epoch 70: Loss=0.2731
2025-06-01 19:28:01,990 - INFO -  RBM3 Epoch 80: Loss=0.2731
2025-06-01 19:28:02,757 - INFO -  RBM3 Epoch 90: Loss=0.2731
2025-06-01 19:28:03,443 - INFO - Starting DBN fine-tuning...
2025-06-01 19:28:27,374 - INFO - Epoch 0: Train(l=0.6827,a=0.6001) | Val(l=0.7589,a=0.0728)
2025-06-01 19:28:27,502 - INFO - Epoch 1: Train(l=0.6484,a=0.6424) | Val(l=0.7610,a=0.0728)
2025-06-01 19:28:27,640 - INFO - Epoch 2: Train(l=0.6145,a=0.6873) | Val(l=0.7629,a=0.0728)
2025-06-01 19:28:27,795 - INFO - Epoch 3: Train(l=0.5911,a=0.7049) | Val(l=0.7645,a=0.0728)
2025-06-01 19:28:27,909 - INFO - Epoch 4: Train(l=0.5710,a=0.7286) | Val(l=0.7664,a=0.0728)
2025-06-01 19:28:28,024 - INFO - Epoch 5: Train(l=0.5567,a=0.7389) | Val(l=0.7657,a=0.0728)
2025-06-01 19:28:28,147 - INFO - Epoch 6: Train(l=0.5407,a=0.7652) | Val(l=0.7647,a=0.0728)
2025-06-01 19:28:28,260 - INFO - Epoch 7: Train(l=0.5296,a=0.7673) | Val(l=0.7380,a=0.1338)
2025-06-01 19:28:28,370 - INFO - Epoch 8: Train(l=0.5241,a=0.7802) | Val(l=0.6766,a=0.6221)
2025-06-01 19:28:28,507 - INFO - Epoch 9: Train(l=0.5068,a=0.8013) | Val(l=0.6184,a=0.7559)
2025-06-01 19:28:28,641 - INFO - Epoch 10: Train(l=0.4978,a=0.8070) | Val(l=0.5611,a=0.7911)
2025-06-01 19:28:28,788 - INFO - Epoch 11: Train(l=0.4945,a=0.8070) | Val(l=0.4573,a=0.8826)
2025-06-01 19:28:28,912 - INFO - Epoch 12: Train(l=0.4750,a=0.8328) | Val(l=0.3351,a=0.9178)
2025-06-01 19:28:29,038 - INFO - Epoch 13: Train(l=0.4719,a=0.8369) | Val(l=0.2674,a=0.9272)
2025-06-01 19:28:29,174 - INFO - Epoch 14: Train(l=0.4633,a=0.8400) | Val(l=0.2381,a=0.9272)
2025-06-01 19:28:29,328 - INFO - Epoch 15: Train(l=0.4595,a=0.8493) | Val(l=0.2280,a=0.9272)
2025-06-01 19:28:29,490 - INFO - Epoch 16: Train(l=0.4419,a=0.8689) | Val(l=0.2280,a=0.9272)
2025-06-01 19:28:29,671 - INFO - Epoch 17: Train(l=0.4334,a=0.8777) | Val(l=0.2287,a=0.9272)
2025-06-01 19:28:29,901 - INFO - Epoch 18: Train(l=0.4184,a=0.8808) | Val(l=0.2257,a=0.9272)
2025-06-01 19:28:30,135 - INFO - Epoch 19: Train(l=0.4152,a=0.8885) | Val(l=0.2239,a=0.9272)
2025-06-01 19:28:30,351 - INFO - Epoch 20: Train(l=0.4041,a=0.8978) | Val(l=0.2156,a=0.9272)
2025-06-01 19:28:30,573 - INFO - Epoch 21: Train(l=0.3972,a=0.9082) | Val(l=0.2165,a=0.9272)
2025-06-01 19:28:30,806 - INFO - Epoch 22: Train(l=0.3860,a=0.9174) | Val(l=0.2122,a=0.9272)
2025-06-01 19:28:31,042 - INFO - Epoch 23: Train(l=0.3859,a=0.9143) | Val(l=0.2160,a=0.9272)
2025-06-01 19:28:31,270 - INFO - Epoch 24: Train(l=0.3733,a=0.9247) | Val(l=0.2096,a=0.9272)
2025-06-01 19:28:31,514 - INFO - Epoch 25: Train(l=0.3605,a=0.9303) | Val(l=0.1970,a=0.9272)
2025-06-01 19:28:31,750 - INFO - Epoch 26: Train(l=0.3618,a=0.9288) | Val(l=0.1955,a=0.9296)
2025-06-01 19:28:32,019 - INFO - Epoch 27: Train(l=0.3497,a=0.9324) | Val(l=0.2024,a=0.9343)
2025-06-01 19:28:32,286 - INFO - Epoch 28: Train(l=0.3415,a=0.9412) | Val(l=0.1983,a=0.9390)
2025-06-01 19:28:32,510 - INFO - Epoch 29: Train(l=0.3349,a=0.9345) | Val(l=0.1994,a=0.9437)
2025-06-01 19:28:33,027 - INFO - Epoch 30: Train(l=0.3316,a=0.9458) | Val(l=0.2082,a=0.9484)
2025-06-01 19:28:33,297 - INFO - Epoch 31: Train(l=0.3230,a=0.9448) | Val(l=0.2415,a=0.9249)
2025-06-01 19:28:33,600 - INFO - Epoch 32: Train(l=0.3217,a=0.9515) | Val(l=0.2900,a=0.8967)
2025-06-01 19:28:33,872 - INFO - Epoch 33: Train(l=0.3155,a=0.9505) | Val(l=0.3252,a=0.8592)
2025-06-01 19:28:34,142 - INFO - Epoch 34: Train(l=0.3120,a=0.9567) | Val(l=0.3582,a=0.8357)
2025-06-01 19:28:34,388 - INFO - Epoch 35: Train(l=0.3107,a=0.9592) | Val(l=0.3961,a=0.8146)
2025-06-01 19:28:34,649 - INFO - Epoch 36: Train(l=0.3137,a=0.9525) | Val(l=0.4056,a=0.8052)
2025-06-01 19:28:34,937 - INFO - Epoch 37: Train(l=0.3121,a=0.9561) | Val(l=0.4214,a=0.7911)
2025-06-01 19:28:35,234 - INFO - Epoch 38: Train(l=0.3089,a=0.9520) | Val(l=0.4360,a=0.7770)
2025-06-01 19:28:35,457 - INFO - Epoch 39: Train(l=0.3115,a=0.9484) | Val(l=0.4415,a=0.7723)
2025-06-01 19:28:35,708 - INFO - Epoch 40: Train(l=0.3093,a=0.9525) | Val(l=0.4374,a=0.7817)
2025-06-01 19:28:35,961 - INFO - Epoch 41: Train(l=0.3075,a=0.9628) | Val(l=0.4397,a=0.7770)
2025-06-01 19:28:36,196 - INFO - Epoch 42: Train(l=0.3011,a=0.9592) | Val(l=0.4473,a=0.7770)
2025-06-01 19:28:36,387 - INFO - Epoch 43: Train(l=0.3020,a=0.9536) | Val(l=0.4564,a=0.7653)
2025-06-01 19:28:36,589 - INFO - Epoch 44: Train(l=0.3020,a=0.9592) | Val(l=0.4589,a=0.7629)
2025-06-01 19:28:36,806 - INFO - Epoch 45: Train(l=0.3039,a=0.9582) | Val(l=0.4534,a=0.7676)
2025-06-01 19:28:37,067 - INFO - Epoch 46: Train(l=0.3036,a=0.9582) | Val(l=0.4525,a=0.7676)
2025-06-01 19:28:37,284 - INFO - Epoch 47: Train(l=0.3028,a=0.9567) | Val(l=0.4521,a=0.7700)
2025-06-01 19:28:37,487 - INFO - Epoch 48: Train(l=0.2999,a=0.9603) | Val(l=0.4522,a=0.7676)
2025-06-01 19:28:37,692 - INFO - Epoch 49: Train(l=0.3008,a=0.9572) | Val(l=0.4538,a=0.7629)
2025-06-01 19:28:37,950 - INFO - Epoch 50: Train(l=0.3062,a=0.9603) | Val(l=0.4552,a=0.7629)
2025-06-01 19:28:38,206 - INFO - Epoch 51: Train(l=0.2994,a=0.9618) | Val(l=0.4625,a=0.7606)
2025-06-01 19:28:38,402 - INFO - Epoch 52: Train(l=0.2990,a=0.9582) | Val(l=0.4598,a=0.7629)
2025-06-01 19:28:38,605 - INFO - Epoch 53: Train(l=0.3029,a=0.9587) | Val(l=0.4642,a=0.7606)
2025-06-01 19:28:38,816 - INFO - Epoch 54: Train(l=0.3056,a=0.9561) | Val(l=0.4665,a=0.7606)
2025-06-01 19:28:39,039 - INFO - Epoch 55: Train(l=0.3039,a=0.9592) | Val(l=0.4729,a=0.7606)
2025-06-01 19:28:39,251 - INFO - Epoch 56: Train(l=0.3040,a=0.9530) | Val(l=0.4678,a=0.7606)
2025-06-01 19:28:39,470 - INFO - Epoch 57: Train(l=0.3055,a=0.9556) | Val(l=0.4677,a=0.7606)
2025-06-01 19:28:39,703 - INFO - Epoch 58: Train(l=0.3030,a=0.9613) | Val(l=0.4692,a=0.7606)
2025-06-01 19:28:39,944 - INFO - Epoch 59: Train(l=0.3032,a=0.9567) | Val(l=0.4633,a=0.7606)
2025-06-01 19:28:40,189 - INFO - Epoch 60: Train(l=0.3048,a=0.9639) | Val(l=0.4578,a=0.7629)
2025-06-01 19:28:40,394 - INFO - Epoch 61: Train(l=0.3037,a=0.9582) | Val(l=0.4548,a=0.7629)
2025-06-01 19:28:40,630 - INFO - Epoch 62: Train(l=0.3067,a=0.9536) | Val(l=0.4566,a=0.7629)
2025-06-01 19:28:40,952 - INFO - Epoch 63: Train(l=0.3002,a=0.9598) | Val(l=0.4574,a=0.7629)
2025-06-01 19:28:41,317 - INFO - Epoch 64: Train(l=0.3060,a=0.9530) | Val(l=0.4558,a=0.7653)
2025-06-01 19:28:41,603 - INFO - Epoch 65: Train(l=0.3046,a=0.9628) | Val(l=0.4685,a=0.7606)
2025-06-01 19:28:41,870 - INFO - Epoch 66: Train(l=0.2993,a=0.9551) | Val(l=0.4642,a=0.7606)
2025-06-01 19:28:42,171 - INFO - Epoch 67: Train(l=0.3032,a=0.9572) | Val(l=0.4580,a=0.7629)
2025-06-01 19:28:42,423 - INFO - Epoch 68: Train(l=0.2990,a=0.9598) | Val(l=0.4605,a=0.7629)
2025-06-01 19:28:42,659 - INFO - Epoch 69: Train(l=0.3032,a=0.9530) | Val(l=0.4706,a=0.7582)
2025-06-01 19:28:42,909 - INFO - Epoch 70: Train(l=0.3006,a=0.9582) | Val(l=0.4654,a=0.7606)
2025-06-01 19:28:43,173 - INFO - Epoch 71: Train(l=0.3008,a=0.9587) | Val(l=0.4606,a=0.7629)
2025-06-01 19:28:43,397 - INFO - Epoch 72: Train(l=0.3026,a=0.9592) | Val(l=0.4701,a=0.7606)
2025-06-01 19:28:43,651 - INFO - Epoch 73: Train(l=0.3025,a=0.9561) | Val(l=0.4663,a=0.7606)
2025-06-01 19:28:43,919 - INFO - Epoch 74: Train(l=0.2972,a=0.9634) | Val(l=0.4670,a=0.7606)
2025-06-01 19:28:44,167 - INFO - Epoch 75: Train(l=0.3047,a=0.9577) | Val(l=0.4640,a=0.7606)
2025-06-01 19:28:44,380 - INFO - Epoch 76: Train(l=0.3007,a=0.9587) | Val(l=0.4654,a=0.7606)
2025-06-01 19:28:44,380 - INFO - Early stopping.
2025-06-01 19:29:02,971 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-01 19:29:17,831 - INFO - Validation MSE: 0.152509
2025-06-02 21:25:36,201 - INFO - Training DBN...
2025-06-02 21:25:36,981 - INFO - Starting DBN pre-training...
2025-06-02 21:25:36,982 - INFO - Pre-training RBM layer 1/3
2025-06-02 21:25:37,656 - INFO -  RBM1 Epoch 0: Loss=1.5722
2025-06-02 21:25:38,594 - INFO -  RBM1 Epoch 10: Loss=1.5508
2025-06-02 21:25:39,651 - INFO -  RBM1 Epoch 20: Loss=1.5305
2025-06-02 21:25:41,056 - INFO -  RBM1 Epoch 30: Loss=1.5053
2025-06-02 21:25:42,272 - INFO -  RBM1 Epoch 40: Loss=1.4896
2025-06-02 21:25:43,423 - INFO - Pre-training RBM layer 2/3
2025-06-02 21:25:43,615 - INFO -  RBM2 Epoch 0: Loss=0.2678
2025-06-02 21:25:44,588 - INFO -  RBM2 Epoch 10: Loss=0.2679
2025-06-02 21:25:45,518 - INFO -  RBM2 Epoch 20: Loss=0.2680
2025-06-02 21:25:46,235 - INFO -  RBM2 Epoch 30: Loss=0.2679
2025-06-02 21:25:47,034 - INFO -  RBM2 Epoch 40: Loss=0.2679
2025-06-02 21:25:48,247 - INFO - Pre-training RBM layer 3/3
2025-06-02 21:25:48,310 - INFO -  RBM3 Epoch 0: Loss=0.2649
2025-06-02 21:25:48,975 - INFO -  RBM3 Epoch 10: Loss=0.2649
2025-06-02 21:25:49,751 - INFO -  RBM3 Epoch 20: Loss=0.2650
2025-06-02 21:25:50,363 - INFO -  RBM3 Epoch 30: Loss=0.2649
2025-06-02 21:25:51,477 - INFO -  RBM3 Epoch 40: Loss=0.2649
2025-06-02 21:25:52,878 - INFO - Starting DBN fine-tuning...
2025-06-02 21:26:17,349 - INFO - Epoch 0: Train(l=0.7274,a=0.5062) | Val(l=0.6480,a=0.9272)
2025-06-02 21:26:17,509 - INFO - Epoch 1: Train(l=0.6580,a=0.6300) | Val(l=0.6473,a=0.9272)
2025-06-02 21:26:17,662 - INFO - Epoch 2: Train(l=0.6219,a=0.6785) | Val(l=0.6489,a=0.9272)
2025-06-02 21:26:17,799 - INFO - Epoch 3: Train(l=0.5811,a=0.7394) | Val(l=0.6540,a=0.9272)
2025-06-02 21:26:17,933 - INFO - Epoch 4: Train(l=0.5482,a=0.7611) | Val(l=0.6675,a=0.9272)
2025-06-02 21:26:18,087 - INFO - Epoch 5: Train(l=0.5209,a=0.7848) | Val(l=0.6950,a=0.2488)
2025-06-02 21:26:18,231 - INFO - Epoch 6: Train(l=0.5052,a=0.8050) | Val(l=0.7240,a=0.0728)
2025-06-02 21:26:18,367 - INFO - Epoch 7: Train(l=0.4921,a=0.8163) | Val(l=0.7702,a=0.0728)
2025-06-02 21:26:18,523 - INFO - Epoch 8: Train(l=0.4878,a=0.8179) | Val(l=0.8726,a=0.0728)
2025-06-02 21:26:18,661 - INFO - Epoch 9: Train(l=0.4622,a=0.8421) | Val(l=1.0449,a=0.0728)
2025-06-02 21:26:18,798 - INFO - Epoch 10: Train(l=0.4591,a=0.8519) | Val(l=1.0897,a=0.0728)
2025-06-02 21:26:18,931 - INFO - Epoch 11: Train(l=0.4545,a=0.8560) | Val(l=1.1648,a=0.0751)
2025-06-02 21:26:19,068 - INFO - Epoch 12: Train(l=0.4494,a=0.8612) | Val(l=1.2585,a=0.0845)
2025-06-02 21:26:19,212 - INFO - Epoch 13: Train(l=0.4381,a=0.8679) | Val(l=1.3336,a=0.1174)
2025-06-02 21:26:19,356 - INFO - Epoch 14: Train(l=0.4347,a=0.8746) | Val(l=1.0783,a=0.2535)
2025-06-02 21:26:19,516 - INFO - Epoch 15: Train(l=0.4310,a=0.8720) | Val(l=0.9694,a=0.3521)
2025-06-02 21:26:19,656 - INFO - Epoch 16: Train(l=0.4278,a=0.8844) | Val(l=0.9035,a=0.4178)
2025-06-02 21:26:19,794 - INFO - Epoch 17: Train(l=0.4229,a=0.8798) | Val(l=0.8705,a=0.4624)
2025-06-02 21:26:19,936 - INFO - Epoch 18: Train(l=0.4306,a=0.8674) | Val(l=0.7294,a=0.5751)
2025-06-02 21:26:20,080 - INFO - Epoch 19: Train(l=0.4316,a=0.8638) | Val(l=0.6682,a=0.6291)
2025-06-02 21:26:20,228 - INFO - Epoch 20: Train(l=0.4247,a=0.8772) | Val(l=0.6434,a=0.6573)
2025-06-02 21:26:20,386 - INFO - Epoch 21: Train(l=0.4245,a=0.8829) | Val(l=0.6325,a=0.6620)
2025-06-02 21:26:20,551 - INFO - Epoch 22: Train(l=0.4253,a=0.8772) | Val(l=0.6221,a=0.6667)
2025-06-02 21:26:20,699 - INFO - Epoch 23: Train(l=0.4215,a=0.8880) | Val(l=0.6244,a=0.6643)
2025-06-02 21:26:20,839 - INFO - Epoch 24: Train(l=0.4199,a=0.8839) | Val(l=0.6271,a=0.6690)
2025-06-02 21:26:20,983 - INFO - Epoch 25: Train(l=0.4215,a=0.8793) | Val(l=0.6171,a=0.6761)
2025-06-02 21:26:21,132 - INFO - Epoch 26: Train(l=0.4148,a=0.8849) | Val(l=0.6084,a=0.6808)
2025-06-02 21:26:21,403 - INFO - Epoch 27: Train(l=0.4151,a=0.8916) | Val(l=0.6052,a=0.6831)
2025-06-02 21:26:21,626 - INFO - Epoch 28: Train(l=0.4221,a=0.8834) | Val(l=0.5987,a=0.6901)
2025-06-02 21:26:21,792 - INFO - Epoch 29: Train(l=0.4090,a=0.8922) | Val(l=0.6012,a=0.6878)
2025-06-02 21:26:21,944 - INFO - Epoch 30: Train(l=0.4116,a=0.8932) | Val(l=0.5970,a=0.6948)
2025-06-02 21:26:22,148 - INFO - Epoch 31: Train(l=0.4106,a=0.8891) | Val(l=0.5915,a=0.6948)
2025-06-02 21:26:22,320 - INFO - Epoch 32: Train(l=0.4103,a=0.8932) | Val(l=0.5894,a=0.6925)
2025-06-02 21:26:22,492 - INFO - Epoch 33: Train(l=0.4075,a=0.8916) | Val(l=0.5851,a=0.6925)
2025-06-02 21:26:22,678 - INFO - Epoch 34: Train(l=0.4065,a=0.9020) | Val(l=0.5832,a=0.6948)
2025-06-02 21:26:22,831 - INFO - Epoch 35: Train(l=0.4019,a=0.8927) | Val(l=0.5824,a=0.6972)
2025-06-02 21:26:22,985 - INFO - Epoch 36: Train(l=0.4024,a=0.9009) | Val(l=0.5764,a=0.6972)
2025-06-02 21:26:23,136 - INFO - Epoch 37: Train(l=0.4038,a=0.8953) | Val(l=0.5750,a=0.6972)
2025-06-02 21:26:23,279 - INFO - Epoch 38: Train(l=0.4018,a=0.9004) | Val(l=0.5735,a=0.6995)
2025-06-02 21:26:23,437 - INFO - Epoch 39: Train(l=0.4000,a=0.8947) | Val(l=0.5748,a=0.6995)
2025-06-02 21:26:23,608 - INFO - Epoch 40: Train(l=0.4040,a=0.8922) | Val(l=0.5657,a=0.7019)
2025-06-02 21:26:23,763 - INFO - Epoch 41: Train(l=0.3994,a=0.8927) | Val(l=0.5740,a=0.6948)
2025-06-02 21:26:23,919 - INFO - Epoch 42: Train(l=0.3940,a=0.8922) | Val(l=0.5817,a=0.6925)
2025-06-02 21:26:24,104 - INFO - Epoch 43: Train(l=0.4009,a=0.8906) | Val(l=0.5841,a=0.6925)
2025-06-02 21:26:24,305 - INFO - Epoch 44: Train(l=0.3905,a=0.8989) | Val(l=0.5751,a=0.6972)
2025-06-02 21:26:24,511 - INFO - Epoch 45: Train(l=0.3961,a=0.9035) | Val(l=0.5367,a=0.7254)
2025-06-02 21:26:24,719 - INFO - Epoch 46: Train(l=0.3963,a=0.8906) | Val(l=0.5165,a=0.7394)
2025-06-02 21:26:24,944 - INFO - Epoch 47: Train(l=0.3884,a=0.9040) | Val(l=0.5097,a=0.7394)
2025-06-02 21:26:25,159 - INFO - Epoch 48: Train(l=0.3917,a=0.9051) | Val(l=0.5040,a=0.7394)
2025-06-02 21:26:25,373 - INFO - Epoch 49: Train(l=0.3884,a=0.9061) | Val(l=0.5008,a=0.7418)
2025-06-02 21:26:49,623 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 21:27:02,358 - INFO - Validation MSE: 0.165211
2025-06-02 21:29:05,463 - INFO - Training DBN...
2025-06-02 21:29:06,297 - INFO - Starting DBN pre-training...
2025-06-02 21:29:06,317 - INFO - Pre-training RBM layer 1/3
2025-06-02 21:29:07,606 - INFO -  RBM1 Epoch 0: Loss=1.5692
2025-06-02 21:29:22,841 - INFO -  RBM1 Epoch 10: Loss=1.3857
2025-06-02 21:29:43,187 - INFO -  RBM1 Epoch 20: Loss=1.2819
2025-06-02 21:29:53,566 - INFO -  RBM1 Epoch 30: Loss=1.2254
2025-06-02 21:29:57,165 - INFO -  RBM1 Epoch 40: Loss=1.1896
2025-06-02 21:30:01,159 - INFO -  RBM1 Epoch 50: Loss=1.1577
2025-06-02 21:30:04,687 - INFO -  RBM1 Epoch 60: Loss=1.1442
2025-06-02 21:30:08,397 - INFO -  RBM1 Epoch 70: Loss=1.1273
2025-06-02 21:30:12,303 - INFO -  RBM1 Epoch 80: Loss=1.1063
2025-06-02 21:30:15,228 - INFO -  RBM1 Epoch 90: Loss=1.1108
2025-06-02 21:30:17,603 - INFO - Pre-training RBM layer 2/3
2025-06-02 21:30:17,937 - INFO -  RBM2 Epoch 0: Loss=0.3001
2025-06-02 21:30:20,648 - INFO -  RBM2 Epoch 10: Loss=0.3002
2025-06-02 21:30:22,548 - INFO -  RBM2 Epoch 20: Loss=0.3003
2025-06-02 21:30:24,474 - INFO -  RBM2 Epoch 30: Loss=0.2999
2025-06-02 21:30:25,816 - INFO -  RBM2 Epoch 40: Loss=0.3002
2025-06-02 21:30:27,281 - INFO -  RBM2 Epoch 50: Loss=0.3005
2025-06-02 21:30:28,918 - INFO -  RBM2 Epoch 60: Loss=0.2998
2025-06-02 21:30:30,544 - INFO -  RBM2 Epoch 70: Loss=0.3000
2025-06-02 21:30:31,872 - INFO -  RBM2 Epoch 80: Loss=0.3001
2025-06-02 21:30:33,159 - INFO -  RBM2 Epoch 90: Loss=0.2995
2025-06-02 21:30:34,338 - INFO - Pre-training RBM layer 3/3
2025-06-02 21:30:34,404 - INFO -  RBM3 Epoch 0: Loss=0.2682
2025-06-02 21:30:35,044 - INFO -  RBM3 Epoch 10: Loss=0.2672
2025-06-02 21:30:35,906 - INFO -  RBM3 Epoch 20: Loss=0.2662
2025-06-02 21:30:36,972 - INFO -  RBM3 Epoch 30: Loss=0.2656
2025-06-02 21:30:38,047 - INFO -  RBM3 Epoch 40: Loss=0.2649
2025-06-02 21:30:39,165 - INFO -  RBM3 Epoch 50: Loss=0.2641
2025-06-02 21:30:40,034 - INFO -  RBM3 Epoch 60: Loss=0.2639
2025-06-02 21:30:40,912 - INFO -  RBM3 Epoch 70: Loss=0.2633
2025-06-02 21:30:41,905 - INFO -  RBM3 Epoch 80: Loss=0.2628
2025-06-02 21:30:42,684 - INFO -  RBM3 Epoch 90: Loss=0.2628
2025-06-02 21:30:43,204 - INFO - Starting DBN fine-tuning...
2025-06-02 21:31:02,178 - INFO - Epoch 0: Train(l=0.6542,a=0.5991) | Val(l=0.7828,a=0.0728)
2025-06-02 21:31:02,608 - INFO - Epoch 1: Train(l=0.5991,a=0.6723) | Val(l=0.8003,a=0.0728)
2025-06-02 21:31:02,966 - INFO - Epoch 2: Train(l=0.5671,a=0.6878) | Val(l=0.7341,a=0.0728)
2025-06-02 21:31:03,372 - INFO - Epoch 3: Train(l=0.5056,a=0.7343) | Val(l=0.6532,a=0.9272)
2025-06-02 21:31:03,698 - INFO - Epoch 4: Train(l=0.3872,a=0.8772) | Val(l=0.7391,a=0.0728)
2025-06-02 21:31:03,981 - INFO - Epoch 5: Train(l=0.2941,a=0.9298) | Val(l=1.0874,a=0.0728)
2025-06-02 21:31:04,317 - INFO - Epoch 6: Train(l=0.2285,a=0.9577) | Val(l=2.1284,a=0.0728)
2025-06-02 21:31:04,625 - INFO - Epoch 7: Train(l=0.1898,a=0.9690) | Val(l=3.7012,a=0.0728)
2025-06-02 21:31:04,896 - INFO - Epoch 8: Train(l=0.1652,a=0.9799) | Val(l=3.4589,a=0.0728)
2025-06-02 21:31:05,178 - INFO - Epoch 9: Train(l=0.1478,a=0.9845) | Val(l=3.5287,a=0.0728)
2025-06-02 21:31:05,576 - INFO - Epoch 10: Train(l=0.1386,a=0.9886) | Val(l=3.8631,a=0.0728)
2025-06-02 21:31:05,879 - INFO - Epoch 11: Train(l=0.1313,a=0.9912) | Val(l=4.4940,a=0.0728)
2025-06-02 21:31:06,137 - INFO - Epoch 12: Train(l=0.1209,a=0.9948) | Val(l=2.8136,a=0.0728)
2025-06-02 21:31:06,646 - INFO - Epoch 13: Train(l=0.1167,a=0.9954) | Val(l=2.7438,a=0.0892)
2025-06-02 21:31:07,075 - INFO - Epoch 14: Train(l=0.1162,a=0.9964) | Val(l=2.2304,a=0.1549)
2025-06-02 21:31:08,061 - INFO - Epoch 15: Train(l=0.1127,a=0.9943) | Val(l=2.3093,a=0.2019)
2025-06-02 21:31:08,363 - INFO - Epoch 16: Train(l=0.1111,a=0.9969) | Val(l=1.2685,a=0.5094)
2025-06-02 21:31:08,632 - INFO - Epoch 17: Train(l=0.1076,a=0.9979) | Val(l=0.9974,a=0.5939)
2025-06-02 21:31:08,845 - INFO - Epoch 18: Train(l=0.1056,a=0.9979) | Val(l=0.9200,a=0.6080)
2025-06-02 21:31:09,104 - INFO - Epoch 19: Train(l=0.1051,a=0.9985) | Val(l=0.7442,a=0.6643)
2025-06-02 21:31:09,307 - INFO - Epoch 20: Train(l=0.1043,a=0.9985) | Val(l=0.5769,a=0.7207)
2025-06-02 21:31:09,538 - INFO - Epoch 21: Train(l=0.1015,a=0.9979) | Val(l=0.5691,a=0.7277)
2025-06-02 21:31:09,733 - INFO - Epoch 22: Train(l=0.1007,a=0.9974) | Val(l=0.5321,a=0.7371)
2025-06-02 21:31:09,925 - INFO - Epoch 23: Train(l=0.1023,a=0.9969) | Val(l=0.4828,a=0.7535)
2025-06-02 21:31:10,121 - INFO - Epoch 24: Train(l=0.1006,a=0.9985) | Val(l=0.5061,a=0.7441)
2025-06-02 21:31:10,319 - INFO - Epoch 25: Train(l=0.1021,a=0.9974) | Val(l=0.5581,a=0.7347)
2025-06-02 21:31:10,553 - INFO - Epoch 26: Train(l=0.0996,a=0.9979) | Val(l=0.5024,a=0.7418)
2025-06-02 21:31:10,767 - INFO - Epoch 27: Train(l=0.0981,a=0.9990) | Val(l=0.5414,a=0.7347)
2025-06-02 21:31:10,951 - INFO - Epoch 28: Train(l=0.0979,a=0.9979) | Val(l=0.4830,a=0.7488)
2025-06-02 21:31:11,141 - INFO - Epoch 29: Train(l=0.1008,a=0.9990) | Val(l=0.4479,a=0.7911)
2025-06-02 21:31:11,370 - INFO - Epoch 30: Train(l=0.0968,a=0.9990) | Val(l=0.4303,a=0.8052)
2025-06-02 21:31:11,594 - INFO - Epoch 31: Train(l=0.0985,a=0.9979) | Val(l=0.4404,a=0.8005)
2025-06-02 21:31:11,792 - INFO - Epoch 32: Train(l=0.0969,a=0.9990) | Val(l=0.4391,a=0.8028)
2025-06-02 21:31:11,971 - INFO - Epoch 33: Train(l=0.0962,a=0.9985) | Val(l=0.4341,a=0.8052)
2025-06-02 21:31:12,160 - INFO - Epoch 34: Train(l=0.0956,a=0.9995) | Val(l=0.4079,a=0.8146)
2025-06-02 21:31:12,368 - INFO - Epoch 35: Train(l=0.0980,a=0.9990) | Val(l=0.4421,a=0.8028)
2025-06-02 21:31:12,586 - INFO - Epoch 36: Train(l=0.0983,a=0.9990) | Val(l=0.4508,a=0.7981)
2025-06-02 21:31:12,797 - INFO - Epoch 37: Train(l=0.0961,a=0.9979) | Val(l=0.4157,a=0.8122)
2025-06-02 21:31:12,994 - INFO - Epoch 38: Train(l=0.0946,a=0.9990) | Val(l=0.3964,a=0.8169)
2025-06-02 21:31:13,187 - INFO - Epoch 39: Train(l=0.0946,a=0.9985) | Val(l=0.3993,a=0.8216)
2025-06-02 21:31:13,399 - INFO - Epoch 40: Train(l=0.0966,a=0.9979) | Val(l=0.4333,a=0.8075)
2025-06-02 21:31:13,638 - INFO - Epoch 41: Train(l=0.0940,a=0.9985) | Val(l=0.4381,a=0.8075)
2025-06-02 21:31:13,837 - INFO - Epoch 42: Train(l=0.0943,a=0.9985) | Val(l=0.4199,a=0.8122)
2025-06-02 21:31:14,018 - INFO - Epoch 43: Train(l=0.0946,a=1.0000) | Val(l=0.4086,a=0.8169)
2025-06-02 21:31:14,213 - INFO - Epoch 44: Train(l=0.0924,a=0.9990) | Val(l=0.3827,a=0.8286)
2025-06-02 21:31:14,418 - INFO - Epoch 45: Train(l=0.0941,a=0.9985) | Val(l=0.3672,a=0.8357)
2025-06-02 21:31:14,625 - INFO - Epoch 46: Train(l=0.0916,a=0.9985) | Val(l=0.3628,a=0.8380)
2025-06-02 21:31:14,815 - INFO - Epoch 47: Train(l=0.0940,a=0.9979) | Val(l=0.3884,a=0.8239)
2025-06-02 21:31:14,993 - INFO - Epoch 48: Train(l=0.0935,a=0.9985) | Val(l=0.3796,a=0.8333)
2025-06-02 21:31:15,169 - INFO - Epoch 49: Train(l=0.0931,a=0.9995) | Val(l=0.3827,a=0.8310)
2025-06-02 21:31:15,359 - INFO - Epoch 50: Train(l=0.0921,a=0.9985) | Val(l=0.3853,a=0.8263)
2025-06-02 21:31:15,568 - INFO - Epoch 51: Train(l=0.0917,a=0.9995) | Val(l=0.3735,a=0.8357)
2025-06-02 21:31:15,756 - INFO - Epoch 52: Train(l=0.0909,a=0.9985) | Val(l=0.3592,a=0.8451)
2025-06-02 21:31:15,968 - INFO - Epoch 53: Train(l=0.0936,a=1.0000) | Val(l=0.3668,a=0.8380)
2025-06-02 21:31:16,159 - INFO - Epoch 54: Train(l=0.0941,a=0.9985) | Val(l=0.3701,a=0.8357)
2025-06-02 21:31:16,351 - INFO - Epoch 55: Train(l=0.0913,a=0.9995) | Val(l=0.3654,a=0.8404)
2025-06-02 21:31:16,554 - INFO - Epoch 56: Train(l=0.0922,a=0.9985) | Val(l=0.3576,a=0.8474)
2025-06-02 21:31:16,759 - INFO - Epoch 57: Train(l=0.0931,a=0.9985) | Val(l=0.3629,a=0.8427)
2025-06-02 21:31:16,934 - INFO - Epoch 58: Train(l=0.0937,a=0.9985) | Val(l=0.3592,a=0.8474)
2025-06-02 21:31:17,129 - INFO - Epoch 59: Train(l=0.0936,a=0.9990) | Val(l=0.3569,a=0.8451)
2025-06-02 21:31:17,319 - INFO - Epoch 60: Train(l=0.0929,a=0.9990) | Val(l=0.3659,a=0.8404)
2025-06-02 21:31:17,516 - INFO - Epoch 61: Train(l=0.0918,a=0.9985) | Val(l=0.3682,a=0.8404)
2025-06-02 21:31:17,706 - INFO - Epoch 62: Train(l=0.0929,a=0.9985) | Val(l=0.3656,a=0.8404)
2025-06-02 21:31:17,883 - INFO - Epoch 63: Train(l=0.0927,a=0.9990) | Val(l=0.3570,a=0.8474)
2025-06-02 21:31:18,068 - INFO - Epoch 64: Train(l=0.0901,a=0.9985) | Val(l=0.3536,a=0.8474)
2025-06-02 21:31:18,267 - INFO - Epoch 65: Train(l=0.0930,a=0.9979) | Val(l=0.3546,a=0.8498)
2025-06-02 21:31:18,464 - INFO - Epoch 66: Train(l=0.0927,a=0.9985) | Val(l=0.3468,a=0.8545)
2025-06-02 21:31:18,662 - INFO - Epoch 67: Train(l=0.0932,a=0.9979) | Val(l=0.3450,a=0.8592)
2025-06-02 21:31:18,831 - INFO - Epoch 68: Train(l=0.0919,a=0.9990) | Val(l=0.3431,a=0.8615)
2025-06-02 21:31:19,026 - INFO - Epoch 69: Train(l=0.0933,a=0.9985) | Val(l=0.3451,a=0.8615)
2025-06-02 21:31:19,257 - INFO - Epoch 70: Train(l=0.0914,a=0.9990) | Val(l=0.3469,a=0.8568)
2025-06-02 21:31:19,494 - INFO - Epoch 71: Train(l=0.0912,a=0.9995) | Val(l=0.3432,a=0.8615)
2025-06-02 21:31:19,706 - INFO - Epoch 72: Train(l=0.0915,a=0.9985) | Val(l=0.3458,a=0.8592)
2025-06-02 21:31:19,903 - INFO - Epoch 73: Train(l=0.0911,a=0.9990) | Val(l=0.3456,a=0.8615)
2025-06-02 21:31:20,101 - INFO - Epoch 74: Train(l=0.0913,a=0.9995) | Val(l=0.3367,a=0.8638)
2025-06-02 21:31:20,336 - INFO - Epoch 75: Train(l=0.0913,a=0.9995) | Val(l=0.3378,a=0.8638)
2025-06-02 21:31:20,586 - INFO - Epoch 76: Train(l=0.0909,a=0.9990) | Val(l=0.3451,a=0.8615)
2025-06-02 21:31:20,789 - INFO - Epoch 77: Train(l=0.0915,a=0.9990) | Val(l=0.3478,a=0.8568)
2025-06-02 21:31:20,979 - INFO - Epoch 78: Train(l=0.0907,a=0.9995) | Val(l=0.3427,a=0.8615)
2025-06-02 21:31:21,209 - INFO - Epoch 79: Train(l=0.0907,a=1.0000) | Val(l=0.3437,a=0.8615)
2025-06-02 21:31:21,446 - INFO - Epoch 80: Train(l=0.0919,a=0.9990) | Val(l=0.3435,a=0.8615)
2025-06-02 21:31:21,677 - INFO - Epoch 81: Train(l=0.0917,a=0.9985) | Val(l=0.3448,a=0.8615)
2025-06-02 21:31:21,904 - INFO - Epoch 82: Train(l=0.0913,a=0.9985) | Val(l=0.3417,a=0.8615)
2025-06-02 21:31:22,118 - INFO - Epoch 83: Train(l=0.0894,a=0.9990) | Val(l=0.3434,a=0.8615)
2025-06-02 21:31:22,366 - INFO - Epoch 84: Train(l=0.0926,a=0.9974) | Val(l=0.3364,a=0.8685)
2025-06-02 21:31:22,637 - INFO - Epoch 85: Train(l=0.0900,a=0.9995) | Val(l=0.3398,a=0.8638)
2025-06-02 21:31:22,880 - INFO - Epoch 86: Train(l=0.0899,a=0.9995) | Val(l=0.3425,a=0.8615)
2025-06-02 21:31:23,101 - INFO - Epoch 87: Train(l=0.0905,a=0.9990) | Val(l=0.3403,a=0.8638)
2025-06-02 21:31:23,355 - INFO - Epoch 88: Train(l=0.0929,a=0.9995) | Val(l=0.3381,a=0.8662)
2025-06-02 21:31:23,605 - INFO - Epoch 89: Train(l=0.0904,a=0.9995) | Val(l=0.3408,a=0.8615)
2025-06-02 21:31:23,831 - INFO - Epoch 90: Train(l=0.0926,a=0.9985) | Val(l=0.3407,a=0.8638)
2025-06-02 21:31:24,032 - INFO - Epoch 91: Train(l=0.0921,a=0.9985) | Val(l=0.3376,a=0.8685)
2025-06-02 21:31:24,243 - INFO - Epoch 92: Train(l=0.0913,a=0.9985) | Val(l=0.3375,a=0.8685)
2025-06-02 21:31:24,462 - INFO - Epoch 93: Train(l=0.0902,a=0.9990) | Val(l=0.3419,a=0.8615)
2025-06-02 21:31:24,659 - INFO - Epoch 94: Train(l=0.0917,a=1.0000) | Val(l=0.3346,a=0.8685)
2025-06-02 21:31:24,856 - INFO - Epoch 95: Train(l=0.0897,a=0.9995) | Val(l=0.3423,a=0.8615)
2025-06-02 21:31:25,075 - INFO - Epoch 96: Train(l=0.0915,a=0.9995) | Val(l=0.3385,a=0.8662)
2025-06-02 21:31:25,284 - INFO - Epoch 97: Train(l=0.0912,a=0.9985) | Val(l=0.3392,a=0.8662)
2025-06-02 21:31:25,479 - INFO - Epoch 98: Train(l=0.0916,a=0.9995) | Val(l=0.3396,a=0.8662)
2025-06-02 21:31:25,664 - INFO - Epoch 99: Train(l=0.0912,a=0.9995) | Val(l=0.3389,a=0.8685)
2025-06-02 21:31:35,677 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 21:32:09,559 - INFO - Validation MSE: 0.105442
2025-06-02 21:35:22,379 - INFO - Training DBN...
2025-06-02 21:35:22,743 - INFO - Starting DBN pre-training...
2025-06-02 21:35:22,744 - INFO - Pre-training RBM layer 1/3
2025-06-02 21:35:23,146 - INFO -  RBM1 Epoch 0: Loss=1.5677
2025-06-02 21:35:25,426 - INFO -  RBM1 Epoch 10: Loss=1.3858
2025-06-02 21:35:27,120 - INFO -  RBM1 Epoch 20: Loss=1.2836
2025-06-02 21:35:29,065 - INFO -  RBM1 Epoch 30: Loss=1.2205
2025-06-02 21:35:31,171 - INFO -  RBM1 Epoch 40: Loss=1.1885
2025-06-02 21:35:32,851 - INFO -  RBM1 Epoch 50: Loss=1.1627
2025-06-02 21:35:34,538 - INFO -  RBM1 Epoch 60: Loss=1.1433
2025-06-02 21:35:37,017 - INFO -  RBM1 Epoch 70: Loss=1.1285
2025-06-02 21:35:39,358 - INFO -  RBM1 Epoch 80: Loss=1.1173
2025-06-02 21:35:41,344 - INFO -  RBM1 Epoch 90: Loss=1.1089
2025-06-02 21:35:42,948 - INFO - Pre-training RBM layer 2/3
2025-06-02 21:35:43,189 - INFO -  RBM2 Epoch 0: Loss=0.3003
2025-06-02 21:35:44,021 - INFO -  RBM2 Epoch 10: Loss=0.3000
2025-06-02 21:35:45,011 - INFO -  RBM2 Epoch 20: Loss=0.3002
2025-06-02 21:35:46,537 - INFO -  RBM2 Epoch 30: Loss=0.2999
2025-06-02 21:35:47,859 - INFO -  RBM2 Epoch 40: Loss=0.3001
2025-06-02 21:35:49,158 - INFO -  RBM2 Epoch 50: Loss=0.3000
2025-06-02 21:35:50,379 - INFO -  RBM2 Epoch 60: Loss=0.3001
2025-06-02 21:35:52,043 - INFO -  RBM2 Epoch 70: Loss=0.3001
2025-06-02 21:35:53,483 - INFO -  RBM2 Epoch 80: Loss=0.3000
2025-06-02 21:35:54,653 - INFO -  RBM2 Epoch 90: Loss=0.2999
2025-06-02 21:35:55,567 - INFO - Pre-training RBM layer 3/3
2025-06-02 21:35:55,633 - INFO -  RBM3 Epoch 0: Loss=0.2683
2025-06-02 21:35:56,128 - INFO -  RBM3 Epoch 10: Loss=0.2674
2025-06-02 21:35:56,719 - INFO -  RBM3 Epoch 20: Loss=0.2666
2025-06-02 21:35:57,289 - INFO -  RBM3 Epoch 30: Loss=0.2659
2025-06-02 21:35:58,324 - INFO -  RBM3 Epoch 40: Loss=0.2651
2025-06-02 21:35:59,196 - INFO -  RBM3 Epoch 50: Loss=0.2645
2025-06-02 21:36:00,068 - INFO -  RBM3 Epoch 60: Loss=0.2641
2025-06-02 21:36:00,572 - INFO -  RBM3 Epoch 70: Loss=0.2637
2025-06-02 21:36:01,194 - INFO -  RBM3 Epoch 80: Loss=0.2629
2025-06-02 21:36:02,360 - INFO -  RBM3 Epoch 90: Loss=0.2627
2025-06-02 21:36:03,121 - INFO - Starting DBN fine-tuning...
2025-06-02 21:36:22,742 - INFO - Epoch 0: Train(l=0.6938,a=0.5738) | Val(l=0.7237,a=0.0728)
2025-06-02 21:36:22,947 - INFO - Epoch 1: Train(l=0.6315,a=0.6744) | Val(l=0.7254,a=0.0728)
2025-06-02 21:36:23,124 - INFO - Epoch 2: Train(l=0.6020,a=0.6832) | Val(l=0.6787,a=0.3826)
2025-06-02 21:36:23,289 - INFO - Epoch 3: Train(l=0.5425,a=0.7167) | Val(l=0.6240,a=0.9272)
2025-06-02 21:36:23,462 - INFO - Epoch 4: Train(l=0.4412,a=0.8328) | Val(l=0.6829,a=0.2441)
2025-06-02 21:36:23,638 - INFO - Epoch 5: Train(l=0.3166,a=0.9319) | Val(l=1.0260,a=0.0728)
2025-06-02 21:36:23,816 - INFO - Epoch 6: Train(l=0.2525,a=0.9494) | Val(l=1.6387,a=0.0728)
2025-06-02 21:36:24,013 - INFO - Epoch 7: Train(l=0.2069,a=0.9706) | Val(l=2.3196,a=0.0728)
2025-06-02 21:36:24,186 - INFO - Epoch 8: Train(l=0.1801,a=0.9799) | Val(l=2.2281,a=0.0728)
2025-06-02 21:36:24,371 - INFO - Epoch 9: Train(l=0.1646,a=0.9845) | Val(l=2.1920,a=0.0728)
2025-06-02 21:36:24,561 - INFO - Epoch 10: Train(l=0.1529,a=0.9907) | Val(l=2.2983,a=0.0728)
2025-06-02 21:36:24,732 - INFO - Epoch 11: Train(l=0.1468,a=0.9907) | Val(l=2.4893,a=0.0728)
2025-06-02 21:36:24,917 - INFO - Epoch 12: Train(l=0.1378,a=0.9933) | Val(l=1.4886,a=0.2887)
2025-06-02 21:36:25,098 - INFO - Epoch 13: Train(l=0.1317,a=0.9954) | Val(l=1.3406,a=0.4577)
2025-06-02 21:36:25,266 - INFO - Epoch 14: Train(l=0.1314,a=0.9948) | Val(l=0.9684,a=0.5798)
2025-06-02 21:36:25,448 - INFO - Epoch 15: Train(l=0.1246,a=0.9969) | Val(l=1.3740,a=0.5141)
2025-06-02 21:36:25,631 - INFO - Epoch 16: Train(l=0.1220,a=0.9948) | Val(l=0.7002,a=0.6854)
2025-06-02 21:36:25,811 - INFO - Epoch 17: Train(l=0.1212,a=0.9964) | Val(l=0.7426,a=0.6831)
2025-06-02 21:36:26,004 - INFO - Epoch 18: Train(l=0.1186,a=0.9954) | Val(l=0.6857,a=0.6972)
2025-06-02 21:36:26,180 - INFO - Epoch 19: Train(l=0.1209,a=0.9969) | Val(l=0.6498,a=0.7019)
2025-06-02 21:36:26,356 - INFO - Epoch 20: Train(l=0.1166,a=0.9979) | Val(l=0.5275,a=0.7324)
2025-06-02 21:36:26,545 - INFO - Epoch 21: Train(l=0.1143,a=0.9985) | Val(l=0.5224,a=0.7418)
2025-06-02 21:36:26,730 - INFO - Epoch 22: Train(l=0.1134,a=0.9979) | Val(l=0.5061,a=0.7512)
2025-06-02 21:36:26,910 - INFO - Epoch 23: Train(l=0.1158,a=0.9974) | Val(l=0.4553,a=0.8005)
2025-06-02 21:36:27,093 - INFO - Epoch 24: Train(l=0.1151,a=0.9969) | Val(l=0.4792,a=0.7864)
2025-06-02 21:36:27,312 - INFO - Epoch 25: Train(l=0.1115,a=0.9990) | Val(l=0.4748,a=0.7911)
2025-06-02 21:36:27,572 - INFO - Epoch 26: Train(l=0.1125,a=0.9979) | Val(l=0.4488,a=0.8005)
2025-06-02 21:36:27,849 - INFO - Epoch 27: Train(l=0.1107,a=0.9979) | Val(l=0.4321,a=0.8122)
2025-06-02 21:36:28,151 - INFO - Epoch 28: Train(l=0.1127,a=0.9985) | Val(l=0.5011,a=0.7582)
2025-06-02 21:36:28,368 - INFO - Epoch 29: Train(l=0.1095,a=0.9985) | Val(l=0.4737,a=0.7934)
2025-06-02 21:36:28,565 - INFO - Epoch 30: Train(l=0.1091,a=0.9974) | Val(l=0.4402,a=0.8052)
2025-06-02 21:36:28,790 - INFO - Epoch 31: Train(l=0.1105,a=0.9990) | Val(l=0.4817,a=0.7793)
2025-06-02 21:36:29,067 - INFO - Epoch 32: Train(l=0.1079,a=0.9985) | Val(l=0.4249,a=0.8122)
2025-06-02 21:36:29,267 - INFO - Epoch 33: Train(l=0.1075,a=0.9979) | Val(l=0.3947,a=0.8380)
2025-06-02 21:36:29,471 - INFO - Epoch 34: Train(l=0.1094,a=0.9995) | Val(l=0.3933,a=0.8380)
2025-06-02 21:36:29,648 - INFO - Epoch 35: Train(l=0.1073,a=0.9990) | Val(l=0.4137,a=0.8263)
2025-06-02 21:36:29,807 - INFO - Epoch 36: Train(l=0.1083,a=0.9979) | Val(l=0.4120,a=0.8333)
2025-06-02 21:36:29,984 - INFO - Epoch 37: Train(l=0.1060,a=0.9979) | Val(l=0.4000,a=0.8380)
2025-06-02 21:36:30,172 - INFO - Epoch 38: Train(l=0.1070,a=0.9985) | Val(l=0.3905,a=0.8380)
2025-06-02 21:36:30,347 - INFO - Epoch 39: Train(l=0.1075,a=0.9985) | Val(l=0.4016,a=0.8357)
2025-06-02 21:36:30,525 - INFO - Epoch 40: Train(l=0.1049,a=0.9990) | Val(l=0.4017,a=0.8357)
2025-06-02 21:36:30,704 - INFO - Epoch 41: Train(l=0.1042,a=0.9990) | Val(l=0.4053,a=0.8357)
2025-06-02 21:36:30,884 - INFO - Epoch 42: Train(l=0.1035,a=0.9990) | Val(l=0.3966,a=0.8357)
2025-06-02 21:36:31,261 - INFO - Epoch 43: Train(l=0.1044,a=0.9979) | Val(l=0.3777,a=0.8380)
2025-06-02 21:36:31,458 - INFO - Epoch 44: Train(l=0.1035,a=0.9985) | Val(l=0.3694,a=0.8380)
2025-06-02 21:36:31,657 - INFO - Epoch 45: Train(l=0.1077,a=0.9979) | Val(l=0.3600,a=0.8404)
2025-06-02 21:36:31,823 - INFO - Epoch 46: Train(l=0.1049,a=0.9995) | Val(l=0.3578,a=0.8404)
2025-06-02 21:36:32,008 - INFO - Epoch 47: Train(l=0.1068,a=0.9985) | Val(l=0.3559,a=0.8404)
2025-06-02 21:36:32,199 - INFO - Epoch 48: Train(l=0.1027,a=0.9995) | Val(l=0.3509,a=0.8474)
2025-06-02 21:36:32,375 - INFO - Epoch 49: Train(l=0.1031,a=0.9995) | Val(l=0.3539,a=0.8427)
2025-06-02 21:36:32,554 - INFO - Epoch 50: Train(l=0.1037,a=0.9990) | Val(l=0.3603,a=0.8380)
2025-06-02 21:36:32,730 - INFO - Epoch 51: Train(l=0.1028,a=0.9990) | Val(l=0.3559,a=0.8404)
2025-06-02 21:36:32,907 - INFO - Epoch 52: Train(l=0.1019,a=0.9985) | Val(l=0.3628,a=0.8380)
2025-06-02 21:36:33,120 - INFO - Epoch 53: Train(l=0.1021,a=0.9995) | Val(l=0.3472,a=0.8498)
2025-06-02 21:36:33,302 - INFO - Epoch 54: Train(l=0.1049,a=0.9990) | Val(l=0.3354,a=0.8592)
2025-06-02 21:36:33,503 - INFO - Epoch 55: Train(l=0.1043,a=0.9995) | Val(l=0.3334,a=0.8592)
2025-06-02 21:36:33,711 - INFO - Epoch 56: Train(l=0.1020,a=0.9995) | Val(l=0.3365,a=0.8592)
2025-06-02 21:36:33,892 - INFO - Epoch 57: Train(l=0.1009,a=0.9995) | Val(l=0.3389,a=0.8592)
2025-06-02 21:36:34,097 - INFO - Epoch 58: Train(l=0.1022,a=0.9985) | Val(l=0.3356,a=0.8592)
2025-06-02 21:36:34,280 - INFO - Epoch 59: Train(l=0.1009,a=0.9995) | Val(l=0.3356,a=0.8592)
2025-06-02 21:36:34,480 - INFO - Epoch 60: Train(l=0.1023,a=0.9990) | Val(l=0.3287,a=0.8685)
2025-06-02 21:36:34,666 - INFO - Epoch 61: Train(l=0.1006,a=0.9995) | Val(l=0.3297,a=0.8685)
2025-06-02 21:36:34,845 - INFO - Epoch 62: Train(l=0.1034,a=0.9995) | Val(l=0.3301,a=0.8685)
2025-06-02 21:36:35,038 - INFO - Epoch 63: Train(l=0.1032,a=0.9979) | Val(l=0.3292,a=0.8685)
2025-06-02 21:36:35,230 - INFO - Epoch 64: Train(l=0.1024,a=0.9995) | Val(l=0.3249,a=0.8685)
2025-06-02 21:36:35,417 - INFO - Epoch 65: Train(l=0.1010,a=0.9985) | Val(l=0.3257,a=0.8685)
2025-06-02 21:36:35,603 - INFO - Epoch 66: Train(l=0.1033,a=0.9985) | Val(l=0.3201,a=0.8756)
2025-06-02 21:36:35,800 - INFO - Epoch 67: Train(l=0.1033,a=0.9985) | Val(l=0.3222,a=0.8732)
2025-06-02 21:36:36,001 - INFO - Epoch 68: Train(l=0.1014,a=0.9995) | Val(l=0.3291,a=0.8685)
2025-06-02 21:36:36,225 - INFO - Epoch 69: Train(l=0.1015,a=0.9995) | Val(l=0.3267,a=0.8685)
2025-06-02 21:36:36,458 - INFO - Epoch 70: Train(l=0.1033,a=0.9990) | Val(l=0.3310,a=0.8685)
2025-06-02 21:36:36,687 - INFO - Epoch 71: Train(l=0.1005,a=1.0000) | Val(l=0.3235,a=0.8732)
2025-06-02 21:36:36,904 - INFO - Epoch 72: Train(l=0.1023,a=0.9990) | Val(l=0.3262,a=0.8685)
2025-06-02 21:36:37,160 - INFO - Epoch 73: Train(l=0.0999,a=0.9990) | Val(l=0.3251,a=0.8709)
2025-06-02 21:36:37,367 - INFO - Epoch 74: Train(l=0.1007,a=0.9995) | Val(l=0.3213,a=0.8756)
2025-06-02 21:36:37,597 - INFO - Epoch 75: Train(l=0.1004,a=0.9995) | Val(l=0.3205,a=0.8756)
2025-06-02 21:36:37,805 - INFO - Epoch 76: Train(l=0.1014,a=0.9995) | Val(l=0.3212,a=0.8756)
2025-06-02 21:36:38,024 - INFO - Epoch 77: Train(l=0.1008,a=0.9990) | Val(l=0.3169,a=0.8756)
2025-06-02 21:36:38,237 - INFO - Epoch 78: Train(l=0.1008,a=0.9995) | Val(l=0.3177,a=0.8756)
2025-06-02 21:36:38,421 - INFO - Epoch 79: Train(l=0.0999,a=0.9995) | Val(l=0.3155,a=0.8803)
2025-06-02 21:36:38,602 - INFO - Epoch 80: Train(l=0.1026,a=0.9990) | Val(l=0.3191,a=0.8756)
2025-06-02 21:36:38,771 - INFO - Epoch 81: Train(l=0.0991,a=0.9995) | Val(l=0.3212,a=0.8756)
2025-06-02 21:36:38,963 - INFO - Epoch 82: Train(l=0.1007,a=0.9995) | Val(l=0.3160,a=0.8756)
2025-06-02 21:36:39,156 - INFO - Epoch 83: Train(l=0.1012,a=0.9995) | Val(l=0.3195,a=0.8756)
2025-06-02 21:36:39,335 - INFO - Epoch 84: Train(l=0.1021,a=0.9990) | Val(l=0.3242,a=0.8732)
2025-06-02 21:36:39,510 - INFO - Epoch 85: Train(l=0.1004,a=0.9990) | Val(l=0.3224,a=0.8756)
2025-06-02 21:36:39,690 - INFO - Epoch 86: Train(l=0.1027,a=1.0000) | Val(l=0.3205,a=0.8756)
2025-06-02 21:36:39,882 - INFO - Epoch 87: Train(l=0.1009,a=0.9995) | Val(l=0.3201,a=0.8756)
2025-06-02 21:36:40,085 - INFO - Epoch 88: Train(l=0.1008,a=0.9990) | Val(l=0.3204,a=0.8756)
2025-06-02 21:36:40,276 - INFO - Epoch 89: Train(l=0.1004,a=0.9995) | Val(l=0.3172,a=0.8756)
2025-06-02 21:36:40,462 - INFO - Epoch 90: Train(l=0.1003,a=0.9990) | Val(l=0.3186,a=0.8756)
2025-06-02 21:36:40,636 - INFO - Epoch 91: Train(l=0.1013,a=0.9990) | Val(l=0.3212,a=0.8756)
2025-06-02 21:36:40,814 - INFO - Epoch 92: Train(l=0.1034,a=0.9995) | Val(l=0.3139,a=0.8803)
2025-06-02 21:36:40,999 - INFO - Epoch 93: Train(l=0.1006,a=0.9990) | Val(l=0.3176,a=0.8756)
2025-06-02 21:36:41,204 - INFO - Epoch 94: Train(l=0.1001,a=0.9985) | Val(l=0.3169,a=0.8756)
2025-06-02 21:36:41,392 - INFO - Epoch 95: Train(l=0.1047,a=0.9985) | Val(l=0.3206,a=0.8756)
2025-06-02 21:36:41,580 - INFO - Epoch 96: Train(l=0.1008,a=0.9985) | Val(l=0.3230,a=0.8756)
2025-06-02 21:36:41,758 - INFO - Epoch 97: Train(l=0.1002,a=0.9995) | Val(l=0.3169,a=0.8756)
2025-06-02 21:36:41,941 - INFO - Epoch 98: Train(l=0.1015,a=0.9995) | Val(l=0.3150,a=0.8803)
2025-06-02 21:36:42,139 - INFO - Epoch 99: Train(l=0.1027,a=0.9990) | Val(l=0.3143,a=0.8803)
2025-06-02 21:36:53,106 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 21:37:29,689 - INFO - Validation MSE: 0.095600
2025-06-02 21:38:52,941 - INFO - Training DBN...
2025-06-02 21:38:53,664 - INFO - Starting DBN pre-training...
2025-06-02 21:38:53,665 - INFO - Pre-training RBM layer 1/3
2025-06-02 21:38:54,230 - INFO -  RBM1 Epoch 0: Loss=1.5626
2025-06-02 21:38:55,602 - INFO -  RBM1 Epoch 10: Loss=1.1497
2025-06-02 21:38:57,456 - INFO -  RBM1 Epoch 20: Loss=1.1047
2025-06-02 21:38:59,012 - INFO -  RBM1 Epoch 30: Loss=1.0967
2025-06-02 21:39:00,546 - INFO -  RBM1 Epoch 40: Loss=1.0908
2025-06-02 21:39:02,748 - INFO -  RBM1 Epoch 50: Loss=1.0932
2025-06-02 21:39:04,815 - INFO -  RBM1 Epoch 60: Loss=1.1042
2025-06-02 21:39:06,440 - INFO -  RBM1 Epoch 70: Loss=1.1091
2025-06-02 21:39:08,138 - INFO -  RBM1 Epoch 80: Loss=1.1211
2025-06-02 21:39:10,019 - INFO -  RBM1 Epoch 90: Loss=1.1152
2025-06-02 21:39:11,395 - INFO - Pre-training RBM layer 2/3
2025-06-02 21:39:11,581 - INFO -  RBM2 Epoch 0: Loss=0.4341
2025-06-02 21:39:12,435 - INFO -  RBM2 Epoch 10: Loss=0.4101
2025-06-02 21:39:13,831 - INFO -  RBM2 Epoch 20: Loss=0.4008
2025-06-02 21:39:15,423 - INFO -  RBM2 Epoch 30: Loss=0.3894
2025-06-02 21:39:16,680 - INFO -  RBM2 Epoch 40: Loss=0.3821
2025-06-02 21:39:18,083 - INFO -  RBM2 Epoch 50: Loss=0.3738
2025-06-02 21:39:20,766 - INFO -  RBM2 Epoch 60: Loss=0.3683
2025-06-02 21:39:22,573 - INFO -  RBM2 Epoch 70: Loss=0.3634
2025-06-02 21:39:23,777 - INFO -  RBM2 Epoch 80: Loss=0.3600
2025-06-02 21:39:24,655 - INFO -  RBM2 Epoch 90: Loss=0.3574
2025-06-02 21:39:25,434 - INFO - Pre-training RBM layer 3/3
2025-06-02 21:39:25,512 - INFO -  RBM3 Epoch 0: Loss=0.3849
2025-06-02 21:39:25,927 - INFO -  RBM3 Epoch 10: Loss=0.2457
2025-06-02 21:39:26,322 - INFO -  RBM3 Epoch 20: Loss=0.1997
2025-06-02 21:39:26,693 - INFO -  RBM3 Epoch 30: Loss=0.1928
2025-06-02 21:39:27,326 - INFO -  RBM3 Epoch 40: Loss=0.1894
2025-06-02 21:39:27,786 - INFO -  RBM3 Epoch 50: Loss=0.1886
2025-06-02 21:39:28,219 - INFO -  RBM3 Epoch 60: Loss=0.1878
2025-06-02 21:39:28,639 - INFO -  RBM3 Epoch 70: Loss=0.1859
2025-06-02 21:39:29,103 - INFO -  RBM3 Epoch 80: Loss=0.1871
2025-06-02 21:39:29,576 - INFO -  RBM3 Epoch 90: Loss=0.1863
2025-06-02 21:39:30,169 - INFO - Starting DBN fine-tuning...
2025-06-02 21:39:48,608 - INFO - Epoch 0: Train(l=0.7048,a=0.5593) | Val(l=0.7223,a=0.0728)
2025-06-02 21:39:48,794 - INFO - Epoch 1: Train(l=0.6859,a=0.6151) | Val(l=0.6948,a=0.4671)
2025-06-02 21:39:48,965 - INFO - Epoch 2: Train(l=0.6663,a=0.6378) | Val(l=0.6461,a=0.6338)
2025-06-02 21:39:49,260 - INFO - Epoch 3: Train(l=0.6461,a=0.6517) | Val(l=0.6143,a=0.8122)
2025-06-02 21:39:49,520 - INFO - Epoch 4: Train(l=0.6422,a=0.6527) | Val(l=0.6004,a=0.8052)
2025-06-02 21:39:49,720 - INFO - Epoch 5: Train(l=0.6376,a=0.6620) | Val(l=0.5920,a=0.7582)
2025-06-02 21:39:49,912 - INFO - Epoch 6: Train(l=0.6298,a=0.6672) | Val(l=0.5889,a=0.6995)
2025-06-02 21:39:50,098 - INFO - Epoch 7: Train(l=0.6326,a=0.6574) | Val(l=0.5798,a=0.6972)
2025-06-02 21:39:50,267 - INFO - Epoch 8: Train(l=0.6259,a=0.6662) | Val(l=0.5799,a=0.6784)
2025-06-02 21:39:50,424 - INFO - Epoch 9: Train(l=0.6251,a=0.6672) | Val(l=0.5928,a=0.6690)
2025-06-02 21:39:50,600 - INFO - Epoch 10: Train(l=0.6195,a=0.6698) | Val(l=0.6072,a=0.6714)
2025-06-02 21:39:50,770 - INFO - Epoch 11: Train(l=0.6233,a=0.6713) | Val(l=0.6101,a=0.6737)
2025-06-02 21:39:50,950 - INFO - Epoch 12: Train(l=0.6276,a=0.6651) | Val(l=0.6094,a=0.6761)
2025-06-02 21:39:51,136 - INFO - Epoch 13: Train(l=0.6172,a=0.6739) | Val(l=0.5490,a=0.7465)
2025-06-02 21:39:51,354 - INFO - Epoch 14: Train(l=0.6201,a=0.6620) | Val(l=0.5586,a=0.7113)
2025-06-02 21:39:51,583 - INFO - Epoch 15: Train(l=0.6176,a=0.6692) | Val(l=0.5087,a=0.8028)
2025-06-02 21:39:51,875 - INFO - Epoch 16: Train(l=0.6089,a=0.6729) | Val(l=0.5616,a=0.7089)
2025-06-02 21:39:52,095 - INFO - Epoch 17: Train(l=0.5988,a=0.6821) | Val(l=0.7067,a=0.5282)
2025-06-02 21:39:52,301 - INFO - Epoch 18: Train(l=0.5800,a=0.7023) | Val(l=0.8587,a=0.5399)
2025-06-02 21:39:52,519 - INFO - Epoch 19: Train(l=0.5414,a=0.7394) | Val(l=0.7379,a=0.6573)
2025-06-02 21:39:52,726 - INFO - Epoch 20: Train(l=0.5039,a=0.7874) | Val(l=0.5699,a=0.6854)
2025-06-02 21:39:52,926 - INFO - Epoch 21: Train(l=0.4581,a=0.8256) | Val(l=0.5548,a=0.7183)
2025-06-02 21:39:53,098 - INFO - Epoch 22: Train(l=0.4228,a=0.8467) | Val(l=0.8177,a=0.5798)
2025-06-02 21:39:53,279 - INFO - Epoch 23: Train(l=0.3861,a=0.8607) | Val(l=1.1321,a=0.3451)
2025-06-02 21:39:53,435 - INFO - Epoch 24: Train(l=0.3648,a=0.8653) | Val(l=0.6621,a=0.6831)
2025-06-02 21:39:53,602 - INFO - Epoch 25: Train(l=0.3430,a=0.8772) | Val(l=0.5557,a=0.7371)
2025-06-02 21:39:53,786 - INFO - Epoch 26: Train(l=0.3254,a=0.8818) | Val(l=0.6173,a=0.7254)
2025-06-02 21:39:53,967 - INFO - Epoch 27: Train(l=0.3218,a=0.8839) | Val(l=0.4879,a=0.7887)
2025-06-02 21:39:54,152 - INFO - Epoch 28: Train(l=0.3139,a=0.8916) | Val(l=0.5322,a=0.7746)
2025-06-02 21:39:54,313 - INFO - Epoch 29: Train(l=0.3131,a=0.8885) | Val(l=0.5355,a=0.7793)
2025-06-02 21:39:54,481 - INFO - Epoch 30: Train(l=0.3141,a=0.8870) | Val(l=0.5513,a=0.7793)
2025-06-02 21:39:54,643 - INFO - Epoch 31: Train(l=0.3136,a=0.8849) | Val(l=0.5443,a=0.7840)
2025-06-02 21:39:54,835 - INFO - Epoch 32: Train(l=0.3122,a=0.8942) | Val(l=0.5299,a=0.7793)
2025-06-02 21:39:55,015 - INFO - Epoch 33: Train(l=0.3103,a=0.8937) | Val(l=0.5676,a=0.7488)
2025-06-02 21:39:55,184 - INFO - Epoch 34: Train(l=0.3073,a=0.8927) | Val(l=0.5320,a=0.7700)
2025-06-02 21:39:55,343 - INFO - Epoch 35: Train(l=0.2993,a=0.8932) | Val(l=0.4671,a=0.7911)
2025-06-02 21:39:55,502 - INFO - Epoch 36: Train(l=0.2931,a=0.8983) | Val(l=0.4497,a=0.8005)
2025-06-02 21:39:55,667 - INFO - Epoch 37: Train(l=0.2879,a=0.9009) | Val(l=0.4279,a=0.8146)
2025-06-02 21:39:55,855 - INFO - Epoch 38: Train(l=0.2759,a=0.9128) | Val(l=0.7865,a=0.5023)
2025-06-02 21:39:56,028 - INFO - Epoch 39: Train(l=0.2595,a=0.9164) | Val(l=0.6125,a=0.7441)
2025-06-02 21:39:56,207 - INFO - Epoch 40: Train(l=0.2507,a=0.9231) | Val(l=0.6759,a=0.7324)
2025-06-02 21:39:56,385 - INFO - Epoch 41: Train(l=0.2481,a=0.9154) | Val(l=0.8955,a=0.5141)
2025-06-02 21:39:56,565 - INFO - Epoch 42: Train(l=0.2354,a=0.9288) | Val(l=0.9333,a=0.4812)
2025-06-02 21:39:56,760 - INFO - Epoch 43: Train(l=0.2227,a=0.9303) | Val(l=0.8165,a=0.4836)
2025-06-02 21:39:57,008 - INFO - Epoch 44: Train(l=0.2133,a=0.9360) | Val(l=0.7684,a=0.6009)
2025-06-02 21:39:57,222 - INFO - Epoch 45: Train(l=0.2033,a=0.9396) | Val(l=0.5146,a=0.7958)
2025-06-02 21:39:57,485 - INFO - Epoch 46: Train(l=0.2031,a=0.9381) | Val(l=0.4748,a=0.8028)
2025-06-02 21:39:57,703 - INFO - Epoch 47: Train(l=0.1966,a=0.9474) | Val(l=0.5410,a=0.7911)
2025-06-02 21:39:57,909 - INFO - Epoch 48: Train(l=0.1907,a=0.9479) | Val(l=0.4804,a=0.8146)
2025-06-02 21:39:58,134 - INFO - Epoch 49: Train(l=0.1906,a=0.9499) | Val(l=0.4622,a=0.8357)
2025-06-02 21:39:58,328 - INFO - Epoch 50: Train(l=0.1914,a=0.9443) | Val(l=0.4715,a=0.8357)
2025-06-02 21:39:58,580 - INFO - Epoch 51: Train(l=0.1903,a=0.9484) | Val(l=0.4738,a=0.8357)
2025-06-02 21:39:58,786 - INFO - Epoch 52: Train(l=0.1866,a=0.9474) | Val(l=0.4497,a=0.8451)
2025-06-02 21:39:58,985 - INFO - Epoch 53: Train(l=0.1854,a=0.9458) | Val(l=0.4738,a=0.8169)
2025-06-02 21:39:59,148 - INFO - Epoch 54: Train(l=0.1877,a=0.9499) | Val(l=0.6045,a=0.7723)
2025-06-02 21:39:59,312 - INFO - Epoch 55: Train(l=0.1837,a=0.9494) | Val(l=0.4796,a=0.8216)
2025-06-02 21:39:59,517 - INFO - Epoch 56: Train(l=0.1823,a=0.9499) | Val(l=0.3823,a=0.8709)
2025-06-02 21:39:59,794 - INFO - Epoch 57: Train(l=0.1852,a=0.9474) | Val(l=0.6945,a=0.6995)
2025-06-02 21:40:00,014 - INFO - Epoch 58: Train(l=0.1685,a=0.9582) | Val(l=0.9064,a=0.5376)
2025-06-02 21:40:00,200 - INFO - Epoch 59: Train(l=0.1631,a=0.9592) | Val(l=0.8610,a=0.5751)
2025-06-02 21:40:00,383 - INFO - Epoch 60: Train(l=0.1559,a=0.9623) | Val(l=1.3237,a=0.4671)
2025-06-02 21:40:00,562 - INFO - Epoch 61: Train(l=0.1561,a=0.9649) | Val(l=1.2788,a=0.4906)
2025-06-02 21:40:00,739 - INFO - Epoch 62: Train(l=0.1450,a=0.9634) | Val(l=1.4513,a=0.4343)
2025-06-02 21:40:00,962 - INFO - Epoch 63: Train(l=0.1420,a=0.9706) | Val(l=0.9525,a=0.6103)
2025-06-02 21:40:01,162 - INFO - Epoch 64: Train(l=0.1361,a=0.9690) | Val(l=1.0547,a=0.5469)
2025-06-02 21:40:01,369 - INFO - Epoch 65: Train(l=0.1315,a=0.9696) | Val(l=0.7311,a=0.7512)
2025-06-02 21:40:01,610 - INFO - Epoch 66: Train(l=0.1281,a=0.9685) | Val(l=0.5350,a=0.8099)
2025-06-02 21:40:01,853 - INFO - Epoch 67: Train(l=0.1241,a=0.9696) | Val(l=0.3825,a=0.8615)
2025-06-02 21:40:02,109 - INFO - Epoch 68: Train(l=0.1223,a=0.9742) | Val(l=0.4373,a=0.8451)
2025-06-02 21:40:02,321 - INFO - Epoch 69: Train(l=0.1236,a=0.9727) | Val(l=0.4687,a=0.8404)
2025-06-02 21:40:02,593 - INFO - Epoch 70: Train(l=0.1208,a=0.9706) | Val(l=0.4442,a=0.8498)
2025-06-02 21:40:02,889 - INFO - Epoch 71: Train(l=0.1216,a=0.9727) | Val(l=0.4234,a=0.8592)
2025-06-02 21:40:03,143 - INFO - Epoch 72: Train(l=0.1224,a=0.9737) | Val(l=0.4532,a=0.8451)
2025-06-02 21:40:03,364 - INFO - Epoch 73: Train(l=0.1189,a=0.9716) | Val(l=0.4389,a=0.8427)
2025-06-02 21:40:03,540 - INFO - Epoch 74: Train(l=0.1199,a=0.9752) | Val(l=0.7118,a=0.7700)
2025-06-02 21:40:03,754 - INFO - Epoch 75: Train(l=0.1184,a=0.9732) | Val(l=0.7797,a=0.7535)
2025-06-02 21:40:03,959 - INFO - Epoch 76: Train(l=0.1174,a=0.9711) | Val(l=0.8618,a=0.7512)
2025-06-02 21:40:03,959 - INFO - Early stopping.
2025-06-02 21:40:14,286 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 21:40:30,435 - INFO - Validation MSE: 0.234206
2025-06-02 21:43:14,170 - INFO - Training DBN...
2025-06-02 21:43:14,970 - INFO - Starting DBN pre-training...
2025-06-02 21:43:14,972 - INFO - Pre-training RBM layer 1/3
2025-06-02 21:43:15,702 - INFO -  RBM1 Epoch 0: Loss=1.5684
2025-06-02 21:43:17,942 - INFO -  RBM1 Epoch 10: Loss=1.3940
2025-06-02 21:43:19,934 - INFO -  RBM1 Epoch 20: Loss=1.2857
2025-06-02 21:43:23,930 - INFO -  RBM1 Epoch 30: Loss=1.2393
2025-06-02 21:43:26,134 - INFO -  RBM1 Epoch 40: Loss=1.1887
2025-06-02 21:43:28,045 - INFO -  RBM1 Epoch 50: Loss=1.1560
2025-06-02 21:43:30,374 - INFO -  RBM1 Epoch 60: Loss=1.1453
2025-06-02 21:43:31,996 - INFO -  RBM1 Epoch 70: Loss=1.1315
2025-06-02 21:43:33,633 - INFO -  RBM1 Epoch 80: Loss=1.1265
2025-06-02 21:43:36,612 - INFO -  RBM1 Epoch 90: Loss=1.1043
2025-06-02 21:43:38,975 - INFO - Pre-training RBM layer 2/3
2025-06-02 21:43:39,237 - INFO -  RBM2 Epoch 0: Loss=0.3000
2025-06-02 21:43:41,037 - INFO -  RBM2 Epoch 10: Loss=0.3010
2025-06-02 21:43:42,786 - INFO -  RBM2 Epoch 20: Loss=0.3003
2025-06-02 21:43:44,032 - INFO -  RBM2 Epoch 30: Loss=0.3005
2025-06-02 21:43:45,979 - INFO -  RBM2 Epoch 40: Loss=0.3002
2025-06-02 21:43:47,240 - INFO -  RBM2 Epoch 50: Loss=0.2989
2025-06-02 21:43:48,335 - INFO -  RBM2 Epoch 60: Loss=0.2995
2025-06-02 21:43:49,570 - INFO -  RBM2 Epoch 70: Loss=0.2995
2025-06-02 21:43:50,737 - INFO -  RBM2 Epoch 80: Loss=0.2996
2025-06-02 21:43:52,325 - INFO -  RBM2 Epoch 90: Loss=0.2997
2025-06-02 21:43:53,374 - INFO - Pre-training RBM layer 3/3
2025-06-02 21:43:53,433 - INFO -  RBM3 Epoch 0: Loss=0.2682
2025-06-02 21:43:53,929 - INFO -  RBM3 Epoch 10: Loss=0.2675
2025-06-02 21:43:54,639 - INFO -  RBM3 Epoch 20: Loss=0.2666
2025-06-02 21:43:56,225 - INFO -  RBM3 Epoch 30: Loss=0.2659
2025-06-02 21:43:57,632 - INFO -  RBM3 Epoch 40: Loss=0.2650
2025-06-02 21:43:58,364 - INFO -  RBM3 Epoch 50: Loss=0.2646
2025-06-02 21:43:59,129 - INFO -  RBM3 Epoch 60: Loss=0.2640
2025-06-02 21:43:59,615 - INFO -  RBM3 Epoch 70: Loss=0.2635
2025-06-02 21:44:00,124 - INFO -  RBM3 Epoch 80: Loss=0.2631
2025-06-02 21:44:00,631 - INFO -  RBM3 Epoch 90: Loss=0.2627
2025-06-02 21:44:01,074 - INFO - Starting DBN fine-tuning...
2025-06-02 21:44:22,123 - INFO - Epoch 0: Train(l=0.6663,a=0.6146) | Val(l=0.7416,a=0.9272)
2025-06-02 21:44:22,395 - INFO - Epoch 1: Train(l=0.6123,a=0.6878) | Val(l=0.7297,a=0.9272)
2025-06-02 21:44:22,646 - INFO - Epoch 2: Train(l=0.5820,a=0.7012) | Val(l=0.6866,a=0.9272)
2025-06-02 21:44:22,881 - INFO - Epoch 3: Train(l=0.5114,a=0.7399) | Val(l=0.6487,a=0.9272)
2025-06-02 21:44:23,118 - INFO - Epoch 4: Train(l=0.3847,a=0.8885) | Val(l=0.8291,a=0.9272)
2025-06-02 21:44:23,349 - INFO - Epoch 5: Train(l=0.2990,a=0.9381) | Val(l=1.5138,a=0.9272)
2025-06-02 21:44:23,576 - INFO - Epoch 6: Train(l=0.2431,a=0.9634) | Val(l=2.6634,a=0.9272)
2025-06-02 21:44:23,800 - INFO - Epoch 7: Train(l=0.2041,a=0.9732) | Val(l=3.8813,a=0.9272)
2025-06-02 21:44:24,096 - INFO - Epoch 8: Train(l=0.1813,a=0.9804) | Val(l=3.4539,a=0.9272)
2025-06-02 21:44:24,447 - INFO - Epoch 9: Train(l=0.1688,a=0.9825) | Val(l=3.0927,a=0.9272)
2025-06-02 21:44:25,240 - INFO - Epoch 10: Train(l=0.1581,a=0.9856) | Val(l=3.1316,a=0.9272)
2025-06-02 21:44:25,594 - INFO - Epoch 11: Train(l=0.1497,a=0.9917) | Val(l=3.0179,a=0.9272)
2025-06-02 21:44:25,865 - INFO - Epoch 12: Train(l=0.1445,a=0.9923) | Val(l=2.2405,a=0.9272)
2025-06-02 21:44:26,125 - INFO - Epoch 13: Train(l=0.1397,a=0.9959) | Val(l=1.7280,a=0.9272)
2025-06-02 21:44:26,412 - INFO - Epoch 14: Train(l=0.1334,a=0.9954) | Val(l=1.3408,a=0.9272)
2025-06-02 21:44:26,689 - INFO - Epoch 15: Train(l=0.1299,a=0.9969) | Val(l=1.4564,a=0.9272)
2025-06-02 21:44:27,142 - INFO - Epoch 16: Train(l=0.1277,a=0.9943) | Val(l=0.9586,a=0.9272)
2025-06-02 21:44:27,427 - INFO - Epoch 17: Train(l=0.1260,a=0.9985) | Val(l=0.9058,a=0.9272)
2025-06-02 21:44:27,720 - INFO - Epoch 18: Train(l=0.1243,a=0.9979) | Val(l=0.7837,a=0.9272)
2025-06-02 21:44:28,004 - INFO - Epoch 19: Train(l=0.1241,a=0.9974) | Val(l=0.6915,a=0.9272)
2025-06-02 21:44:28,263 - INFO - Epoch 20: Train(l=0.1230,a=0.9974) | Val(l=0.5759,a=0.9272)
2025-06-02 21:44:28,529 - INFO - Epoch 21: Train(l=0.1200,a=0.9985) | Val(l=0.5450,a=0.9272)
2025-06-02 21:44:28,777 - INFO - Epoch 22: Train(l=0.1212,a=0.9985) | Val(l=0.4638,a=0.9272)
2025-06-02 21:44:29,035 - INFO - Epoch 23: Train(l=0.1203,a=0.9979) | Val(l=0.4707,a=0.9272)
2025-06-02 21:44:29,312 - INFO - Epoch 24: Train(l=0.1203,a=0.9990) | Val(l=0.4950,a=0.9272)
2025-06-02 21:44:29,579 - INFO - Epoch 25: Train(l=0.1176,a=0.9985) | Val(l=0.4696,a=0.9272)
2025-06-02 21:44:29,859 - INFO - Epoch 26: Train(l=0.1169,a=0.9985) | Val(l=0.4721,a=0.9272)
2025-06-02 21:44:30,164 - INFO - Epoch 27: Train(l=0.1177,a=0.9995) | Val(l=0.4170,a=0.9272)
2025-06-02 21:44:30,458 - INFO - Epoch 28: Train(l=0.1172,a=0.9985) | Val(l=0.4083,a=0.9272)
2025-06-02 21:44:30,694 - INFO - Epoch 29: Train(l=0.1164,a=0.9990) | Val(l=0.4045,a=0.9272)
2025-06-02 21:44:30,919 - INFO - Epoch 30: Train(l=0.1180,a=0.9985) | Val(l=0.3812,a=0.9272)
2025-06-02 21:44:31,215 - INFO - Epoch 31: Train(l=0.1176,a=0.9990) | Val(l=0.3903,a=0.9272)
2025-06-02 21:44:31,511 - INFO - Epoch 32: Train(l=0.1171,a=0.9995) | Val(l=0.3745,a=0.9272)
2025-06-02 21:44:31,760 - INFO - Epoch 33: Train(l=0.1154,a=0.9990) | Val(l=0.4015,a=0.9272)
2025-06-02 21:44:32,006 - INFO - Epoch 34: Train(l=0.1126,a=0.9990) | Val(l=0.3919,a=0.9272)
2025-06-02 21:44:32,376 - INFO - Epoch 35: Train(l=0.1149,a=0.9990) | Val(l=0.4021,a=0.9272)
2025-06-02 21:44:32,649 - INFO - Epoch 36: Train(l=0.1160,a=0.9990) | Val(l=0.3878,a=0.9272)
2025-06-02 21:44:32,860 - INFO - Epoch 37: Train(l=0.1149,a=0.9979) | Val(l=0.3733,a=0.9272)
2025-06-02 21:44:33,100 - INFO - Epoch 38: Train(l=0.1145,a=0.9990) | Val(l=0.3609,a=0.9272)
2025-06-02 21:44:33,397 - INFO - Epoch 39: Train(l=0.1122,a=0.9979) | Val(l=0.3536,a=0.9272)
2025-06-02 21:44:33,750 - INFO - Epoch 40: Train(l=0.1132,a=0.9990) | Val(l=0.3508,a=0.9272)
2025-06-02 21:44:34,065 - INFO - Epoch 41: Train(l=0.1118,a=0.9985) | Val(l=0.3550,a=0.9272)
2025-06-02 21:44:34,331 - INFO - Epoch 42: Train(l=0.1143,a=0.9985) | Val(l=0.3535,a=0.9272)
2025-06-02 21:44:34,666 - INFO - Epoch 43: Train(l=0.1134,a=0.9985) | Val(l=0.3542,a=0.9272)
2025-06-02 21:44:35,000 - INFO - Epoch 44: Train(l=0.1119,a=0.9985) | Val(l=0.3544,a=0.9272)
2025-06-02 21:44:35,300 - INFO - Epoch 45: Train(l=0.1142,a=0.9990) | Val(l=0.3453,a=0.9272)
2025-06-02 21:44:35,593 - INFO - Epoch 46: Train(l=0.1129,a=1.0000) | Val(l=0.3375,a=0.9272)
2025-06-02 21:44:35,858 - INFO - Epoch 47: Train(l=0.1118,a=0.9990) | Val(l=0.3447,a=0.9272)
2025-06-02 21:44:36,121 - INFO - Epoch 48: Train(l=0.1122,a=0.9985) | Val(l=0.3411,a=0.9272)
2025-06-02 21:44:36,427 - INFO - Epoch 49: Train(l=0.1131,a=0.9985) | Val(l=0.3377,a=0.9272)
2025-06-02 21:44:36,737 - INFO - Epoch 50: Train(l=0.1114,a=0.9995) | Val(l=0.3357,a=0.9272)
2025-06-02 21:44:37,127 - INFO - Epoch 51: Train(l=0.1120,a=0.9979) | Val(l=0.3329,a=0.9272)
2025-06-02 21:44:37,443 - INFO - Epoch 52: Train(l=0.1125,a=1.0000) | Val(l=0.3440,a=0.9272)
2025-06-02 21:44:37,743 - INFO - Epoch 53: Train(l=0.1109,a=0.9990) | Val(l=0.3427,a=0.9272)
2025-06-02 21:44:38,095 - INFO - Epoch 54: Train(l=0.1138,a=0.9995) | Val(l=0.3398,a=0.9272)
2025-06-02 21:44:38,533 - INFO - Epoch 55: Train(l=0.1131,a=0.9990) | Val(l=0.3514,a=0.9272)
2025-06-02 21:44:38,831 - INFO - Epoch 56: Train(l=0.1114,a=0.9985) | Val(l=0.3354,a=0.9272)
2025-06-02 21:44:39,109 - INFO - Epoch 57: Train(l=0.1103,a=0.9990) | Val(l=0.3368,a=0.9272)
2025-06-02 21:44:39,465 - INFO - Epoch 58: Train(l=0.1115,a=0.9990) | Val(l=0.3321,a=0.9272)
2025-06-02 21:44:39,731 - INFO - Epoch 59: Train(l=0.1122,a=0.9990) | Val(l=0.3281,a=0.9272)
2025-06-02 21:44:40,070 - INFO - Epoch 60: Train(l=0.1125,a=1.0000) | Val(l=0.3294,a=0.9272)
2025-06-02 21:44:40,390 - INFO - Epoch 61: Train(l=0.1103,a=0.9990) | Val(l=0.3285,a=0.9272)
2025-06-02 21:44:40,681 - INFO - Epoch 62: Train(l=0.1113,a=0.9990) | Val(l=0.3319,a=0.9272)
2025-06-02 21:44:40,954 - INFO - Epoch 63: Train(l=0.1110,a=0.9995) | Val(l=0.3274,a=0.9272)
2025-06-02 21:44:41,246 - INFO - Epoch 64: Train(l=0.1112,a=0.9990) | Val(l=0.3321,a=0.9272)
2025-06-02 21:44:41,538 - INFO - Epoch 65: Train(l=0.1135,a=0.9985) | Val(l=0.3372,a=0.9272)
2025-06-02 21:44:41,811 - INFO - Epoch 66: Train(l=0.1116,a=0.9990) | Val(l=0.3308,a=0.9272)
2025-06-02 21:44:42,024 - INFO - Epoch 67: Train(l=0.1124,a=0.9990) | Val(l=0.3377,a=0.9272)
2025-06-02 21:44:42,299 - INFO - Epoch 68: Train(l=0.1132,a=0.9985) | Val(l=0.3268,a=0.9272)
2025-06-02 21:44:42,557 - INFO - Epoch 69: Train(l=0.1115,a=0.9990) | Val(l=0.3328,a=0.9272)
2025-06-02 21:44:42,858 - INFO - Epoch 70: Train(l=0.1129,a=0.9990) | Val(l=0.3284,a=0.9272)
2025-06-02 21:44:43,128 - INFO - Epoch 71: Train(l=0.1103,a=0.9990) | Val(l=0.3282,a=0.9272)
2025-06-02 21:44:43,452 - INFO - Epoch 72: Train(l=0.1110,a=0.9990) | Val(l=0.3331,a=0.9272)
2025-06-02 21:44:43,811 - INFO - Epoch 73: Train(l=0.1102,a=0.9995) | Val(l=0.3304,a=0.9272)
2025-06-02 21:44:44,169 - INFO - Epoch 74: Train(l=0.1105,a=0.9985) | Val(l=0.3263,a=0.9272)
2025-06-02 21:44:44,519 - INFO - Epoch 75: Train(l=0.1119,a=1.0000) | Val(l=0.3287,a=0.9272)
2025-06-02 21:44:44,813 - INFO - Epoch 76: Train(l=0.1102,a=0.9995) | Val(l=0.3258,a=0.9272)
2025-06-02 21:44:45,053 - INFO - Epoch 77: Train(l=0.1094,a=0.9990) | Val(l=0.3315,a=0.9272)
2025-06-02 21:44:45,290 - INFO - Epoch 78: Train(l=0.1095,a=0.9995) | Val(l=0.3273,a=0.9272)
2025-06-02 21:44:45,575 - INFO - Epoch 79: Train(l=0.1116,a=1.0000) | Val(l=0.3298,a=0.9272)
2025-06-02 21:44:45,913 - INFO - Epoch 80: Train(l=0.1118,a=0.9995) | Val(l=0.3266,a=0.9272)
2025-06-02 21:44:46,389 - INFO - Epoch 81: Train(l=0.1113,a=0.9995) | Val(l=0.3196,a=0.9272)
2025-06-02 21:44:46,860 - INFO - Epoch 82: Train(l=0.1117,a=0.9985) | Val(l=0.3242,a=0.9272)
2025-06-02 21:44:47,387 - INFO - Epoch 83: Train(l=0.1106,a=0.9979) | Val(l=0.3206,a=0.9272)
2025-06-02 21:44:47,995 - INFO - Epoch 84: Train(l=0.1134,a=0.9995) | Val(l=0.3218,a=0.9272)
2025-06-02 21:44:48,494 - INFO - Epoch 85: Train(l=0.1097,a=0.9995) | Val(l=0.3240,a=0.9272)
2025-06-02 21:44:49,212 - INFO - Epoch 86: Train(l=0.1119,a=0.9995) | Val(l=0.3247,a=0.9272)
2025-06-02 21:44:49,847 - INFO - Epoch 87: Train(l=0.1118,a=0.9990) | Val(l=0.3250,a=0.9272)
2025-06-02 21:44:50,665 - INFO - Epoch 88: Train(l=0.1104,a=0.9995) | Val(l=0.3209,a=0.9272)
2025-06-02 21:44:51,237 - INFO - Epoch 89: Train(l=0.1097,a=0.9995) | Val(l=0.3256,a=0.9272)
2025-06-02 21:44:51,857 - INFO - Epoch 90: Train(l=0.1137,a=0.9990) | Val(l=0.3255,a=0.9272)
2025-06-02 21:44:52,641 - INFO - Epoch 91: Train(l=0.1109,a=0.9990) | Val(l=0.3256,a=0.9272)
2025-06-02 21:44:53,368 - INFO - Epoch 92: Train(l=0.1122,a=0.9990) | Val(l=0.3219,a=0.9272)
2025-06-02 21:44:54,146 - INFO - Epoch 93: Train(l=0.1118,a=0.9995) | Val(l=0.3210,a=0.9272)
2025-06-02 21:44:54,857 - INFO - Epoch 94: Train(l=0.1104,a=0.9985) | Val(l=0.3235,a=0.9272)
2025-06-02 21:44:55,433 - INFO - Epoch 95: Train(l=0.1122,a=0.9990) | Val(l=0.3254,a=0.9272)
2025-06-02 21:44:56,042 - INFO - Epoch 96: Train(l=0.1097,a=0.9995) | Val(l=0.3277,a=0.9272)
2025-06-02 21:44:56,655 - INFO - Epoch 97: Train(l=0.1120,a=0.9985) | Val(l=0.3244,a=0.9272)
2025-06-02 21:44:57,383 - INFO - Epoch 98: Train(l=0.1127,a=0.9990) | Val(l=0.3286,a=0.9272)
2025-06-02 21:44:58,253 - INFO - Epoch 99: Train(l=0.1099,a=0.9990) | Val(l=0.3300,a=0.9272)
2025-06-02 21:45:25,784 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 21:47:48,310 - INFO - Validation MSE: 0.101252
2025-06-02 21:54:45,757 - INFO - Training DBN...
2025-06-02 21:54:46,719 - INFO - Starting DBN pre-training...
2025-06-02 21:54:46,720 - INFO - Pre-training RBM layer 1/3
2025-06-02 21:54:47,327 - INFO -  RBM1 Epoch 0: Loss=1.5670
2025-06-02 21:54:49,759 - INFO -  RBM1 Epoch 10: Loss=1.1554
2025-06-02 21:54:52,820 - INFO -  RBM1 Epoch 20: Loss=1.1040
2025-06-02 21:54:55,132 - INFO -  RBM1 Epoch 30: Loss=1.0843
2025-06-02 21:54:57,926 - INFO -  RBM1 Epoch 40: Loss=1.0938
2025-06-02 21:55:08,544 - INFO -  RBM1 Epoch 50: Loss=1.0975
2025-06-02 21:55:27,921 - INFO -  RBM1 Epoch 60: Loss=1.1042
2025-06-02 21:55:31,625 - INFO -  RBM1 Epoch 70: Loss=1.1029
2025-06-02 21:55:34,111 - INFO -  RBM1 Epoch 80: Loss=1.1086
2025-06-02 21:55:37,188 - INFO -  RBM1 Epoch 90: Loss=1.1232
2025-06-02 21:55:39,847 - INFO - Pre-training RBM layer 2/3
2025-06-02 21:55:40,015 - INFO -  RBM2 Epoch 0: Loss=0.4341
2025-06-02 21:55:41,102 - INFO -  RBM2 Epoch 10: Loss=0.4093
2025-06-02 21:55:42,326 - INFO -  RBM2 Epoch 20: Loss=0.4000
2025-06-02 21:55:43,965 - INFO -  RBM2 Epoch 30: Loss=0.3878
2025-06-02 21:55:45,222 - INFO -  RBM2 Epoch 40: Loss=0.3781
2025-06-02 21:55:46,541 - INFO -  RBM2 Epoch 50: Loss=0.3707
2025-06-02 21:55:48,162 - INFO -  RBM2 Epoch 60: Loss=0.3649
2025-06-02 21:55:49,882 - INFO -  RBM2 Epoch 70: Loss=0.3616
2025-06-02 21:55:51,782 - INFO -  RBM2 Epoch 80: Loss=0.3587
2025-06-02 21:55:54,630 - INFO -  RBM2 Epoch 90: Loss=0.3569
2025-06-02 21:55:58,099 - INFO - Pre-training RBM layer 3/3
2025-06-02 21:55:58,272 - INFO -  RBM3 Epoch 0: Loss=0.3860
2025-06-02 21:56:01,956 - INFO -  RBM3 Epoch 10: Loss=0.2448
2025-06-02 21:56:06,166 - INFO -  RBM3 Epoch 20: Loss=0.1997
2025-06-02 21:56:10,817 - INFO -  RBM3 Epoch 30: Loss=0.1926
2025-06-02 21:56:19,933 - INFO -  RBM3 Epoch 40: Loss=0.1899
2025-06-02 21:56:21,735 - INFO -  RBM3 Epoch 50: Loss=0.1886
2025-06-02 21:56:23,222 - INFO -  RBM3 Epoch 60: Loss=0.1875
2025-06-02 21:56:25,885 - INFO -  RBM3 Epoch 70: Loss=0.1860
2025-06-02 21:56:27,411 - INFO -  RBM3 Epoch 80: Loss=0.1863
2025-06-02 21:56:29,231 - INFO -  RBM3 Epoch 90: Loss=0.1858
2025-06-02 21:57:02,790 - INFO - Starting DBN fine-tuning...
2025-06-02 21:57:39,027 - INFO - Epoch 0: Train(l=0.5611,a=0.5232) | Val(l=0.6273,a=0.9272)
2025-06-02 21:57:39,440 - INFO - Epoch 1: Train(l=0.5457,a=0.5944) | Val(l=0.5713,a=0.9272)
2025-06-02 21:57:39,795 - INFO - Epoch 2: Train(l=0.5349,a=0.6151) | Val(l=0.5477,a=0.9272)
2025-06-02 21:57:40,115 - INFO - Epoch 3: Train(l=0.5317,a=0.6176) | Val(l=0.5455,a=0.9272)
2025-06-02 21:57:40,479 - INFO - Epoch 4: Train(l=0.5244,a=0.6249) | Val(l=0.5373,a=0.9272)
2025-06-02 21:57:40,846 - INFO - Epoch 5: Train(l=0.5196,a=0.6589) | Val(l=0.5241,a=0.9272)
2025-06-02 21:57:41,359 - INFO - Epoch 6: Train(l=0.5132,a=0.6625) | Val(l=0.5143,a=0.9272)
2025-06-02 21:57:42,341 - INFO - Epoch 7: Train(l=0.5105,a=0.6651) | Val(l=0.5061,a=0.9272)
2025-06-02 21:57:43,033 - INFO - Epoch 8: Train(l=0.5064,a=0.6600) | Val(l=0.4962,a=0.9272)
2025-06-02 21:57:43,467 - INFO - Epoch 9: Train(l=0.5033,a=0.6646) | Val(l=0.4941,a=0.8404)
2025-06-02 21:57:43,838 - INFO - Epoch 10: Train(l=0.5033,a=0.6677) | Val(l=0.4985,a=0.7887)
2025-06-02 21:57:44,183 - INFO - Epoch 11: Train(l=0.5046,a=0.6625) | Val(l=0.5072,a=0.7629)
2025-06-02 21:57:44,522 - INFO - Epoch 12: Train(l=0.5089,a=0.6569) | Val(l=0.5129,a=0.7606)
2025-06-02 21:57:44,938 - INFO - Epoch 13: Train(l=0.5043,a=0.6672) | Val(l=0.5496,a=0.6901)
2025-06-02 21:57:45,522 - INFO - Epoch 14: Train(l=0.5024,a=0.6713) | Val(l=0.5787,a=0.6549)
2025-06-02 21:57:46,148 - INFO - Epoch 15: Train(l=0.4963,a=0.6682) | Val(l=0.5376,a=0.6761)
2025-06-02 21:57:46,648 - INFO - Epoch 16: Train(l=0.4917,a=0.6827) | Val(l=0.5927,a=0.6502)
2025-06-02 21:57:47,087 - INFO - Epoch 17: Train(l=0.4751,a=0.6873) | Val(l=0.5368,a=0.6925)
2025-06-02 21:57:47,602 - INFO - Epoch 18: Train(l=0.4491,a=0.7126) | Val(l=0.5864,a=0.6667)
2025-06-02 21:57:48,178 - INFO - Epoch 19: Train(l=0.4236,a=0.7611) | Val(l=0.6197,a=0.6761)
2025-06-02 21:57:48,674 - INFO - Epoch 20: Train(l=0.3925,a=0.8111) | Val(l=1.1265,a=0.3756)
2025-06-02 21:57:49,382 - INFO - Epoch 21: Train(l=0.3617,a=0.8323) | Val(l=0.8009,a=0.5798)
2025-06-02 21:57:50,217 - INFO - Epoch 22: Train(l=0.3310,a=0.8478) | Val(l=0.5266,a=0.7254)
2025-06-02 21:57:51,182 - INFO - Epoch 23: Train(l=0.3021,a=0.8700) | Val(l=0.7879,a=0.5986)
2025-06-02 21:57:52,501 - INFO - Epoch 24: Train(l=0.2798,a=0.8741) | Val(l=0.5603,a=0.7254)
2025-06-02 21:57:53,830 - INFO - Epoch 25: Train(l=0.2682,a=0.8865) | Val(l=0.5205,a=0.7465)
2025-06-02 21:57:55,658 - INFO - Epoch 26: Train(l=0.2598,a=0.8860) | Val(l=0.3891,a=0.8333)
2025-06-02 21:57:57,906 - INFO - Epoch 27: Train(l=0.2549,a=0.8906) | Val(l=0.4683,a=0.7770)
2025-06-02 21:58:03,354 - INFO - Epoch 28: Train(l=0.2506,a=0.8885) | Val(l=0.4056,a=0.8075)
2025-06-02 21:58:07,809 - INFO - Epoch 29: Train(l=0.2492,a=0.8901) | Val(l=0.4221,a=0.8052)
2025-06-02 21:58:08,437 - INFO - Epoch 30: Train(l=0.2498,a=0.8891) | Val(l=0.4423,a=0.7958)
2025-06-02 21:58:08,987 - INFO - Epoch 31: Train(l=0.2473,a=0.8937) | Val(l=0.4441,a=0.7981)
2025-06-02 21:58:09,546 - INFO - Epoch 32: Train(l=0.2483,a=0.8916) | Val(l=0.4313,a=0.8052)
2025-06-02 21:58:10,231 - INFO - Epoch 33: Train(l=0.2454,a=0.8922) | Val(l=0.4022,a=0.8122)
2025-06-02 21:58:10,781 - INFO - Epoch 34: Train(l=0.2415,a=0.8968) | Val(l=0.5218,a=0.7606)
2025-06-02 21:58:11,415 - INFO - Epoch 35: Train(l=0.2363,a=0.8983) | Val(l=0.2979,a=0.9155)
2025-06-02 21:58:12,053 - INFO - Epoch 36: Train(l=0.2287,a=0.9025) | Val(l=0.4548,a=0.7911)
2025-06-02 21:58:12,661 - INFO - Epoch 37: Train(l=0.2247,a=0.9009) | Val(l=0.5409,a=0.7418)
2025-06-02 21:58:13,661 - INFO - Epoch 38: Train(l=0.2147,a=0.9143) | Val(l=0.3634,a=0.8826)
2025-06-02 21:58:14,501 - INFO - Epoch 39: Train(l=0.2108,a=0.9154) | Val(l=1.0062,a=0.4531)
2025-06-02 21:58:15,263 - INFO - Epoch 40: Train(l=0.2092,a=0.9200) | Val(l=1.2664,a=0.4202)
2025-06-02 21:58:16,049 - INFO - Epoch 41: Train(l=0.1910,a=0.9252) | Val(l=1.1543,a=0.4249)
2025-06-02 21:58:16,805 - INFO - Epoch 42: Train(l=0.1828,a=0.9283) | Val(l=0.8345,a=0.5211)
2025-06-02 21:58:17,351 - INFO - Epoch 43: Train(l=0.1721,a=0.9355) | Val(l=0.6003,a=0.7488)
2025-06-02 21:58:18,045 - INFO - Epoch 44: Train(l=0.1671,a=0.9360) | Val(l=0.5907,a=0.7535)
2025-06-02 21:58:19,231 - INFO - Epoch 45: Train(l=0.1605,a=0.9448) | Val(l=0.4552,a=0.8099)
2025-06-02 21:58:20,146 - INFO - Epoch 46: Train(l=0.1576,a=0.9443) | Val(l=0.3704,a=0.8498)
2025-06-02 21:58:21,770 - INFO - Epoch 47: Train(l=0.1515,a=0.9530) | Val(l=0.5218,a=0.7958)
2025-06-02 21:58:22,902 - INFO - Epoch 48: Train(l=0.1478,a=0.9463) | Val(l=0.3658,a=0.8638)
2025-06-02 21:58:24,450 - INFO - Epoch 49: Train(l=0.1451,a=0.9525) | Val(l=0.3771,a=0.8615)
2025-06-02 21:58:26,250 - INFO - Epoch 50: Train(l=0.1467,a=0.9499) | Val(l=0.3881,a=0.8592)
2025-06-02 21:58:34,350 - INFO - Epoch 51: Train(l=0.1496,a=0.9474) | Val(l=0.4225,a=0.8380)
2025-06-02 21:58:39,425 - INFO - Epoch 52: Train(l=0.1458,a=0.9515) | Val(l=0.3715,a=0.8592)
2025-06-02 21:58:43,341 - INFO - Epoch 53: Train(l=0.1467,a=0.9479) | Val(l=0.3527,a=0.8662)
2025-06-02 21:58:49,790 - INFO - Epoch 54: Train(l=0.1410,a=0.9520) | Val(l=0.3553,a=0.8685)
2025-06-02 21:58:54,014 - INFO - Epoch 55: Train(l=0.1400,a=0.9546) | Val(l=0.3935,a=0.8239)
2025-06-02 21:58:54,019 - INFO - Early stopping.
2025-06-02 21:59:14,971 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 21:59:37,186 - INFO - Validation MSE: 8.128840
2025-06-02 21:59:37,188 - INFO - Total training time: 291.43s
2025-06-02 21:59:37,189 - INFO - Validation MCC: 0.3506, AUC: 0.8459
2025-06-02 21:59:37,190 - INFO - Test       MCC: 0.3961, AUC: 0.8446
2025-06-02 22:07:23,975 - INFO - Training DBN...
2025-06-02 22:07:24,658 - INFO - Starting DBN pre-training...
2025-06-02 22:07:24,659 - INFO - Pre-training RBM layer 1/3
2025-06-02 22:07:25,243 - INFO -  RBM1 Epoch 0: Loss=1.5619
2025-06-02 22:07:26,270 - INFO -  RBM1 Epoch 10: Loss=1.1501
2025-06-02 22:07:27,706 - INFO -  RBM1 Epoch 20: Loss=1.1092
2025-06-02 22:07:28,841 - INFO -  RBM1 Epoch 30: Loss=1.0881
2025-06-02 22:07:29,986 - INFO -  RBM1 Epoch 40: Loss=1.0963
2025-06-02 22:07:31,552 - INFO -  RBM1 Epoch 50: Loss=1.0941
2025-06-02 22:07:32,959 - INFO -  RBM1 Epoch 60: Loss=1.0971
2025-06-02 22:07:34,369 - INFO -  RBM1 Epoch 70: Loss=1.1118
2025-06-02 22:07:35,874 - INFO -  RBM1 Epoch 80: Loss=1.1044
2025-06-02 22:07:38,723 - INFO -  RBM1 Epoch 90: Loss=1.1195
2025-06-02 22:07:40,904 - INFO - Pre-training RBM layer 2/3
2025-06-02 22:07:41,084 - INFO -  RBM2 Epoch 0: Loss=0.4352
2025-06-02 22:07:42,583 - INFO -  RBM2 Epoch 10: Loss=0.4099
2025-06-02 22:07:44,386 - INFO -  RBM2 Epoch 20: Loss=0.4012
2025-06-02 22:07:45,536 - INFO -  RBM2 Epoch 30: Loss=0.3918
2025-06-02 22:07:46,380 - INFO -  RBM2 Epoch 40: Loss=0.3827
2025-06-02 22:07:47,688 - INFO -  RBM2 Epoch 50: Loss=0.3739
2025-06-02 22:07:49,697 - INFO -  RBM2 Epoch 60: Loss=0.3697
2025-06-02 22:07:50,806 - INFO -  RBM2 Epoch 70: Loss=0.3659
2025-06-02 22:07:52,889 - INFO -  RBM2 Epoch 80: Loss=0.3615
2025-06-02 22:07:54,880 - INFO -  RBM2 Epoch 90: Loss=0.3595
2025-06-02 22:07:55,901 - INFO - Pre-training RBM layer 3/3
2025-06-02 22:07:55,955 - INFO -  RBM3 Epoch 0: Loss=0.3818
2025-06-02 22:07:56,515 - INFO -  RBM3 Epoch 10: Loss=0.2469
2025-06-02 22:07:57,085 - INFO -  RBM3 Epoch 20: Loss=0.2013
2025-06-02 22:07:57,596 - INFO -  RBM3 Epoch 30: Loss=0.1958
2025-06-02 22:07:58,244 - INFO -  RBM3 Epoch 40: Loss=0.1922
2025-06-02 22:07:58,780 - INFO -  RBM3 Epoch 50: Loss=0.1913
2025-06-02 22:07:59,223 - INFO -  RBM3 Epoch 60: Loss=0.1898
2025-06-02 22:07:59,714 - INFO -  RBM3 Epoch 70: Loss=0.1901
2025-06-02 22:08:00,239 - INFO -  RBM3 Epoch 80: Loss=0.1899
2025-06-02 22:08:00,782 - INFO -  RBM3 Epoch 90: Loss=0.1900
2025-06-02 22:08:01,204 - INFO - Starting DBN fine-tuning...
2025-06-02 22:08:18,807 - INFO - Epoch 0: Train(l=0.5455,a=0.6063) | Val(l=0.7553,a=0.0728)
2025-06-02 22:08:19,044 - INFO - Epoch 1: Train(l=0.5412,a=0.6192) | Val(l=0.7403,a=0.0728)
2025-06-02 22:08:19,231 - INFO - Epoch 2: Train(l=0.5232,a=0.6409) | Val(l=0.6903,a=0.4554)
2025-06-02 22:08:19,595 - INFO - Epoch 3: Train(l=0.5178,a=0.6569) | Val(l=0.6382,a=0.5869)
2025-06-02 22:08:19,839 - INFO - Epoch 4: Train(l=0.5165,a=0.6594) | Val(l=0.5946,a=0.7864)
2025-06-02 22:08:20,108 - INFO - Epoch 5: Train(l=0.5093,a=0.6579) | Val(l=0.5661,a=0.9178)
2025-06-02 22:08:20,361 - INFO - Epoch 6: Train(l=0.5015,a=0.6754) | Val(l=0.5508,a=0.8122)
2025-06-02 22:08:20,647 - INFO - Epoch 7: Train(l=0.5063,a=0.6698) | Val(l=0.5429,a=0.7324)
2025-06-02 22:08:20,926 - INFO - Epoch 8: Train(l=0.5014,a=0.6718) | Val(l=0.5362,a=0.7089)
2025-06-02 22:08:21,182 - INFO - Epoch 9: Train(l=0.5020,a=0.6760) | Val(l=0.5514,a=0.7019)
2025-06-02 22:08:21,443 - INFO - Epoch 10: Train(l=0.4897,a=0.6868) | Val(l=0.5836,a=0.6268)
2025-06-02 22:08:21,736 - INFO - Epoch 11: Train(l=0.4798,a=0.7012) | Val(l=0.4613,a=0.7347)
2025-06-02 22:08:22,019 - INFO - Epoch 12: Train(l=0.4638,a=0.7126) | Val(l=0.2994,a=0.9272)
2025-06-02 22:08:22,280 - INFO - Epoch 13: Train(l=0.4404,a=0.7595) | Val(l=0.3711,a=0.8427)
2025-06-02 22:08:22,593 - INFO - Epoch 14: Train(l=0.4068,a=0.7843) | Val(l=0.3576,a=0.8099)
2025-06-02 22:08:22,891 - INFO - Epoch 15: Train(l=0.3748,a=0.8225) | Val(l=0.3243,a=0.8568)
2025-06-02 22:08:23,191 - INFO - Epoch 16: Train(l=0.3440,a=0.8437) | Val(l=0.5498,a=0.6925)
2025-06-02 22:08:23,451 - INFO - Epoch 17: Train(l=0.3275,a=0.8545) | Val(l=0.6269,a=0.6737)
2025-06-02 22:08:23,777 - INFO - Epoch 18: Train(l=0.2995,a=0.8591) | Val(l=0.7974,a=0.6432)
2025-06-02 22:08:24,026 - INFO - Epoch 19: Train(l=0.2798,a=0.8756) | Val(l=0.5194,a=0.7277)
2025-06-02 22:08:24,240 - INFO - Epoch 20: Train(l=0.2717,a=0.8834) | Val(l=0.6369,a=0.7066)
2025-06-02 22:08:24,506 - INFO - Epoch 21: Train(l=0.2607,a=0.8839) | Val(l=0.5730,a=0.7254)
2025-06-02 22:08:24,768 - INFO - Epoch 22: Train(l=0.2548,a=0.8818) | Val(l=0.4884,a=0.7700)
2025-06-02 22:08:24,976 - INFO - Epoch 23: Train(l=0.2482,a=0.8927) | Val(l=0.6416,a=0.7183)
2025-06-02 22:08:25,212 - INFO - Epoch 24: Train(l=0.2457,a=0.8891) | Val(l=0.4676,a=0.7676)
2025-06-02 22:08:25,439 - INFO - Epoch 25: Train(l=0.2399,a=0.8968) | Val(l=0.4754,a=0.7746)
2025-06-02 22:08:25,669 - INFO - Epoch 26: Train(l=0.2401,a=0.8958) | Val(l=0.4958,a=0.7700)
2025-06-02 22:08:25,875 - INFO - Epoch 27: Train(l=0.2336,a=0.8947) | Val(l=0.4926,a=0.7770)
2025-06-02 22:08:26,087 - INFO - Epoch 28: Train(l=0.2374,a=0.8963) | Val(l=0.4771,a=0.7911)
2025-06-02 22:08:26,301 - INFO - Epoch 29: Train(l=0.2357,a=0.8937) | Val(l=0.4710,a=0.7958)
2025-06-02 22:08:26,555 - INFO - Epoch 30: Train(l=0.2337,a=0.8989) | Val(l=0.7509,a=0.7042)
2025-06-02 22:08:26,805 - INFO - Epoch 31: Train(l=0.2258,a=0.9030) | Val(l=0.6159,a=0.7347)
2025-06-02 22:08:27,027 - INFO - Epoch 32: Train(l=0.2158,a=0.9097) | Val(l=1.2641,a=0.3850)
2025-06-02 22:08:27,027 - INFO - Early stopping.
2025-06-02 22:08:41,986 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 22:10:06,339 - INFO - Validation MSE: 5.593739
2025-06-02 22:10:06,359 - INFO - Total training time: 162.38s
2025-06-02 22:10:06,359 - INFO - Validation MCC: 0.2878, AUC: 0.8191
2025-06-02 22:10:06,360 - INFO - Test       MCC: 0.2742, AUC: 0.8392
2025-06-02 22:10:45,721 - INFO - Training DBN...
2025-06-02 22:10:46,032 - INFO - Starting DBN pre-training...
2025-06-02 22:10:46,033 - INFO - Pre-training RBM layer 1/3
2025-06-02 22:10:46,380 - INFO -  RBM1 Epoch 0: Loss=1.5618
2025-06-02 22:10:47,806 - INFO -  RBM1 Epoch 10: Loss=1.1634
2025-06-02 22:10:49,361 - INFO -  RBM1 Epoch 20: Loss=1.0965
2025-06-02 22:10:50,922 - INFO -  RBM1 Epoch 30: Loss=1.0872
2025-06-02 22:10:53,168 - INFO -  RBM1 Epoch 40: Loss=1.0891
2025-06-02 22:10:55,358 - INFO -  RBM1 Epoch 50: Loss=1.1033
2025-06-02 22:10:56,739 - INFO -  RBM1 Epoch 60: Loss=1.1016
2025-06-02 22:10:58,214 - INFO -  RBM1 Epoch 70: Loss=1.1018
2025-06-02 22:11:00,406 - INFO -  RBM1 Epoch 80: Loss=1.1068
2025-06-02 22:11:02,294 - INFO -  RBM1 Epoch 90: Loss=1.1215
2025-06-02 22:11:04,106 - INFO - Pre-training RBM layer 2/3
2025-06-02 22:11:04,347 - INFO -  RBM2 Epoch 0: Loss=0.4355
2025-06-02 22:11:05,245 - INFO -  RBM2 Epoch 10: Loss=0.4084
2025-06-02 22:11:06,529 - INFO -  RBM2 Epoch 20: Loss=0.4004
2025-06-02 22:11:08,335 - INFO -  RBM2 Epoch 30: Loss=0.3899
2025-06-02 22:11:09,554 - INFO -  RBM2 Epoch 40: Loss=0.3822
2025-06-02 22:11:11,047 - INFO -  RBM2 Epoch 50: Loss=0.3758
2025-06-02 22:11:12,362 - INFO -  RBM2 Epoch 60: Loss=0.3682
2025-06-02 22:11:13,400 - INFO -  RBM2 Epoch 70: Loss=0.3655
2025-06-02 22:11:15,168 - INFO -  RBM2 Epoch 80: Loss=0.3601
2025-06-02 22:11:16,582 - INFO -  RBM2 Epoch 90: Loss=0.3581
2025-06-02 22:11:17,540 - INFO - Pre-training RBM layer 3/3
2025-06-02 22:11:17,577 - INFO -  RBM3 Epoch 0: Loss=0.3854
2025-06-02 22:11:17,984 - INFO -  RBM3 Epoch 10: Loss=0.2454
2025-06-02 22:11:18,413 - INFO -  RBM3 Epoch 20: Loss=0.1996
2025-06-02 22:11:18,887 - INFO -  RBM3 Epoch 30: Loss=0.1921
2025-06-02 22:11:19,540 - INFO -  RBM3 Epoch 40: Loss=0.1887
2025-06-02 22:11:20,005 - INFO -  RBM3 Epoch 50: Loss=0.1871
2025-06-02 22:11:20,574 - INFO -  RBM3 Epoch 60: Loss=0.1859
2025-06-02 22:11:21,237 - INFO -  RBM3 Epoch 70: Loss=0.1852
2025-06-02 22:11:22,405 - INFO -  RBM3 Epoch 80: Loss=0.1861
2025-06-02 22:11:22,982 - INFO -  RBM3 Epoch 90: Loss=0.1854
2025-06-02 22:11:23,550 - INFO - Starting DBN fine-tuning...
2025-06-02 22:11:41,749 - INFO - Epoch 0: Train(l=0.5674,a=0.5640) | Val(l=0.7664,a=0.0728)
2025-06-02 22:11:42,112 - INFO - Epoch 1: Train(l=0.5366,a=0.6300) | Val(l=0.7402,a=0.3357)
2025-06-02 22:11:42,307 - INFO - Epoch 2: Train(l=0.5339,a=0.6445) | Val(l=0.6905,a=0.4836)
2025-06-02 22:11:42,502 - INFO - Epoch 3: Train(l=0.5216,a=0.6476) | Val(l=0.6557,a=0.5305)
2025-06-02 22:11:42,743 - INFO - Epoch 4: Train(l=0.5113,a=0.6579) | Val(l=0.6249,a=0.5775)
2025-06-02 22:11:42,992 - INFO - Epoch 5: Train(l=0.5168,a=0.6455) | Val(l=0.6122,a=0.5845)
2025-06-02 22:11:43,209 - INFO - Epoch 6: Train(l=0.5127,a=0.6620) | Val(l=0.6006,a=0.5939)
2025-06-02 22:11:43,423 - INFO - Epoch 7: Train(l=0.5091,a=0.6646) | Val(l=0.6056,a=0.5939)
2025-06-02 22:11:43,685 - INFO - Epoch 8: Train(l=0.4950,a=0.6713) | Val(l=0.6069,a=0.5939)
2025-06-02 22:11:43,897 - INFO - Epoch 9: Train(l=0.4976,a=0.6739) | Val(l=0.6078,a=0.6033)
2025-06-02 22:11:44,123 - INFO - Epoch 10: Train(l=0.4997,a=0.6667) | Val(l=0.6072,a=0.6197)
2025-06-02 22:11:44,359 - INFO - Epoch 11: Train(l=0.4967,a=0.6749) | Val(l=0.6043,a=0.6362)
2025-06-02 22:11:44,615 - INFO - Epoch 12: Train(l=0.4997,a=0.6734) | Val(l=0.6006,a=0.6268)
2025-06-02 22:11:44,862 - INFO - Epoch 13: Train(l=0.5008,a=0.6656) | Val(l=0.5902,a=0.6221)
2025-06-02 22:11:45,090 - INFO - Epoch 14: Train(l=0.4939,a=0.6749) | Val(l=0.6555,a=0.6150)
2025-06-02 22:11:45,315 - INFO - Epoch 15: Train(l=0.4942,a=0.6785) | Val(l=0.5843,a=0.6526)
2025-06-02 22:11:45,569 - INFO - Epoch 16: Train(l=0.4827,a=0.6791) | Val(l=0.5077,a=0.6878)
2025-06-02 22:11:45,844 - INFO - Epoch 17: Train(l=0.4674,a=0.6987) | Val(l=0.7704,a=0.5540)
2025-06-02 22:11:46,131 - INFO - Epoch 18: Train(l=0.4445,a=0.7430) | Val(l=0.8303,a=0.5258)
2025-06-02 22:11:46,372 - INFO - Epoch 19: Train(l=0.4215,a=0.7792) | Val(l=0.6936,a=0.6362)
2025-06-02 22:11:46,693 - INFO - Epoch 20: Train(l=0.3949,a=0.8024) | Val(l=0.4444,a=0.7394)
2025-06-02 22:11:46,992 - INFO - Epoch 21: Train(l=0.3579,a=0.8426) | Val(l=0.5126,a=0.6995)
2025-06-02 22:11:47,245 - INFO - Epoch 22: Train(l=0.3315,a=0.8488) | Val(l=0.4122,a=0.8216)
2025-06-02 22:11:47,500 - INFO - Epoch 23: Train(l=0.3118,a=0.8622) | Val(l=0.9604,a=0.5446)
2025-06-02 22:11:47,773 - INFO - Epoch 24: Train(l=0.2913,a=0.8689) | Val(l=0.4501,a=0.7676)
2025-06-02 22:11:48,032 - INFO - Epoch 25: Train(l=0.2736,a=0.8767) | Val(l=0.5278,a=0.7207)
2025-06-02 22:11:48,285 - INFO - Epoch 26: Train(l=0.2660,a=0.8860) | Val(l=0.5594,a=0.7113)
2025-06-02 22:11:48,602 - INFO - Epoch 27: Train(l=0.2552,a=0.8916) | Val(l=0.5322,a=0.7371)
2025-06-02 22:11:48,835 - INFO - Epoch 28: Train(l=0.2515,a=0.8911) | Val(l=0.4680,a=0.7629)
2025-06-02 22:11:49,078 - INFO - Epoch 29: Train(l=0.2547,a=0.8927) | Val(l=0.4559,a=0.7723)
2025-06-02 22:11:49,317 - INFO - Epoch 30: Train(l=0.2517,a=0.8958) | Val(l=0.4576,a=0.7746)
2025-06-02 22:11:49,571 - INFO - Epoch 31: Train(l=0.2505,a=0.8968) | Val(l=0.4834,a=0.7653)
2025-06-02 22:11:49,815 - INFO - Epoch 32: Train(l=0.2453,a=0.8999) | Val(l=0.4947,a=0.7512)
2025-06-02 22:11:50,071 - INFO - Epoch 33: Train(l=0.2458,a=0.8989) | Val(l=0.4672,a=0.7629)
2025-06-02 22:11:50,334 - INFO - Epoch 34: Train(l=0.2463,a=0.8994) | Val(l=0.5275,a=0.7488)
2025-06-02 22:11:50,616 - INFO - Epoch 35: Train(l=0.2378,a=0.8963) | Val(l=0.4496,a=0.7723)
2025-06-02 22:11:51,057 - INFO - Epoch 36: Train(l=0.2355,a=0.9040) | Val(l=1.0701,a=0.4648)
2025-06-02 22:11:51,395 - INFO - Epoch 37: Train(l=0.2274,a=0.9004) | Val(l=0.7536,a=0.6995)
2025-06-02 22:11:51,686 - INFO - Epoch 38: Train(l=0.2208,a=0.9076) | Val(l=0.7035,a=0.6901)
2025-06-02 22:11:52,139 - INFO - Epoch 39: Train(l=0.2098,a=0.9190) | Val(l=0.9183,a=0.6573)
2025-06-02 22:11:52,537 - INFO - Epoch 40: Train(l=0.2022,a=0.9195) | Val(l=0.6277,a=0.5329)
2025-06-02 22:11:52,992 - INFO - Epoch 41: Train(l=0.1937,a=0.9252) | Val(l=0.7380,a=0.4883)
2025-06-02 22:11:53,695 - INFO - Epoch 42: Train(l=0.1806,a=0.9309) | Val(l=0.5787,a=0.7324)
2025-06-02 22:11:53,698 - INFO - Early stopping.
2025-06-02 22:12:08,312 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 22:12:23,575 - INFO - Validation MSE: 5.114575
2025-06-02 22:12:23,575 - INFO - Total training time: 97.85s
2025-06-02 22:12:23,577 - INFO - Validation MCC: 0.2900, AUC: 0.8283
2025-06-02 22:12:23,577 - INFO - Test       MCC: 0.3380, AUC: 0.8370
2025-06-02 22:13:30,246 - INFO - Training DBN...
2025-06-02 22:13:30,526 - INFO - Starting DBN pre-training...
2025-06-02 22:13:30,527 - INFO - Pre-training RBM layer 1/3
2025-06-02 22:13:30,773 - INFO -  RBM1 Epoch 0: Loss=1.5648
2025-06-02 22:13:33,079 - INFO -  RBM1 Epoch 10: Loss=1.1531
2025-06-02 22:13:35,956 - INFO -  RBM1 Epoch 20: Loss=1.1042
2025-06-02 22:13:41,460 - INFO -  RBM1 Epoch 30: Loss=1.0932
2025-06-02 22:13:44,449 - INFO -  RBM1 Epoch 40: Loss=1.0912
2025-06-02 22:13:46,465 - INFO -  RBM1 Epoch 50: Loss=1.0918
2025-06-02 22:13:48,304 - INFO -  RBM1 Epoch 60: Loss=1.1098
2025-06-02 22:13:50,636 - INFO -  RBM1 Epoch 70: Loss=1.1000
2025-06-02 22:13:54,333 - INFO -  RBM1 Epoch 80: Loss=1.1024
2025-06-02 22:13:57,961 - INFO -  RBM1 Epoch 90: Loss=1.1200
2025-06-02 22:14:01,385 - INFO - Pre-training RBM layer 2/3
2025-06-02 22:14:01,746 - INFO -  RBM2 Epoch 0: Loss=0.4340
2025-06-02 22:14:07,010 - INFO -  RBM2 Epoch 10: Loss=0.4095
2025-06-02 22:14:11,922 - INFO -  RBM2 Epoch 20: Loss=0.3994
2025-06-02 22:14:17,957 - INFO -  RBM2 Epoch 30: Loss=0.3903
2025-06-02 22:14:23,239 - INFO -  RBM2 Epoch 40: Loss=0.3816
2025-06-02 22:14:37,033 - INFO -  RBM2 Epoch 50: Loss=0.3751
2025-06-02 22:14:41,560 - INFO -  RBM2 Epoch 60: Loss=0.3721
2025-06-02 22:14:46,121 - INFO -  RBM2 Epoch 70: Loss=0.3668
2025-06-02 22:14:49,512 - INFO -  RBM2 Epoch 80: Loss=0.3633
2025-06-02 22:14:54,333 - INFO -  RBM2 Epoch 90: Loss=0.3620
2025-06-02 22:15:08,425 - INFO - Pre-training RBM layer 3/3
2025-06-02 22:15:13,211 - INFO -  RBM3 Epoch 0: Loss=0.3802
2025-06-02 22:15:27,481 - INFO -  RBM3 Epoch 10: Loss=0.2451
2025-06-02 22:15:29,693 - INFO -  RBM3 Epoch 20: Loss=0.2035
2025-06-02 22:15:30,959 - INFO -  RBM3 Epoch 30: Loss=0.1974
2025-06-02 22:15:33,710 - INFO -  RBM3 Epoch 40: Loss=0.1963
2025-06-02 22:15:34,602 - INFO -  RBM3 Epoch 50: Loss=0.1932
2025-06-02 22:15:35,834 - INFO -  RBM3 Epoch 60: Loss=0.1936
2025-06-02 22:15:37,530 - INFO -  RBM3 Epoch 70: Loss=0.1935
2025-06-02 22:15:38,662 - INFO -  RBM3 Epoch 80: Loss=0.1934
2025-06-02 22:15:40,080 - INFO -  RBM3 Epoch 90: Loss=0.1924
2025-06-02 22:15:41,047 - INFO - Starting DBN fine-tuning...
2025-06-02 22:16:01,065 - INFO - Epoch 0: Train(l=0.5450,a=0.5759) | Val(l=0.6673,a=0.4624)
2025-06-02 22:16:01,479 - INFO - Epoch 1: Train(l=0.5297,a=0.6419) | Val(l=0.6368,a=0.6690)
2025-06-02 22:16:01,910 - INFO - Epoch 2: Train(l=0.5180,a=0.6460) | Val(l=0.6014,a=0.9272)
2025-06-02 22:16:02,375 - INFO - Epoch 3: Train(l=0.5150,a=0.6615) | Val(l=0.5526,a=0.9272)
2025-06-02 22:16:02,770 - INFO - Epoch 4: Train(l=0.5134,a=0.6600) | Val(l=0.5255,a=0.9272)
2025-06-02 22:16:03,114 - INFO - Epoch 5: Train(l=0.5042,a=0.6636) | Val(l=0.5112,a=0.8826)
2025-06-02 22:16:03,470 - INFO - Epoch 6: Train(l=0.5059,a=0.6656) | Val(l=0.5031,a=0.8216)
2025-06-02 22:16:03,847 - INFO - Epoch 7: Train(l=0.5001,a=0.6687) | Val(l=0.5097,a=0.7653)
2025-06-02 22:16:04,326 - INFO - Epoch 8: Train(l=0.4902,a=0.6734) | Val(l=0.5150,a=0.7324)
2025-06-02 22:16:04,694 - INFO - Epoch 9: Train(l=0.4911,a=0.6760) | Val(l=0.5291,a=0.6972)
2025-06-02 22:16:05,000 - INFO - Epoch 10: Train(l=0.4919,a=0.6708) | Val(l=0.5508,a=0.6995)
2025-06-02 22:16:05,329 - INFO - Epoch 11: Train(l=0.4966,a=0.6780) | Val(l=0.5592,a=0.6995)
2025-06-02 22:16:05,626 - INFO - Epoch 12: Train(l=0.4938,a=0.6718) | Val(l=0.5749,a=0.6878)
2025-06-02 22:16:05,914 - INFO - Epoch 13: Train(l=0.4969,a=0.6785) | Val(l=0.5853,a=0.6408)
2025-06-02 22:16:06,275 - INFO - Epoch 14: Train(l=0.4871,a=0.6718) | Val(l=0.6142,a=0.6362)
2025-06-02 22:16:06,631 - INFO - Epoch 15: Train(l=0.4840,a=0.6816) | Val(l=0.7585,a=0.5869)
2025-06-02 22:16:07,028 - INFO - Epoch 16: Train(l=0.4700,a=0.7012) | Val(l=0.5403,a=0.6761)
2025-06-02 22:16:07,432 - INFO - Epoch 17: Train(l=0.4540,a=0.7198) | Val(l=0.4802,a=0.7371)
2025-06-02 22:16:07,767 - INFO - Epoch 18: Train(l=0.4275,a=0.7590) | Val(l=0.6697,a=0.6315)
2025-06-02 22:16:08,122 - INFO - Epoch 19: Train(l=0.4019,a=0.7941) | Val(l=0.8517,a=0.5516)
2025-06-02 22:16:08,550 - INFO - Epoch 20: Train(l=0.3684,a=0.8266) | Val(l=0.7991,a=0.5962)
2025-06-02 22:16:08,914 - INFO - Epoch 21: Train(l=0.3411,a=0.8437) | Val(l=0.8300,a=0.5845)
2025-06-02 22:16:09,278 - INFO - Epoch 22: Train(l=0.3111,a=0.8540) | Val(l=0.6985,a=0.6362)
2025-06-02 22:16:09,609 - INFO - Epoch 23: Train(l=0.2926,a=0.8787) | Val(l=1.4022,a=0.2981)
2025-06-02 22:16:09,894 - INFO - Epoch 24: Train(l=0.2751,a=0.8782) | Val(l=0.6260,a=0.7042)
2025-06-02 22:16:10,204 - INFO - Epoch 25: Train(l=0.2606,a=0.8849) | Val(l=0.6112,a=0.7207)
2025-06-02 22:16:10,515 - INFO - Epoch 26: Train(l=0.2574,a=0.8860) | Val(l=0.4884,a=0.7512)
2025-06-02 22:16:10,793 - INFO - Epoch 27: Train(l=0.2465,a=0.8911) | Val(l=0.4300,a=0.7840)
2025-06-02 22:16:11,070 - INFO - Epoch 28: Train(l=0.2394,a=0.8932) | Val(l=0.4559,a=0.7864)
2025-06-02 22:16:11,395 - INFO - Epoch 29: Train(l=0.2402,a=0.8942) | Val(l=0.4689,a=0.7840)
2025-06-02 22:16:11,779 - INFO - Epoch 30: Train(l=0.2390,a=0.8942) | Val(l=0.4618,a=0.7817)
2025-06-02 22:16:12,194 - INFO - Epoch 31: Train(l=0.2381,a=0.9025) | Val(l=0.4446,a=0.7911)
2025-06-02 22:16:12,634 - INFO - Epoch 32: Train(l=0.2338,a=0.8973) | Val(l=0.4555,a=0.7887)
2025-06-02 22:16:12,974 - INFO - Epoch 33: Train(l=0.2322,a=0.9004) | Val(l=0.4302,a=0.7887)
2025-06-02 22:16:13,292 - INFO - Epoch 34: Train(l=0.2273,a=0.9051) | Val(l=0.5023,a=0.7488)
2025-06-02 22:16:13,588 - INFO - Epoch 35: Train(l=0.2247,a=0.8994) | Val(l=0.3886,a=0.8263)
2025-06-02 22:16:13,879 - INFO - Epoch 36: Train(l=0.2227,a=0.9087) | Val(l=0.6851,a=0.7160)
2025-06-02 22:16:14,179 - INFO - Epoch 37: Train(l=0.2179,a=0.9061) | Val(l=0.4487,a=0.7958)
2025-06-02 22:16:14,486 - INFO - Epoch 38: Train(l=0.2072,a=0.9128) | Val(l=0.7670,a=0.6878)
2025-06-02 22:16:14,773 - INFO - Epoch 39: Train(l=0.1997,a=0.9205) | Val(l=0.6443,a=0.7347)
2025-06-02 22:16:15,048 - INFO - Epoch 40: Train(l=0.1926,a=0.9241) | Val(l=0.8075,a=0.4695)
2025-06-02 22:16:15,362 - INFO - Epoch 41: Train(l=0.1860,a=0.9288) | Val(l=0.7047,a=0.5376)
2025-06-02 22:16:15,652 - INFO - Epoch 42: Train(l=0.1813,a=0.9247) | Val(l=0.6489,a=0.7300)
2025-06-02 22:16:15,924 - INFO - Epoch 43: Train(l=0.1687,a=0.9334) | Val(l=0.6970,a=0.6854)
2025-06-02 22:16:16,354 - INFO - Epoch 44: Train(l=0.1605,a=0.9432) | Val(l=0.7442,a=0.5634)
2025-06-02 22:16:16,675 - INFO - Epoch 45: Train(l=0.1558,a=0.9438) | Val(l=0.5440,a=0.7817)
2025-06-02 22:16:16,964 - INFO - Epoch 46: Train(l=0.1482,a=0.9474) | Val(l=0.4524,a=0.8146)
2025-06-02 22:16:17,249 - INFO - Epoch 47: Train(l=0.1457,a=0.9474) | Val(l=0.4055,a=0.8216)
2025-06-02 22:16:17,774 - INFO - Epoch 48: Train(l=0.1472,a=0.9510) | Val(l=0.5075,a=0.8052)
2025-06-02 22:16:18,073 - INFO - Epoch 49: Train(l=0.1380,a=0.9443) | Val(l=0.4388,a=0.8263)
2025-06-02 22:16:18,373 - INFO - Epoch 50: Train(l=0.1383,a=0.9474) | Val(l=0.4214,a=0.8380)
2025-06-02 22:16:18,687 - INFO - Epoch 51: Train(l=0.1359,a=0.9541) | Val(l=0.3475,a=0.8685)
2025-06-02 22:16:18,958 - INFO - Epoch 52: Train(l=0.1444,a=0.9541) | Val(l=0.4526,a=0.8286)
2025-06-02 22:16:19,227 - INFO - Epoch 53: Train(l=0.1385,a=0.9520) | Val(l=0.4297,a=0.8263)
2025-06-02 22:16:19,508 - INFO - Epoch 54: Train(l=0.1384,a=0.9530) | Val(l=0.5937,a=0.7723)
2025-06-02 22:16:19,780 - INFO - Epoch 55: Train(l=0.1352,a=0.9546) | Val(l=0.5532,a=0.7864)
2025-06-02 22:16:20,056 - INFO - Epoch 56: Train(l=0.1334,a=0.9598) | Val(l=0.9896,a=0.5751)
2025-06-02 22:16:20,369 - INFO - Epoch 57: Train(l=0.1347,a=0.9577) | Val(l=1.1113,a=0.5070)
2025-06-02 22:16:20,650 - INFO - Epoch 58: Train(l=0.1250,a=0.9608) | Val(l=1.8015,a=0.4413)
2025-06-02 22:16:20,932 - INFO - Epoch 59: Train(l=0.1297,a=0.9561) | Val(l=1.7353,a=0.4484)
2025-06-02 22:16:21,249 - INFO - Epoch 60: Train(l=0.1325,a=0.9556) | Val(l=1.4321,a=0.5047)
2025-06-02 22:16:21,581 - INFO - Epoch 61: Train(l=0.1111,a=0.9649) | Val(l=0.9076,a=0.5235)
2025-06-02 22:16:21,900 - INFO - Epoch 62: Train(l=0.1064,a=0.9680) | Val(l=0.7413,a=0.7371)
2025-06-02 22:16:22,227 - INFO - Epoch 63: Train(l=0.1012,a=0.9680) | Val(l=0.4280,a=0.8404)
2025-06-02 22:16:22,596 - INFO - Epoch 64: Train(l=0.0998,a=0.9685) | Val(l=0.4240,a=0.8404)
2025-06-02 22:16:22,898 - INFO - Epoch 65: Train(l=0.0979,a=0.9727) | Val(l=0.5487,a=0.7958)
2025-06-02 22:16:23,229 - INFO - Epoch 66: Train(l=0.0958,a=0.9716) | Val(l=0.6145,a=0.7840)
2025-06-02 22:16:23,582 - INFO - Epoch 67: Train(l=0.0941,a=0.9737) | Val(l=0.4305,a=0.8333)
2025-06-02 22:16:23,832 - INFO - Epoch 68: Train(l=0.0901,a=0.9696) | Val(l=0.4612,a=0.8263)
2025-06-02 22:16:24,080 - INFO - Epoch 69: Train(l=0.0918,a=0.9716) | Val(l=0.3603,a=0.8685)
2025-06-02 22:16:24,350 - INFO - Epoch 70: Train(l=0.0887,a=0.9727) | Val(l=0.3670,a=0.8709)
2025-06-02 22:16:24,614 - INFO - Epoch 71: Train(l=0.0858,a=0.9732) | Val(l=0.3524,a=0.8779)
2025-06-02 22:16:24,615 - INFO - Early stopping.
2025-06-02 22:16:34,239 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 22:16:46,347 - INFO - Validation MSE: 10.973536
2025-06-02 22:16:46,348 - INFO - Total training time: 196.10s
2025-06-02 22:16:46,348 - INFO - Validation MCC: 0.4321, AUC: 0.8377
2025-06-02 22:16:46,349 - INFO - Test       MCC: 0.4093, AUC: 0.8288
2025-06-02 22:34:58,513 - INFO - Training DBN...
2025-06-02 22:34:59,317 - INFO - Starting DBN pre-training...
2025-06-02 22:34:59,318 - INFO - Pre-training RBM layer 1/3
2025-06-02 22:34:59,843 - INFO -  RBM1 Epoch 0: Loss=1.5696
2025-06-02 22:35:00,813 - INFO -  RBM1 Epoch 10: Loss=1.1554
2025-06-02 22:35:02,602 - INFO -  RBM1 Epoch 20: Loss=1.1011
2025-06-02 22:35:03,669 - INFO -  RBM1 Epoch 30: Loss=1.0902
2025-06-02 22:35:04,657 - INFO -  RBM1 Epoch 40: Loss=1.0981
2025-06-02 22:35:05,808 - INFO -  RBM1 Epoch 50: Loss=1.0960
2025-06-02 22:35:08,190 - INFO -  RBM1 Epoch 60: Loss=1.1072
2025-06-02 22:35:09,535 - INFO -  RBM1 Epoch 70: Loss=1.1105
2025-06-02 22:35:10,806 - INFO -  RBM1 Epoch 80: Loss=1.1153
2025-06-02 22:35:12,294 - INFO -  RBM1 Epoch 90: Loss=1.1172
2025-06-02 22:35:13,937 - INFO - Pre-training RBM layer 2/3
2025-06-02 22:35:14,078 - INFO -  RBM2 Epoch 0: Loss=0.4346
2025-06-02 22:35:15,489 - INFO -  RBM2 Epoch 10: Loss=0.4098
2025-06-02 22:35:16,947 - INFO -  RBM2 Epoch 20: Loss=0.4022
2025-06-02 22:35:18,299 - INFO -  RBM2 Epoch 30: Loss=0.3930
2025-06-02 22:35:19,501 - INFO -  RBM2 Epoch 40: Loss=0.3833
2025-06-02 22:35:20,687 - INFO -  RBM2 Epoch 50: Loss=0.3753
2025-06-02 22:35:23,209 - INFO -  RBM2 Epoch 60: Loss=0.3698
2025-06-02 22:35:24,795 - INFO -  RBM2 Epoch 70: Loss=0.3645
2025-06-02 22:35:26,089 - INFO -  RBM2 Epoch 80: Loss=0.3612
2025-06-02 22:35:27,328 - INFO -  RBM2 Epoch 90: Loss=0.3581
2025-06-02 22:35:28,729 - INFO - Pre-training RBM layer 3/3
2025-06-02 22:35:28,779 - INFO -  RBM3 Epoch 0: Loss=0.3847
2025-06-02 22:35:29,335 - INFO -  RBM3 Epoch 10: Loss=0.2470
2025-06-02 22:35:29,803 - INFO -  RBM3 Epoch 20: Loss=0.2009
2025-06-02 22:35:30,335 - INFO -  RBM3 Epoch 30: Loss=0.1926
2025-06-02 22:35:32,107 - INFO -  RBM3 Epoch 40: Loss=0.1895
2025-06-02 22:35:32,530 - INFO -  RBM3 Epoch 50: Loss=0.1880
2025-06-02 22:35:32,990 - INFO -  RBM3 Epoch 60: Loss=0.1879
2025-06-02 22:35:33,441 - INFO -  RBM3 Epoch 70: Loss=0.1863
2025-06-02 22:35:33,929 - INFO -  RBM3 Epoch 80: Loss=0.1868
2025-06-02 22:35:34,445 - INFO -  RBM3 Epoch 90: Loss=0.1863
2025-06-02 22:35:34,955 - INFO - Starting DBN fine-tuning...
2025-06-02 22:36:04,204 - INFO - Epoch 0: Train(l=0.5864,a=0.4216) | Val(l=0.6309,a=0.9272)
2025-06-02 22:36:04,330 - INFO - Epoch 1: Train(l=0.5681,a=0.5031) | Val(l=0.7388,a=0.0728)
2025-06-02 22:36:04,471 - INFO - Epoch 2: Train(l=0.5669,a=0.5273) | Val(l=0.7288,a=0.0728)
2025-06-02 22:36:04,614 - INFO - Epoch 3: Train(l=0.5693,a=0.4928) | Val(l=0.7080,a=0.0728)
2025-06-02 22:36:04,756 - INFO - Epoch 4: Train(l=0.5664,a=0.5206) | Val(l=0.6984,a=0.0728)
2025-06-02 22:36:04,893 - INFO - Epoch 5: Train(l=0.5645,a=0.5021) | Val(l=0.6933,a=0.0728)
2025-06-02 22:36:05,059 - INFO - Epoch 6: Train(l=0.5604,a=0.5144) | Val(l=0.7021,a=0.0728)
2025-06-02 22:36:05,188 - INFO - Epoch 7: Train(l=0.5645,a=0.4933) | Val(l=0.6961,a=0.0728)
2025-06-02 22:36:05,326 - INFO - Epoch 8: Train(l=0.5560,a=0.5114) | Val(l=0.7045,a=0.0728)
2025-06-02 22:36:05,461 - INFO - Epoch 9: Train(l=0.5613,a=0.4964) | Val(l=0.7100,a=0.0728)
2025-06-02 22:36:05,603 - INFO - Epoch 10: Train(l=0.5627,a=0.4933) | Val(l=0.7053,a=0.0728)
2025-06-02 22:36:05,742 - INFO - Epoch 11: Train(l=0.5572,a=0.5335) | Val(l=0.7050,a=0.0728)
2025-06-02 22:36:06,189 - INFO - Epoch 12: Train(l=0.5625,a=0.5072) | Val(l=0.6969,a=0.3169)
2025-06-02 22:36:06,383 - INFO - Epoch 13: Train(l=0.5588,a=0.5191) | Val(l=0.6931,a=0.3498)
2025-06-02 22:36:06,571 - INFO - Epoch 14: Train(l=0.5625,a=0.5114) | Val(l=0.6936,a=0.3498)
2025-06-02 22:36:06,751 - INFO - Epoch 15: Train(l=0.5571,a=0.5253) | Val(l=0.6987,a=0.3169)
2025-06-02 22:36:06,935 - INFO - Epoch 16: Train(l=0.5614,a=0.5067) | Val(l=0.7044,a=0.2441)
2025-06-02 22:36:07,156 - INFO - Epoch 17: Train(l=0.5601,a=0.5206) | Val(l=0.7058,a=0.2441)
2025-06-02 22:36:07,439 - INFO - Epoch 18: Train(l=0.5571,a=0.5361) | Val(l=0.7075,a=0.2441)
2025-06-02 22:36:07,628 - INFO - Epoch 19: Train(l=0.5604,a=0.5258) | Val(l=0.7071,a=0.2488)
2025-06-02 22:36:07,804 - INFO - Epoch 20: Train(l=0.5549,a=0.5402) | Val(l=0.7075,a=0.2488)
2025-06-02 22:36:07,805 - INFO - Early stopping.
2025-06-02 22:37:43,269 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 22:37:55,275 - INFO - Validation MSE: 0.069040
2025-06-02 22:37:55,275 - INFO - Total training time: 176.76s
2025-06-02 22:37:55,276 - INFO - Validation MCC: 0.0000, AUC: 0.5757
2025-06-02 22:37:55,276 - INFO - Test       MCC: 0.0000, AUC: 0.6089
2025-06-02 22:40:58,064 - INFO - Training DBN...
2025-06-02 22:40:58,939 - INFO - Starting DBN pre-training...
2025-06-02 22:40:58,940 - INFO - Pre-training RBM layer 1/3
2025-06-02 22:40:59,511 - INFO -  RBM1 Epoch 0: Loss=1.5570
2025-06-02 22:41:00,709 - INFO -  RBM1 Epoch 10: Loss=1.1429
2025-06-02 22:41:02,362 - INFO -  RBM1 Epoch 20: Loss=1.1072
2025-06-02 22:41:04,373 - INFO -  RBM1 Epoch 30: Loss=1.0985
2025-06-02 22:41:05,677 - INFO -  RBM1 Epoch 40: Loss=1.0936
2025-06-02 22:41:07,226 - INFO -  RBM1 Epoch 50: Loss=1.0902
2025-06-02 22:41:09,423 - INFO -  RBM1 Epoch 60: Loss=1.0986
2025-06-02 22:41:10,919 - INFO -  RBM1 Epoch 70: Loss=1.1072
2025-06-02 22:41:12,444 - INFO -  RBM1 Epoch 80: Loss=1.1181
2025-06-02 22:41:14,305 - INFO -  RBM1 Epoch 90: Loss=1.1147
2025-06-02 22:41:16,106 - INFO - Pre-training RBM layer 2/3
2025-06-02 22:41:16,235 - INFO -  RBM2 Epoch 0: Loss=0.4342
2025-06-02 22:41:17,315 - INFO -  RBM2 Epoch 10: Loss=0.4087
2025-06-02 22:41:19,218 - INFO -  RBM2 Epoch 20: Loss=0.3998
2025-06-02 22:41:20,593 - INFO -  RBM2 Epoch 30: Loss=0.3908
2025-06-02 22:41:21,904 - INFO -  RBM2 Epoch 40: Loss=0.3806
2025-06-02 22:41:23,681 - INFO -  RBM2 Epoch 50: Loss=0.3717
2025-06-02 22:41:25,255 - INFO -  RBM2 Epoch 60: Loss=0.3671
2025-06-02 22:41:26,691 - INFO -  RBM2 Epoch 70: Loss=0.3631
2025-06-02 22:41:28,073 - INFO -  RBM2 Epoch 80: Loss=0.3598
2025-06-02 22:41:29,817 - INFO -  RBM2 Epoch 90: Loss=0.3579
2025-06-02 22:41:31,576 - INFO - Pre-training RBM layer 3/3
2025-06-02 22:41:31,649 - INFO -  RBM3 Epoch 0: Loss=0.3858
2025-06-02 22:41:32,733 - INFO -  RBM3 Epoch 10: Loss=0.2457
2025-06-02 22:41:33,722 - INFO -  RBM3 Epoch 20: Loss=0.2006
2025-06-02 22:41:34,796 - INFO -  RBM3 Epoch 30: Loss=0.1924
2025-06-02 22:41:36,470 - INFO -  RBM3 Epoch 40: Loss=0.1911
2025-06-02 22:41:38,167 - INFO -  RBM3 Epoch 50: Loss=0.1883
2025-06-02 22:41:40,096 - INFO -  RBM3 Epoch 60: Loss=0.1878
2025-06-02 22:41:41,747 - INFO -  RBM3 Epoch 70: Loss=0.1873
2025-06-02 22:41:43,506 - INFO -  RBM3 Epoch 80: Loss=0.1868
2025-06-02 22:41:45,266 - INFO -  RBM3 Epoch 90: Loss=0.1868
2025-06-02 22:41:46,578 - INFO - Starting DBN fine-tuning...
2025-06-02 22:42:14,888 - INFO - Epoch 0: Train(l=0.5561,a=0.5960) | Val(l=0.7510,a=0.0728)
2025-06-02 22:42:15,172 - INFO - Epoch 1: Train(l=0.5435,a=0.6269) | Val(l=0.7237,a=0.4296)
2025-06-02 22:42:15,466 - INFO - Epoch 2: Train(l=0.5269,a=0.6414) | Val(l=0.6679,a=0.5540)
2025-06-02 22:42:15,776 - INFO - Epoch 3: Train(l=0.5251,a=0.6471) | Val(l=0.6081,a=0.6878)
2025-06-02 22:42:16,157 - INFO - Epoch 4: Train(l=0.5204,a=0.6517) | Val(l=0.5688,a=0.7958)
2025-06-02 22:42:16,619 - INFO - Epoch 5: Train(l=0.5150,a=0.6507) | Val(l=0.5465,a=0.8709)
2025-06-02 22:42:16,916 - INFO - Epoch 6: Train(l=0.5089,a=0.6620) | Val(l=0.5348,a=0.8169)
2025-06-02 22:42:17,214 - INFO - Epoch 7: Train(l=0.5113,a=0.6620) | Val(l=0.5313,a=0.7488)
2025-06-02 22:42:17,512 - INFO - Epoch 8: Train(l=0.5091,a=0.6589) | Val(l=0.5403,a=0.6972)
2025-06-02 22:42:17,827 - INFO - Epoch 9: Train(l=0.5058,a=0.6662) | Val(l=0.5452,a=0.6972)
2025-06-02 22:42:18,142 - INFO - Epoch 10: Train(l=0.5031,a=0.6651) | Val(l=0.5581,a=0.6901)
2025-06-02 22:42:18,422 - INFO - Epoch 11: Train(l=0.5086,a=0.6662) | Val(l=0.5669,a=0.6925)
2025-06-02 22:42:18,725 - INFO - Epoch 12: Train(l=0.5098,a=0.6569) | Val(l=0.5702,a=0.6925)
2025-06-02 22:42:18,994 - INFO - Epoch 13: Train(l=0.5032,a=0.6625) | Val(l=0.5620,a=0.6901)
2025-06-02 22:42:19,292 - INFO - Epoch 14: Train(l=0.5041,a=0.6651) | Val(l=0.6050,a=0.6549)
2025-06-02 22:42:19,604 - INFO - Epoch 15: Train(l=0.4904,a=0.6801) | Val(l=0.5731,a=0.6878)
2025-06-02 22:42:19,891 - INFO - Epoch 16: Train(l=0.4860,a=0.6760) | Val(l=0.5226,a=0.7535)
2025-06-02 22:42:20,229 - INFO - Epoch 17: Train(l=0.4836,a=0.6878) | Val(l=0.6481,a=0.5822)
2025-06-02 22:42:20,549 - INFO - Epoch 18: Train(l=0.4705,a=0.6940) | Val(l=0.7584,a=0.5164)
2025-06-02 22:42:20,860 - INFO - Epoch 19: Train(l=0.4502,a=0.7131) | Val(l=0.7615,a=0.5493)
2025-06-02 22:42:21,182 - INFO - Epoch 20: Train(l=0.4228,a=0.7637) | Val(l=1.0357,a=0.4085)
2025-06-02 22:42:21,546 - INFO - Epoch 21: Train(l=0.3857,a=0.8044) | Val(l=1.0904,a=0.2254)
2025-06-02 22:42:21,931 - INFO - Epoch 22: Train(l=0.3427,a=0.8457) | Val(l=1.6118,a=0.1761)
2025-06-02 22:42:22,298 - INFO - Epoch 23: Train(l=0.3048,a=0.8643) | Val(l=1.0909,a=0.5376)
2025-06-02 22:42:22,713 - INFO - Epoch 24: Train(l=0.2800,a=0.8741) | Val(l=0.9489,a=0.5986)
2025-06-02 22:42:23,109 - INFO - Epoch 25: Train(l=0.2625,a=0.8865) | Val(l=0.6970,a=0.6620)
2025-06-02 22:42:23,458 - INFO - Epoch 26: Train(l=0.2492,a=0.8922) | Val(l=0.6112,a=0.7230)
2025-06-02 22:42:23,754 - INFO - Epoch 27: Train(l=0.2412,a=0.8916) | Val(l=0.3898,a=0.8239)
2025-06-02 22:42:24,047 - INFO - Epoch 28: Train(l=0.2369,a=0.8973) | Val(l=0.4088,a=0.8122)
2025-06-02 22:42:24,334 - INFO - Epoch 29: Train(l=0.2350,a=0.9025) | Val(l=0.4002,a=0.8216)
2025-06-02 22:42:24,630 - INFO - Epoch 30: Train(l=0.2311,a=0.8989) | Val(l=0.4208,a=0.8122)
2025-06-02 22:42:24,956 - INFO - Epoch 31: Train(l=0.2328,a=0.9020) | Val(l=0.4317,a=0.8122)
2025-06-02 22:42:25,359 - INFO - Epoch 32: Train(l=0.2303,a=0.9004) | Val(l=0.4287,a=0.8122)
2025-06-02 22:42:25,646 - INFO - Epoch 33: Train(l=0.2280,a=0.8994) | Val(l=0.4036,a=0.8122)
2025-06-02 22:42:25,956 - INFO - Epoch 34: Train(l=0.2233,a=0.9045) | Val(l=0.4262,a=0.7887)
2025-06-02 22:42:26,241 - INFO - Epoch 35: Train(l=0.2146,a=0.9123) | Val(l=0.8984,a=0.6667)
2025-06-02 22:42:26,519 - INFO - Epoch 36: Train(l=0.2090,a=0.9066) | Val(l=0.6072,a=0.7183)
2025-06-02 22:42:26,824 - INFO - Epoch 37: Train(l=0.2034,a=0.9174) | Val(l=0.6151,a=0.7254)
2025-06-02 22:42:27,105 - INFO - Epoch 38: Train(l=0.1939,a=0.9200) | Val(l=0.9123,a=0.4413)
2025-06-02 22:42:27,394 - INFO - Epoch 39: Train(l=0.1823,a=0.9236) | Val(l=1.3043,a=0.3991)
2025-06-02 22:42:27,683 - INFO - Epoch 40: Train(l=0.1692,a=0.9350) | Val(l=1.3500,a=0.4085)
2025-06-02 22:42:27,990 - INFO - Epoch 41: Train(l=0.1667,a=0.9350) | Val(l=1.4888,a=0.3944)
2025-06-02 22:42:28,278 - INFO - Epoch 42: Train(l=0.1478,a=0.9463) | Val(l=1.0535,a=0.4390)
2025-06-02 22:42:28,563 - INFO - Epoch 43: Train(l=0.1444,a=0.9499) | Val(l=1.2720,a=0.4624)
2025-06-02 22:42:28,854 - INFO - Epoch 44: Train(l=0.1342,a=0.9567) | Val(l=1.1924,a=0.4695)
2025-06-02 22:42:29,123 - INFO - Epoch 45: Train(l=0.1278,a=0.9541) | Val(l=0.7933,a=0.5563)
2025-06-02 22:42:29,435 - INFO - Epoch 46: Train(l=0.1229,a=0.9598) | Val(l=0.9012,a=0.5540)
2025-06-02 22:42:29,736 - INFO - Epoch 47: Train(l=0.1207,a=0.9561) | Val(l=0.3666,a=0.8685)
2025-06-02 22:42:30,038 - INFO - Epoch 48: Train(l=0.1154,a=0.9670) | Val(l=0.5558,a=0.8052)
2025-06-02 22:42:30,312 - INFO - Epoch 49: Train(l=0.1161,a=0.9592) | Val(l=0.4032,a=0.8521)
2025-06-02 22:42:30,588 - INFO - Epoch 50: Train(l=0.1160,a=0.9592) | Val(l=0.3767,a=0.8615)
2025-06-02 22:42:30,891 - INFO - Epoch 51: Train(l=0.1155,a=0.9618) | Val(l=0.3089,a=0.8897)
2025-06-02 22:42:31,160 - INFO - Epoch 52: Train(l=0.1174,a=0.9634) | Val(l=0.3521,a=0.8709)
2025-06-02 22:42:31,451 - INFO - Epoch 53: Train(l=0.1137,a=0.9608) | Val(l=0.4437,a=0.8474)
2025-06-02 22:42:31,759 - INFO - Epoch 54: Train(l=0.1097,a=0.9623) | Val(l=0.4529,a=0.8333)
2025-06-02 22:42:32,063 - INFO - Epoch 55: Train(l=0.1051,a=0.9628) | Val(l=0.4132,a=0.8380)
2025-06-02 22:42:32,327 - INFO - Epoch 56: Train(l=0.1096,a=0.9608) | Val(l=0.3211,a=0.8732)
2025-06-02 22:42:32,607 - INFO - Epoch 57: Train(l=0.1042,a=0.9665) | Val(l=0.4166,a=0.8521)
2025-06-02 22:42:32,908 - INFO - Epoch 58: Train(l=0.1059,a=0.9649) | Val(l=0.7977,a=0.6080)
2025-06-02 22:42:33,178 - INFO - Epoch 59: Train(l=0.0989,a=0.9670) | Val(l=1.2582,a=0.4883)
2025-06-02 22:42:33,453 - INFO - Epoch 60: Train(l=0.0967,a=0.9665) | Val(l=1.2639,a=0.4977)
2025-06-02 22:42:33,761 - INFO - Epoch 61: Train(l=0.0878,a=0.9727) | Val(l=1.1071,a=0.5211)
2025-06-02 22:42:34,051 - INFO - Epoch 62: Train(l=0.0862,a=0.9716) | Val(l=0.9561,a=0.5986)
2025-06-02 22:42:34,335 - INFO - Epoch 63: Train(l=0.0849,a=0.9742) | Val(l=0.7869,a=0.5892)
2025-06-02 22:42:34,618 - INFO - Epoch 64: Train(l=0.0791,a=0.9737) | Val(l=1.2948,a=0.4859)
2025-06-02 22:42:34,913 - INFO - Epoch 65: Train(l=0.0754,a=0.9721) | Val(l=0.8380,a=0.6221)
2025-06-02 22:42:35,161 - INFO - Epoch 66: Train(l=0.0787,a=0.9737) | Val(l=0.2575,a=0.9108)
2025-06-02 22:42:35,440 - INFO - Epoch 67: Train(l=0.0862,a=0.9711) | Val(l=0.6099,a=0.8216)
2025-06-02 22:42:35,729 - INFO - Epoch 68: Train(l=0.0720,a=0.9757) | Val(l=0.2999,a=0.8944)
2025-06-02 22:42:36,011 - INFO - Epoch 69: Train(l=0.0729,a=0.9773) | Val(l=0.3688,a=0.8803)
2025-06-02 22:42:36,313 - INFO - Epoch 70: Train(l=0.0725,a=0.9783) | Val(l=0.3673,a=0.8803)
2025-06-02 22:42:36,691 - INFO - Epoch 71: Train(l=0.0706,a=0.9747) | Val(l=0.4374,a=0.8662)
2025-06-02 22:42:37,038 - INFO - Epoch 72: Train(l=0.0692,a=0.9747) | Val(l=0.4636,a=0.8592)
2025-06-02 22:42:37,368 - INFO - Epoch 73: Train(l=0.0683,a=0.9757) | Val(l=0.3448,a=0.8803)
2025-06-02 22:42:37,798 - INFO - Epoch 74: Train(l=0.0723,a=0.9757) | Val(l=0.7303,a=0.7817)
2025-06-02 22:42:38,085 - INFO - Epoch 75: Train(l=0.0712,a=0.9763) | Val(l=0.8866,a=0.6643)
2025-06-02 22:42:38,360 - INFO - Epoch 76: Train(l=0.0821,a=0.9732) | Val(l=0.8192,a=0.6408)
2025-06-02 22:42:38,687 - INFO - Epoch 77: Train(l=0.0691,a=0.9783) | Val(l=0.8665,a=0.6174)
2025-06-02 22:42:39,017 - INFO - Epoch 78: Train(l=0.0669,a=0.9794) | Val(l=1.5540,a=0.4765)
2025-06-02 22:42:39,265 - INFO - Epoch 79: Train(l=0.0650,a=0.9778) | Val(l=1.9424,a=0.4437)
2025-06-02 22:42:39,534 - INFO - Epoch 80: Train(l=0.0871,a=0.9696) | Val(l=1.0809,a=0.5845)
2025-06-02 22:42:39,832 - INFO - Epoch 81: Train(l=0.0626,a=0.9804) | Val(l=1.6897,a=0.4765)
2025-06-02 22:42:40,099 - INFO - Epoch 82: Train(l=0.0652,a=0.9773) | Val(l=1.2678,a=0.5329)
2025-06-02 22:42:40,373 - INFO - Epoch 83: Train(l=0.0544,a=0.9825) | Val(l=0.9244,a=0.6056)
2025-06-02 22:42:40,625 - INFO - Epoch 84: Train(l=0.0576,a=0.9830) | Val(l=1.0232,a=0.5798)
2025-06-02 22:42:40,924 - INFO - Epoch 85: Train(l=0.0513,a=0.9814) | Val(l=0.5531,a=0.7911)
2025-06-02 22:42:41,181 - INFO - Epoch 86: Train(l=0.0499,a=0.9861) | Val(l=0.3687,a=0.8873)
2025-06-02 22:42:41,182 - INFO - Early stopping.
2025-06-02 22:42:52,892 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 22:43:08,877 - INFO - Validation MSE: 14.579190
2025-06-02 22:43:08,878 - INFO - Total training time: 130.81s
2025-06-02 22:43:08,878 - INFO - Validation MCC: 0.4256, AUC: 0.8159
2025-06-02 22:43:08,879 - INFO - Test       MCC: 0.3412, AUC: 0.8006
2025-06-02 22:46:40,863 - INFO - Training DBN...
2025-06-02 22:46:41,675 - INFO - Starting DBN pre-training...
2025-06-02 22:46:41,675 - INFO -  Pre-training RBM layer 1/3
2025-06-02 22:46:42,308 - INFO -   RBM1 Epoch 0: Loss=1.5722
2025-06-02 22:46:44,349 - INFO -   RBM1 Epoch 10: Loss=1.1930
2025-06-02 22:46:46,256 - INFO -   RBM1 Epoch 20: Loss=1.1081
2025-06-02 22:46:48,256 - INFO -   RBM1 Epoch 30: Loss=1.0902
2025-06-02 22:46:50,402 - INFO -   RBM1 Epoch 40: Loss=1.0916
2025-06-02 22:46:53,520 - INFO -   RBM1 Epoch 50: Loss=1.1029
2025-06-02 22:46:56,033 - INFO -   RBM1 Epoch 60: Loss=1.1135
2025-06-02 22:46:58,307 - INFO -   RBM1 Epoch 70: Loss=1.1109
2025-06-02 22:47:00,937 - INFO -   RBM1 Epoch 80: Loss=1.1275
2025-06-02 22:47:05,137 - INFO -   RBM1 Epoch 90: Loss=1.1189
2025-06-02 22:47:09,304 - INFO -  Pre-training RBM layer 2/3
2025-06-02 22:47:09,805 - INFO -   RBM2 Epoch 0: Loss=0.4368
2025-06-02 22:47:13,401 - INFO -   RBM2 Epoch 10: Loss=0.4245
2025-06-02 22:47:17,028 - INFO -   RBM2 Epoch 20: Loss=0.4223
2025-06-02 22:47:20,195 - INFO -   RBM2 Epoch 30: Loss=0.4207
2025-06-02 22:47:23,647 - INFO -   RBM2 Epoch 40: Loss=0.4197
2025-06-02 22:47:26,825 - INFO -   RBM2 Epoch 50: Loss=0.4189
2025-06-02 22:47:29,881 - INFO -   RBM2 Epoch 60: Loss=0.4162
2025-06-02 22:47:33,695 - INFO -   RBM2 Epoch 70: Loss=0.4166
2025-06-02 22:47:38,427 - INFO -   RBM2 Epoch 80: Loss=0.4172
2025-06-02 22:47:41,530 - INFO -   RBM2 Epoch 90: Loss=0.4159
2025-06-02 22:47:43,606 - INFO -  Pre-training RBM layer 3/3
2025-06-02 22:47:43,771 - INFO -   RBM3 Epoch 0: Loss=0.3752
2025-06-02 22:47:45,427 - INFO -   RBM3 Epoch 10: Loss=0.2618
2025-06-02 22:47:46,581 - INFO -   RBM3 Epoch 20: Loss=0.2148
2025-06-02 22:47:48,324 - INFO -   RBM3 Epoch 30: Loss=0.2071
2025-06-02 22:47:49,584 - INFO -   RBM3 Epoch 40: Loss=0.2054
2025-06-02 22:47:50,749 - INFO -   RBM3 Epoch 50: Loss=0.2035
2025-06-02 22:47:52,944 - INFO -   RBM3 Epoch 60: Loss=0.2041
2025-06-02 22:47:54,864 - INFO -   RBM3 Epoch 70: Loss=0.2024
2025-06-02 22:47:57,468 - INFO -   RBM3 Epoch 80: Loss=0.2022
2025-06-02 22:47:59,256 - INFO -   RBM3 Epoch 90: Loss=0.2020
2025-06-02 22:48:01,294 - INFO - Starting DBN fine-tuning...
2025-06-02 22:50:04,160 - INFO - Training DBN...
2025-06-02 22:50:04,484 - INFO - Starting DBN pre-training...
2025-06-02 22:50:04,723 - INFO -  RBM1 Epoch 0: Loss=1.5698
2025-06-02 22:50:06,896 - INFO -  RBM1 Epoch 10: Loss=1.1850
2025-06-02 22:50:09,431 - INFO -  RBM1 Epoch 20: Loss=1.1158
2025-06-02 22:50:12,360 - INFO -  RBM1 Epoch 30: Loss=1.1002
2025-06-02 22:50:15,289 - INFO -  RBM1 Epoch 40: Loss=1.0946
2025-06-02 22:50:19,094 - INFO -  RBM1 Epoch 50: Loss=1.1027
2025-06-02 22:50:22,721 - INFO -  RBM1 Epoch 60: Loss=1.1052
2025-06-02 22:50:27,101 - INFO -  RBM1 Epoch 70: Loss=1.1092
2025-06-02 22:50:30,631 - INFO -  RBM1 Epoch 80: Loss=1.1235
2025-06-02 22:50:33,449 - INFO -  RBM1 Epoch 90: Loss=1.1265
2025-06-02 22:50:37,515 - INFO -  RBM2 Epoch 0: Loss=0.4359
2025-06-02 22:50:41,074 - INFO -  RBM2 Epoch 10: Loss=0.4246
2025-06-02 22:50:44,774 - INFO -  RBM2 Epoch 20: Loss=0.4233
2025-06-02 22:50:48,436 - INFO -  RBM2 Epoch 30: Loss=0.4203
2025-06-02 22:50:52,115 - INFO -  RBM2 Epoch 40: Loss=0.4192
2025-06-02 22:50:58,471 - INFO -  RBM2 Epoch 50: Loss=0.4180
2025-06-02 22:51:11,531 - INFO -  RBM2 Epoch 60: Loss=0.4175
2025-06-02 22:51:20,585 - INFO -  RBM2 Epoch 70: Loss=0.4161
2025-06-02 22:51:25,087 - INFO -  RBM2 Epoch 80: Loss=0.4159
2025-06-02 22:51:27,835 - INFO -  RBM2 Epoch 90: Loss=0.4153
2025-06-02 22:51:31,124 - INFO -  RBM3 Epoch 0: Loss=0.3811
2025-06-02 22:51:32,617 - INFO -  RBM3 Epoch 10: Loss=0.2608
2025-06-02 22:51:35,174 - INFO -  RBM3 Epoch 20: Loss=0.2105
2025-06-02 22:51:39,971 - INFO -  RBM3 Epoch 30: Loss=0.2047
2025-06-02 22:51:44,869 - INFO -  RBM3 Epoch 40: Loss=0.2013
2025-06-02 22:51:50,044 - INFO -  RBM3 Epoch 50: Loss=0.2004
2025-06-02 22:51:57,931 - INFO -  RBM3 Epoch 60: Loss=0.1998
2025-06-02 22:52:12,001 - INFO -  RBM3 Epoch 70: Loss=0.1992
2025-06-02 22:52:18,030 - INFO -  RBM3 Epoch 80: Loss=0.1982
2025-06-02 22:52:20,826 - INFO -  RBM3 Epoch 90: Loss=0.1976
2025-06-02 22:52:23,563 - INFO - Starting DBN fine-tuning...
2025-06-02 22:52:48,942 - INFO - Ep 0: Train(l=0.0024,a=0.5557) | Val(l=0.7105,a=0.0728) | LR=1.00e-04
2025-06-02 22:52:49,221 - INFO - Ep 1: Train(l=0.0023,a=0.6094) | Val(l=0.7125,a=0.0751) | LR=1.00e-04
2025-06-02 22:52:49,514 - INFO - Ep 2: Train(l=0.0022,a=0.6352) | Val(l=0.7162,a=0.0986) | LR=1.00e-04
2025-06-02 22:52:49,808 - INFO - Ep 3: Train(l=0.0022,a=0.6419) | Val(l=0.7242,a=0.1033) | LR=1.00e-04
2025-06-02 22:52:50,177 - INFO - Ep 4: Train(l=0.0022,a=0.6414) | Val(l=0.7394,a=0.1009) | LR=1.00e-04
2025-06-02 22:52:50,533 - INFO - Ep 5: Train(l=0.0021,a=0.6594) | Val(l=0.7500,a=0.1009) | LR=1.00e-04
2025-06-02 22:52:50,845 - INFO - Ep 6: Train(l=0.0021,a=0.6512) | Val(l=0.7479,a=0.1009) | LR=5.00e-05
2025-06-02 22:52:51,242 - INFO - Ep 7: Train(l=0.0022,a=0.6677) | Val(l=0.7515,a=0.1056) | LR=5.00e-05
2025-06-02 22:52:51,604 - INFO - Ep 8: Train(l=0.0022,a=0.6563) | Val(l=0.7555,a=0.1690) | LR=5.00e-05
2025-06-02 22:52:52,027 - INFO - Ep 9: Train(l=0.0021,a=0.6538) | Val(l=0.7559,a=0.4014) | LR=5.00e-05
2025-06-02 22:52:52,456 - INFO - Ep 10: Train(l=0.0021,a=0.6641) | Val(l=0.7578,a=0.4014) | LR=5.00e-05
2025-06-02 22:52:52,835 - INFO - Ep 11: Train(l=0.0021,a=0.6620) | Val(l=0.7571,a=0.4014) | LR=5.00e-05
2025-06-02 22:52:53,311 - INFO - Ep 12: Train(l=0.0021,a=0.6656) | Val(l=0.7433,a=0.4014) | LR=2.50e-05
2025-06-02 22:52:53,894 - INFO - Ep 13: Train(l=0.0021,a=0.6610) | Val(l=0.6870,a=0.4061) | LR=2.50e-05
2025-06-02 22:52:54,327 - INFO - Ep 14: Train(l=0.0021,a=0.6563) | Val(l=0.6338,a=0.8615) | LR=2.50e-05
2025-06-02 22:52:54,698 - INFO - Ep 15: Train(l=0.0021,a=0.6698) | Val(l=0.6264,a=0.8897) | LR=2.50e-05
2025-06-02 22:52:55,033 - INFO - Ep 16: Train(l=0.0021,a=0.6765) | Val(l=0.6627,a=0.8357) | LR=2.50e-05
2025-06-02 22:52:55,408 - INFO - Ep 17: Train(l=0.0020,a=0.6847) | Val(l=0.6962,a=0.2606) | LR=2.50e-05
2025-06-02 22:52:55,762 - INFO - Ep 18: Train(l=0.0021,a=0.6858) | Val(l=0.7025,a=0.2817) | LR=2.50e-05
2025-06-02 22:52:56,181 - INFO - Ep 19: Train(l=0.0021,a=0.6579) | Val(l=0.6814,a=0.2817) | LR=2.50e-05
2025-06-02 22:52:56,590 - INFO - Ep 20: Train(l=0.0021,a=0.6816) | Val(l=0.6581,a=0.6714) | LR=2.50e-05
2025-06-02 22:52:56,945 - INFO - Ep 21: Train(l=0.0020,a=0.6889) | Val(l=0.6336,a=0.6714) | LR=1.25e-05
2025-06-02 22:52:57,359 - INFO - Ep 22: Train(l=0.0020,a=0.6930) | Val(l=0.6512,a=0.6197) | LR=1.25e-05
2025-06-02 22:52:57,797 - INFO - Ep 23: Train(l=0.0020,a=0.6930) | Val(l=0.6587,a=0.6221) | LR=1.25e-05
2025-06-02 22:52:58,209 - INFO - Ep 24: Train(l=0.0020,a=0.6816) | Val(l=0.6855,a=0.6197) | LR=1.25e-05
2025-06-02 22:52:58,644 - INFO - Ep 25: Train(l=0.0020,a=0.6904) | Val(l=0.7204,a=0.6197) | LR=1.25e-05
2025-06-02 22:52:59,034 - INFO - Ep 26: Train(l=0.0020,a=0.6950) | Val(l=0.7572,a=0.6221) | LR=1.25e-05
2025-06-02 22:52:59,432 - INFO - Ep 27: Train(l=0.0020,a=0.6971) | Val(l=0.7810,a=0.6221) | LR=6.25e-06
2025-06-02 22:52:59,810 - INFO - Ep 28: Train(l=0.0020,a=0.6914) | Val(l=0.7693,a=0.6221) | LR=6.25e-06
2025-06-02 22:53:00,296 - INFO - Ep 29: Train(l=0.0020,a=0.6997) | Val(l=0.7610,a=0.6197) | LR=6.25e-06
2025-06-02 22:53:00,739 - INFO - Ep 30: Train(l=0.0020,a=0.7152) | Val(l=0.7765,a=0.6221) | LR=6.25e-06
2025-06-02 22:53:00,740 - INFO - Early stopping.
2025-06-02 22:53:00,741 - INFO - Training finished.
2025-06-02 22:53:20,416 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 22:53:30,038 - INFO - Validation MSE: 0.504670
2025-06-02 22:53:30,039 - INFO - Total training time: 205.88s
2025-06-02 22:53:30,039 - INFO - Validation MCC: 0.0735, AUC: 0.6552
2025-06-02 22:53:30,039 - INFO - Test       MCC: 0.1763, AUC: 0.7022
2025-06-02 22:55:21,843 - INFO - Training DBN...
2025-06-02 22:55:22,183 - INFO - Starting DBN pre-training...
2025-06-02 22:55:22,183 - INFO - Pre-training RBM layer 1/3
2025-06-02 22:55:22,396 - INFO -  RBM1 Epoch 0: Loss=1.5597
2025-06-02 22:55:23,669 - INFO -  RBM1 Epoch 10: Loss=1.1554
2025-06-02 22:55:24,768 - INFO -  RBM1 Epoch 20: Loss=1.0966
2025-06-02 22:55:25,913 - INFO -  RBM1 Epoch 30: Loss=1.0960
2025-06-02 22:55:27,205 - INFO -  RBM1 Epoch 40: Loss=1.0953
2025-06-02 22:55:28,608 - INFO -  RBM1 Epoch 50: Loss=1.0932
2025-06-02 22:55:29,880 - INFO -  RBM1 Epoch 60: Loss=1.0988
2025-06-02 22:55:31,557 - INFO -  RBM1 Epoch 70: Loss=1.1106
2025-06-02 22:55:32,842 - INFO -  RBM1 Epoch 80: Loss=1.1169
2025-06-02 22:55:34,082 - INFO -  RBM1 Epoch 90: Loss=1.1209
2025-06-02 22:55:35,718 - INFO - Pre-training RBM layer 2/3
2025-06-02 22:55:35,960 - INFO -  RBM2 Epoch 0: Loss=0.4352
2025-06-02 22:55:36,944 - INFO -  RBM2 Epoch 10: Loss=0.4095
2025-06-02 22:55:38,062 - INFO -  RBM2 Epoch 20: Loss=0.3988
2025-06-02 22:55:39,104 - INFO -  RBM2 Epoch 30: Loss=0.3903
2025-06-02 22:55:40,153 - INFO -  RBM2 Epoch 40: Loss=0.3814
2025-06-02 22:55:41,194 - INFO -  RBM2 Epoch 50: Loss=0.3740
2025-06-02 22:55:42,052 - INFO -  RBM2 Epoch 60: Loss=0.3683
2025-06-02 22:55:43,038 - INFO -  RBM2 Epoch 70: Loss=0.3623
2025-06-02 22:55:44,664 - INFO -  RBM2 Epoch 80: Loss=0.3596
2025-06-02 22:55:46,156 - INFO -  RBM2 Epoch 90: Loss=0.3568
2025-06-02 22:55:47,050 - INFO - Pre-training RBM layer 3/3
2025-06-02 22:55:47,098 - INFO -  RBM3 Epoch 0: Loss=0.3864
2025-06-02 22:55:47,534 - INFO -  RBM3 Epoch 10: Loss=0.2456
2025-06-02 22:55:47,919 - INFO -  RBM3 Epoch 20: Loss=0.1994
2025-06-02 22:55:48,268 - INFO -  RBM3 Epoch 30: Loss=0.1919
2025-06-02 22:55:48,765 - INFO -  RBM3 Epoch 40: Loss=0.1891
2025-06-02 22:55:49,229 - INFO -  RBM3 Epoch 50: Loss=0.1883
2025-06-02 22:55:49,705 - INFO -  RBM3 Epoch 60: Loss=0.1867
2025-06-02 22:55:50,110 - INFO -  RBM3 Epoch 70: Loss=0.1863
2025-06-02 22:55:50,664 - INFO -  RBM3 Epoch 80: Loss=0.1860
2025-06-02 22:55:51,088 - INFO -  RBM3 Epoch 90: Loss=0.1848
2025-06-02 22:55:51,915 - INFO - Starting DBN fine-tuning...
2025-06-02 22:56:22,177 - INFO - Epoch 0: Train(l=0.5596,a=0.5764) | Val(l=0.6989,a=0.0728)
2025-06-02 22:56:24,894 - INFO - Epoch 1: Train(l=0.5408,a=0.6331) | Val(l=0.7061,a=0.3756)
2025-06-02 22:56:25,804 - INFO - Epoch 2: Train(l=0.5312,a=0.6388) | Val(l=0.6647,a=0.5141)
2025-06-02 22:56:26,744 - INFO - Epoch 3: Train(l=0.5294,a=0.6445) | Val(l=0.6281,a=0.6338)
2025-06-02 22:56:27,593 - INFO - Epoch 4: Train(l=0.5192,a=0.6512) | Val(l=0.5919,a=0.7911)
2025-06-02 22:56:29,374 - INFO - Epoch 5: Train(l=0.5132,a=0.6574) | Val(l=0.5683,a=0.8568)
2025-06-02 22:56:30,086 - INFO - Epoch 6: Train(l=0.5112,a=0.6589) | Val(l=0.5414,a=0.8826)
2025-06-02 22:56:30,823 - INFO - Epoch 7: Train(l=0.5069,a=0.6589) | Val(l=0.5272,a=0.8052)
2025-06-02 22:56:31,589 - INFO - Epoch 8: Train(l=0.5079,a=0.6610) | Val(l=0.5268,a=0.7512)
2025-06-02 22:56:33,256 - INFO - Epoch 9: Train(l=0.5059,a=0.6615) | Val(l=0.5343,a=0.7019)
2025-06-02 22:56:34,658 - INFO - Epoch 10: Train(l=0.5058,a=0.6620) | Val(l=0.5468,a=0.6995)
2025-06-02 22:56:35,777 - INFO - Epoch 11: Train(l=0.5062,a=0.6620) | Val(l=0.5540,a=0.6995)
2025-06-02 22:56:36,755 - INFO - Epoch 12: Train(l=0.5057,a=0.6749) | Val(l=0.5453,a=0.6972)
2025-06-02 22:56:38,158 - INFO - Epoch 13: Train(l=0.5023,a=0.6600) | Val(l=0.5322,a=0.7019)
2025-06-02 22:56:39,329 - INFO - Epoch 14: Train(l=0.5039,a=0.6703) | Val(l=0.5623,a=0.6972)
2025-06-02 22:56:41,096 - INFO - Epoch 15: Train(l=0.4930,a=0.6811) | Val(l=0.5861,a=0.6643)
2025-06-02 22:56:42,758 - INFO - Epoch 16: Train(l=0.4886,a=0.6780) | Val(l=0.6278,a=0.5892)
2025-06-02 22:56:44,256 - INFO - Epoch 17: Train(l=0.4845,a=0.6847) | Val(l=0.6571,a=0.6315)
2025-06-02 22:56:46,978 - INFO - Epoch 18: Train(l=0.4756,a=0.6894) | Val(l=0.5424,a=0.6901)
2025-06-02 22:56:53,920 - INFO - Epoch 19: Train(l=0.4573,a=0.7069) | Val(l=0.6886,a=0.6408)
2025-06-02 22:57:11,740 - INFO - Epoch 20: Train(l=0.4292,a=0.7327) | Val(l=0.8679,a=0.6009)
2025-06-02 22:57:12,929 - INFO - Epoch 21: Train(l=0.3923,a=0.8044) | Val(l=1.2875,a=0.2465)
2025-06-02 22:57:13,775 - INFO - Epoch 22: Train(l=0.3482,a=0.8344) | Val(l=1.2357,a=0.2347)
2025-06-02 22:57:16,493 - INFO - Epoch 23: Train(l=0.3110,a=0.8638) | Val(l=1.1217,a=0.5704)
2025-06-02 22:57:18,640 - INFO - Epoch 24: Train(l=0.2858,a=0.8798) | Val(l=1.0304,a=0.6009)
2025-06-02 22:57:21,401 - INFO - Epoch 25: Train(l=0.2623,a=0.8777) | Val(l=0.4453,a=0.7793)
2025-06-02 22:57:24,627 - INFO - Epoch 26: Train(l=0.2532,a=0.8906) | Val(l=0.6102,a=0.7371)
2025-06-02 22:57:28,654 - INFO - Epoch 27: Train(l=0.2458,a=0.8854) | Val(l=0.3571,a=0.8545)
2025-06-02 22:58:01,379 - INFO - Epoch 28: Train(l=0.2389,a=0.8963) | Val(l=0.3688,a=0.8498)
2025-06-02 22:58:04,042 - INFO - Epoch 29: Train(l=0.2365,a=0.8968) | Val(l=0.4092,a=0.8286)
2025-06-02 22:58:05,108 - INFO - Epoch 30: Train(l=0.2399,a=0.8937) | Val(l=0.4302,a=0.8192)
2025-06-02 22:58:05,975 - INFO - Epoch 31: Train(l=0.2365,a=0.8973) | Val(l=0.4676,a=0.7981)
2025-06-02 22:58:06,911 - INFO - Epoch 32: Train(l=0.2374,a=0.8942) | Val(l=0.4853,a=0.7840)
2025-06-02 22:58:08,408 - INFO - Epoch 33: Train(l=0.2344,a=0.8927) | Val(l=0.4530,a=0.7981)
2025-06-02 22:58:09,560 - INFO - Epoch 34: Train(l=0.2271,a=0.8999) | Val(l=0.4273,a=0.8192)
2025-06-02 22:58:11,270 - INFO - Epoch 35: Train(l=0.2194,a=0.9045) | Val(l=0.4116,a=0.8239)
2025-06-02 22:58:12,656 - INFO - Epoch 36: Train(l=0.2119,a=0.9061) | Val(l=0.3698,a=0.8638)
2025-06-02 22:58:13,969 - INFO - Epoch 37: Train(l=0.1984,a=0.9159) | Val(l=0.6049,a=0.7582)
2025-06-02 22:58:16,553 - INFO - Epoch 38: Train(l=0.1912,a=0.9154) | Val(l=0.6574,a=0.7183)
2025-06-02 22:58:25,880 - INFO - Epoch 39: Train(l=0.1790,a=0.9205) | Val(l=0.9981,a=0.4718)
2025-06-02 22:58:33,069 - INFO - Epoch 40: Train(l=0.1701,a=0.9252) | Val(l=0.9143,a=0.6808)
2025-06-02 22:58:43,603 - INFO - Epoch 41: Train(l=0.1574,a=0.9340) | Val(l=0.6517,a=0.5657)
2025-06-02 22:58:48,295 - INFO - Epoch 42: Train(l=0.1477,a=0.9427) | Val(l=0.7821,a=0.5211)
2025-06-02 22:58:49,701 - INFO - Epoch 43: Train(l=0.1457,a=0.9443) | Val(l=0.6912,a=0.5516)
2025-06-02 22:58:50,932 - INFO - Epoch 44: Train(l=0.1458,a=0.9386) | Val(l=0.5047,a=0.8075)
2025-06-02 22:58:52,321 - INFO - Epoch 45: Train(l=0.1301,a=0.9556) | Val(l=0.6703,a=0.7676)
2025-06-02 22:58:53,917 - INFO - Epoch 46: Train(l=0.1229,a=0.9592) | Val(l=0.5371,a=0.8099)
2025-06-02 22:58:55,358 - INFO - Epoch 47: Train(l=0.1197,a=0.9603) | Val(l=0.7811,a=0.5728)
2025-06-02 22:58:55,360 - INFO - Early stopping.
2025-06-02 22:59:34,966 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 23:00:45,492 - INFO - Validation MSE: 6.850749
2025-06-02 23:00:45,493 - INFO - Total training time: 323.65s
2025-06-02 23:00:45,493 - INFO - Validation MCC: 0.3614, AUC: 0.8405
2025-06-02 23:00:45,493 - INFO - Test       MCC: 0.3493, AUC: 0.8468
2025-06-02 23:20:17,158 - INFO - Training DBN...
2025-06-02 23:20:17,909 - INFO - Starting DBN pre-training...
2025-06-02 23:20:17,909 - INFO - Pre-training RBM layer 1/3
2025-06-02 23:20:18,516 - INFO -  RBM1 Epoch 0: Loss=1.5668
2025-06-02 23:20:20,066 - INFO -  RBM1 Epoch 10: Loss=1.1506
2025-06-02 23:20:23,663 - INFO -  RBM1 Epoch 20: Loss=1.0998
2025-06-02 23:20:26,781 - INFO -  RBM1 Epoch 30: Loss=1.0932
2025-06-02 23:20:28,501 - INFO -  RBM1 Epoch 40: Loss=1.0863
2025-06-02 23:20:30,473 - INFO -  RBM1 Epoch 50: Loss=1.0886
2025-06-02 23:20:32,357 - INFO -  RBM1 Epoch 60: Loss=1.0943
2025-06-02 23:20:34,923 - INFO -  RBM1 Epoch 70: Loss=1.1065
2025-06-02 23:20:37,788 - INFO -  RBM1 Epoch 80: Loss=1.1090
2025-06-02 23:20:40,043 - INFO -  RBM1 Epoch 90: Loss=1.1127
2025-06-02 23:20:42,519 - INFO - Pre-training RBM layer 2/3
2025-06-02 23:20:42,758 - INFO -  RBM2 Epoch 0: Loss=0.4356
2025-06-02 23:20:44,010 - INFO -  RBM2 Epoch 10: Loss=0.4101
2025-06-02 23:20:45,430 - INFO -  RBM2 Epoch 20: Loss=0.4002
2025-06-02 23:20:48,282 - INFO -  RBM2 Epoch 30: Loss=0.3900
2025-06-02 23:20:50,294 - INFO -  RBM2 Epoch 40: Loss=0.3809
2025-06-02 23:20:51,870 - INFO -  RBM2 Epoch 50: Loss=0.3730
2025-06-02 23:20:54,333 - INFO -  RBM2 Epoch 60: Loss=0.3676
2025-06-02 23:20:56,140 - INFO -  RBM2 Epoch 70: Loss=0.3630
2025-06-02 23:20:57,927 - INFO -  RBM2 Epoch 80: Loss=0.3594
2025-06-02 23:20:59,831 - INFO -  RBM2 Epoch 90: Loss=0.3557
2025-06-02 23:21:01,939 - INFO - Pre-training RBM layer 3/3
2025-06-02 23:21:02,121 - INFO -  RBM3 Epoch 0: Loss=0.3868
2025-06-02 23:21:03,813 - INFO -  RBM3 Epoch 10: Loss=0.2444
2025-06-02 23:21:04,984 - INFO -  RBM3 Epoch 20: Loss=0.1984
2025-06-02 23:21:05,739 - INFO -  RBM3 Epoch 30: Loss=0.1916
2025-06-02 23:21:06,795 - INFO -  RBM3 Epoch 40: Loss=0.1885
2025-06-02 23:21:08,967 - INFO -  RBM3 Epoch 50: Loss=0.1865
2025-06-02 23:21:10,922 - INFO -  RBM3 Epoch 60: Loss=0.1859
2025-06-02 23:21:11,822 - INFO -  RBM3 Epoch 70: Loss=0.1847
2025-06-02 23:21:13,553 - INFO -  RBM3 Epoch 80: Loss=0.1846
2025-06-02 23:21:14,362 - INFO -  RBM3 Epoch 90: Loss=0.1837
2025-06-02 23:21:14,936 - INFO - Starting DBN fine-tuning...
2025-06-02 23:21:41,362 - INFO - Epoch 0: Train(l=0.5492,a=0.5908) | Val(l=0.7056,a=0.0728)
2025-06-02 23:21:41,748 - INFO - Epoch 1: Train(l=0.5344,a=0.6434) | Val(l=0.6791,a=0.5023)
2025-06-02 23:21:42,151 - INFO - Epoch 2: Train(l=0.5283,a=0.6455) | Val(l=0.6279,a=0.8709)
2025-06-02 23:21:42,547 - INFO - Epoch 3: Train(l=0.5220,a=0.6476) | Val(l=0.5870,a=0.9272)
2025-06-02 23:21:42,903 - INFO - Epoch 4: Train(l=0.5154,a=0.6409) | Val(l=0.5581,a=0.9272)
2025-06-02 23:21:43,262 - INFO - Epoch 5: Train(l=0.5130,a=0.6584) | Val(l=0.5392,a=0.9272)
2025-06-02 23:21:43,645 - INFO - Epoch 6: Train(l=0.5066,a=0.6698) | Val(l=0.5300,a=0.9272)
2025-06-02 23:21:44,021 - INFO - Epoch 7: Train(l=0.5065,a=0.6625) | Val(l=0.5213,a=0.9272)
2025-06-02 23:21:44,431 - INFO - Epoch 8: Train(l=0.5067,a=0.6667) | Val(l=0.5219,a=0.8592)
2025-06-02 23:21:44,819 - INFO - Epoch 9: Train(l=0.5015,a=0.6631) | Val(l=0.5338,a=0.7864)
2025-06-02 23:21:45,189 - INFO - Epoch 10: Train(l=0.5033,a=0.6651) | Val(l=0.5497,a=0.7465)
2025-06-02 23:21:45,603 - INFO - Epoch 11: Train(l=0.5006,a=0.6656) | Val(l=0.5647,a=0.7207)
2025-06-02 23:21:46,075 - INFO - Epoch 12: Train(l=0.5033,a=0.6713) | Val(l=0.5888,a=0.6995)
2025-06-02 23:21:46,485 - INFO - Epoch 13: Train(l=0.4976,a=0.6708) | Val(l=0.6003,a=0.7019)
2025-06-02 23:21:46,908 - INFO - Epoch 14: Train(l=0.4974,a=0.6713) | Val(l=0.5679,a=0.7089)
2025-06-02 23:21:47,292 - INFO - Epoch 15: Train(l=0.4971,a=0.6718) | Val(l=0.6457,a=0.6385)
2025-06-02 23:21:47,710 - INFO - Epoch 16: Train(l=0.4840,a=0.6811) | Val(l=0.7508,a=0.5892)
2025-06-02 23:21:48,091 - INFO - Epoch 17: Train(l=0.4925,a=0.6780) | Val(l=0.9333,a=0.5211)
2025-06-02 23:21:48,503 - INFO - Epoch 18: Train(l=0.4715,a=0.6904) | Val(l=0.7669,a=0.6009)
2025-06-02 23:21:48,910 - INFO - Epoch 19: Train(l=0.4575,a=0.7085) | Val(l=1.0290,a=0.5070)
2025-06-02 23:21:49,345 - INFO - Epoch 20: Train(l=0.4250,a=0.7647) | Val(l=1.0472,a=0.5516)
2025-06-02 23:21:49,774 - INFO - Epoch 21: Train(l=0.3767,a=0.8189) | Val(l=1.3544,a=0.3920)
2025-06-02 23:21:50,206 - INFO - Epoch 22: Train(l=0.3369,a=0.8416) | Val(l=1.0002,a=0.6150)
2025-06-02 23:21:50,675 - INFO - Epoch 23: Train(l=0.3090,a=0.8633) | Val(l=1.0165,a=0.6338)
2025-06-02 23:21:51,123 - INFO - Epoch 24: Train(l=0.2833,a=0.8746) | Val(l=0.5353,a=0.7535)
2025-06-02 23:21:51,708 - INFO - Epoch 25: Train(l=0.2647,a=0.8772) | Val(l=0.4093,a=0.8192)
2025-06-02 23:21:52,269 - INFO - Epoch 26: Train(l=0.2511,a=0.8973) | Val(l=0.6320,a=0.7300)
2025-06-02 23:21:52,796 - INFO - Epoch 27: Train(l=0.2410,a=0.8839) | Val(l=0.3605,a=0.8521)
2025-06-02 23:21:53,430 - INFO - Epoch 28: Train(l=0.2405,a=0.8958) | Val(l=0.3840,a=0.8474)
2025-06-02 23:21:54,289 - INFO - Epoch 29: Train(l=0.2343,a=0.8989) | Val(l=0.4336,a=0.8169)
2025-06-02 23:21:54,839 - INFO - Epoch 30: Train(l=0.2364,a=0.8973) | Val(l=0.4434,a=0.8099)
2025-06-02 23:21:55,302 - INFO - Epoch 31: Train(l=0.2367,a=0.8937) | Val(l=0.4577,a=0.8075)
2025-06-02 23:21:55,742 - INFO - Epoch 32: Train(l=0.2379,a=0.8968) | Val(l=0.4317,a=0.8216)
2025-06-02 23:21:56,210 - INFO - Epoch 33: Train(l=0.2334,a=0.8968) | Val(l=0.3771,a=0.8474)
2025-06-02 23:21:56,710 - INFO - Epoch 34: Train(l=0.2282,a=0.8958) | Val(l=0.3989,a=0.8286)
2025-06-02 23:21:57,133 - INFO - Epoch 35: Train(l=0.2226,a=0.9061) | Val(l=0.6689,a=0.7324)
2025-06-02 23:21:57,607 - INFO - Epoch 36: Train(l=0.2170,a=0.9040) | Val(l=0.5057,a=0.7723)
2025-06-02 23:21:58,062 - INFO - Epoch 37: Train(l=0.2065,a=0.9107) | Val(l=0.4589,a=0.7934)
2025-06-02 23:21:58,560 - INFO - Epoch 38: Train(l=0.1928,a=0.9154) | Val(l=1.0035,a=0.4554)
2025-06-02 23:21:59,047 - INFO - Epoch 39: Train(l=0.1850,a=0.9174) | Val(l=0.9660,a=0.4718)
2025-06-02 23:21:59,527 - INFO - Epoch 40: Train(l=0.1733,a=0.9226) | Val(l=0.6380,a=0.5423)
2025-06-02 23:22:00,038 - INFO - Epoch 41: Train(l=0.1632,a=0.9303) | Val(l=0.4552,a=0.7512)
2025-06-02 23:22:00,579 - INFO - Epoch 42: Train(l=0.1621,a=0.9350) | Val(l=0.8087,a=0.5141)
2025-06-02 23:22:01,410 - INFO - Epoch 43: Train(l=0.1531,a=0.9407) | Val(l=1.5624,a=0.4225)
2025-06-02 23:22:01,998 - INFO - Epoch 44: Train(l=0.1402,a=0.9484) | Val(l=1.3046,a=0.4718)
2025-06-02 23:22:02,547 - INFO - Epoch 45: Train(l=0.1384,a=0.9422) | Val(l=0.6495,a=0.7746)
2025-06-02 23:22:03,438 - INFO - Epoch 46: Train(l=0.1296,a=0.9484) | Val(l=0.4968,a=0.8122)
2025-06-02 23:22:04,314 - INFO - Epoch 47: Train(l=0.1244,a=0.9536) | Val(l=0.4904,a=0.8310)
2025-06-02 23:22:04,316 - INFO - Early stopping.
2025-06-02 23:22:16,419 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 23:22:35,893 - INFO - Validation MSE: 7.968108
2025-06-02 23:22:35,894 - INFO - Total training time: 138.73s
2025-06-02 23:22:35,898 - INFO - Validation MCC: 0.4320, AUC: 0.8451
2025-06-02 23:22:35,899 - INFO - Test       MCC: 0.4123, AUC: 0.8421
2025-06-02 23:31:02,157 - INFO - Training DBN...
2025-06-02 23:31:02,859 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-02 23:31:02,859 - INFO - Pre-training RBM layer 1/3
2025-06-02 23:31:31,795 - INFO - Pre-training RBM layer 2/3
2025-06-02 23:32:11,812 - INFO - Pre-training RBM layer 3/3
2025-06-02 23:32:25,167 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-02 23:36:10,987 - INFO - Training DBN...
2025-06-02 23:36:11,786 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-02 23:36:11,786 - INFO - --> Pre-training RBM layer 1/3
2025-06-02 23:36:12,396 - INFO -   - RBM1 Epoch   0: ReconLoss=1.598514
2025-06-02 23:36:13,922 - INFO -   - RBM1 Epoch  10: ReconLoss=1.145222
2025-06-02 23:36:15,459 - INFO -   - RBM1 Epoch  20: ReconLoss=1.125913
2025-06-02 23:36:17,607 - INFO -   - RBM1 Epoch  30: ReconLoss=1.117154
2025-06-02 23:36:19,188 - INFO -   - RBM1 Epoch  40: ReconLoss=1.119003
2025-06-02 23:36:20,980 - INFO -   - RBM1 Epoch  50: ReconLoss=1.111107
2025-06-02 23:36:24,490 - INFO -   - RBM1 Epoch  60: ReconLoss=1.123089
2025-06-02 23:36:26,657 - INFO -   - RBM1 Epoch  70: ReconLoss=1.127326
2025-06-02 23:36:29,042 - INFO -   - RBM1 Epoch  80: ReconLoss=1.153438
2025-06-02 23:36:31,934 - INFO -   - RBM1 Epoch  90: ReconLoss=1.148137
2025-06-02 23:36:34,888 - INFO - --> Pre-training RBM layer 2/3
2025-06-02 23:36:35,180 - INFO -   - RBM2 Epoch   0: ReconLoss=0.457080
2025-06-02 23:36:38,038 - INFO -   - RBM2 Epoch  10: ReconLoss=0.429080
2025-06-02 23:36:41,541 - INFO -   - RBM2 Epoch  20: ReconLoss=0.409932
2025-06-02 23:36:43,260 - INFO -   - RBM2 Epoch  30: ReconLoss=0.395837
2025-06-02 23:36:44,521 - INFO -   - RBM2 Epoch  40: ReconLoss=0.387452
2025-06-02 23:36:46,764 - INFO -   - RBM2 Epoch  50: ReconLoss=0.378555
2025-06-02 23:36:48,066 - INFO -   - RBM2 Epoch  60: ReconLoss=0.374001
2025-06-02 23:36:49,365 - INFO -   - RBM2 Epoch  70: ReconLoss=0.368349
2025-06-02 23:36:50,894 - INFO -   - RBM2 Epoch  80: ReconLoss=0.363752
2025-06-02 23:36:53,717 - INFO -   - RBM2 Epoch  90: ReconLoss=0.362880
2025-06-02 23:36:55,454 - INFO - --> Pre-training RBM layer 3/3
2025-06-02 23:36:55,550 - INFO -   - RBM3 Epoch   0: ReconLoss=0.399113
2025-06-02 23:36:56,521 - INFO -   - RBM3 Epoch  10: ReconLoss=0.231256
2025-06-02 23:36:57,197 - INFO -   - RBM3 Epoch  20: ReconLoss=0.199977
2025-06-02 23:36:57,800 - INFO -   - RBM3 Epoch  30: ReconLoss=0.195062
2025-06-02 23:36:58,375 - INFO -   - RBM3 Epoch  40: ReconLoss=0.192084
2025-06-02 23:36:58,991 - INFO -   - RBM3 Epoch  50: ReconLoss=0.189923
2025-06-02 23:36:59,490 - INFO -   - RBM3 Epoch  60: ReconLoss=0.189613
2025-06-02 23:37:00,187 - INFO -   - RBM3 Epoch  70: ReconLoss=0.188976
2025-06-02 23:37:00,797 - INFO -   - RBM3 Epoch  80: ReconLoss=0.188679
2025-06-02 23:37:01,656 - INFO -   - RBM3 Epoch  90: ReconLoss=0.188634
2025-06-02 23:37:02,400 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-02 23:37:36,809 - INFO - Epoch 000 | Train Loss=0.7010, Acc=0.5342 | Val Loss=0.7031, Acc=0.3451 | LR=0.000100
2025-06-02 23:37:37,164 - INFO - Epoch 001 | Train Loss=0.6842, Acc=0.5727 | Val Loss=0.6914, Acc=0.4577 | LR=0.000100
2025-06-02 23:37:37,513 - INFO - Epoch 002 | Train Loss=0.6879, Acc=0.5702 | Val Loss=0.6712, Acc=0.5188 | LR=0.000100
2025-06-02 23:37:37,805 - INFO - Epoch 003 | Train Loss=0.6868, Acc=0.5761 | Val Loss=0.6603, Acc=0.5681 | LR=0.000100
2025-06-02 23:37:38,141 - INFO - Epoch 004 | Train Loss=0.6658, Acc=0.6154 | Val Loss=0.6621, Acc=0.5516 | LR=0.000100
2025-06-02 23:37:38,425 - INFO - Epoch 005 | Train Loss=0.6516, Acc=0.6221 | Val Loss=0.6493, Acc=0.5939 | LR=0.000100
2025-06-02 23:37:38,716 - INFO - Epoch 006 | Train Loss=0.6412, Acc=0.6500 | Val Loss=0.6531, Acc=0.6244 | LR=0.000100
2025-06-02 23:37:39,002 - INFO - Epoch 007 | Train Loss=0.6048, Acc=0.6936 | Val Loss=0.7253, Acc=0.4812 | LR=0.000100
2025-06-02 23:37:39,291 - INFO - Epoch 008 | Train Loss=0.5803, Acc=0.7257 | Val Loss=0.8456, Acc=0.4718 | LR=0.000100
2025-06-02 23:37:39,586 - INFO - Epoch 009 | Train Loss=0.5389, Acc=0.7604 | Val Loss=0.9600, Acc=0.5070 | LR=0.000050
2025-06-02 23:37:39,867 - INFO - Epoch 010 | Train Loss=0.5058, Acc=0.7790 | Val Loss=0.8414, Acc=0.5869 | LR=0.000050
2025-06-02 23:37:40,254 - INFO - Epoch 011 | Train Loss=0.4916, Acc=0.7857 | Val Loss=0.5106, Acc=0.7042 | LR=0.000050
2025-06-02 23:37:40,660 - INFO - Epoch 012 | Train Loss=0.4742, Acc=0.8001 | Val Loss=0.5611, Acc=0.6761 | LR=0.000050
2025-06-02 23:37:40,937 - INFO - Epoch 013 | Train Loss=0.4507, Acc=0.8098 | Val Loss=0.4629, Acc=0.7488 | LR=0.000050
2025-06-02 23:37:41,213 - INFO - Epoch 014 | Train Loss=0.4456, Acc=0.8216 | Val Loss=0.7637, Acc=0.6549 | LR=0.000050
2025-06-02 23:37:41,497 - INFO - Epoch 015 | Train Loss=0.4331, Acc=0.8309 | Val Loss=0.4883, Acc=0.7300 | LR=0.000050
2025-06-02 23:37:41,798 - INFO - Epoch 016 | Train Loss=0.4182, Acc=0.8305 | Val Loss=0.4306, Acc=0.7770 | LR=0.000050
2025-06-02 23:37:42,082 - INFO - Epoch 017 | Train Loss=0.4061, Acc=0.8428 | Val Loss=0.5018, Acc=0.7277 | LR=0.000050
2025-06-02 23:37:42,369 - INFO - Epoch 018 | Train Loss=0.4000, Acc=0.8542 | Val Loss=0.6413, Acc=0.6972 | LR=0.000050
2025-06-02 23:37:42,707 - INFO - Epoch 019 | Train Loss=0.3921, Acc=0.8390 | Val Loss=0.3776, Acc=0.8521 | LR=0.000050
2025-06-02 23:37:43,017 - INFO - Epoch 020 | Train Loss=0.3902, Acc=0.8478 | Val Loss=0.7189, Acc=0.6854 | LR=0.000050
2025-06-02 23:37:43,304 - INFO - Epoch 021 | Train Loss=0.3722, Acc=0.8576 | Val Loss=0.4206, Acc=0.7840 | LR=0.000050
2025-06-02 23:37:43,601 - INFO - Epoch 022 | Train Loss=0.3655, Acc=0.8567 | Val Loss=0.3598, Acc=0.8545 | LR=0.000050
2025-06-02 23:37:43,896 - INFO - Epoch 023 | Train Loss=0.3561, Acc=0.8631 | Val Loss=0.4259, Acc=0.7887 | LR=0.000050
2025-06-02 23:37:44,177 - INFO - Epoch 024 | Train Loss=0.3521, Acc=0.8686 | Val Loss=0.4641, Acc=0.7700 | LR=0.000050
2025-06-02 23:37:44,468 - INFO - Epoch 025 | Train Loss=0.3469, Acc=0.8673 | Val Loss=0.3624, Acc=0.8662 | LR=0.000050
2025-06-02 23:37:44,796 - INFO - Epoch 026 | Train Loss=0.3394, Acc=0.8707 | Val Loss=0.3227, Acc=0.9155 | LR=0.000050
2025-06-02 23:37:45,069 - INFO - Epoch 027 | Train Loss=0.3353, Acc=0.8749 | Val Loss=0.6368, Acc=0.7300 | LR=0.000050
2025-06-02 23:37:45,365 - INFO - Epoch 028 | Train Loss=0.3365, Acc=0.8724 | Val Loss=0.5235, Acc=0.7582 | LR=0.000050
2025-06-02 23:37:45,662 - INFO - Epoch 029 | Train Loss=0.3224, Acc=0.8774 | Val Loss=0.3317, Acc=0.8873 | LR=0.000050
2025-06-02 23:37:45,949 - INFO - Epoch 030 | Train Loss=0.3111, Acc=0.8867 | Val Loss=0.4112, Acc=0.8028 | LR=0.000025
2025-06-02 23:37:46,245 - INFO - Epoch 031 | Train Loss=0.3133, Acc=0.8833 | Val Loss=0.3477, Acc=0.8615 | LR=0.000025
2025-06-02 23:37:46,532 - INFO - Epoch 032 | Train Loss=0.3050, Acc=0.8846 | Val Loss=0.5096, Acc=0.7700 | LR=0.000025
2025-06-02 23:37:46,818 - INFO - Epoch 033 | Train Loss=0.3096, Acc=0.8817 | Val Loss=0.3353, Acc=0.8732 | LR=0.000025
2025-06-02 23:37:47,119 - INFO - Epoch 034 | Train Loss=0.3044, Acc=0.8918 | Val Loss=0.3856, Acc=0.8310 | LR=0.000013
2025-06-02 23:37:47,428 - INFO - Epoch 035 | Train Loss=0.3021, Acc=0.8855 | Val Loss=0.3529, Acc=0.8521 | LR=0.000013
2025-06-02 23:37:47,737 - INFO - Epoch 036 | Train Loss=0.2947, Acc=0.8922 | Val Loss=0.3791, Acc=0.8380 | LR=0.000013
2025-06-02 23:37:48,049 - INFO - Epoch 037 | Train Loss=0.2956, Acc=0.8876 | Val Loss=0.3422, Acc=0.8568 | LR=0.000013
2025-06-02 23:37:48,348 - INFO - Epoch 038 | Train Loss=0.2892, Acc=0.8943 | Val Loss=0.3346, Acc=0.8685 | LR=0.000006
2025-06-02 23:37:48,655 - INFO - Epoch 039 | Train Loss=0.2892, Acc=0.8952 | Val Loss=0.3745, Acc=0.8427 | LR=0.000006
2025-06-02 23:37:48,938 - INFO - Epoch 040 | Train Loss=0.2911, Acc=0.8905 | Val Loss=0.3793, Acc=0.8427 | LR=0.000006
2025-06-02 23:37:49,260 - INFO - Epoch 041 | Train Loss=0.2859, Acc=0.8973 | Val Loss=0.3265, Acc=0.8873 | LR=0.000006
2025-06-02 23:37:49,626 - INFO - Epoch 042 | Train Loss=0.2867, Acc=0.8926 | Val Loss=0.3364, Acc=0.8709 | LR=0.000003
2025-06-02 23:37:49,965 - INFO - Epoch 043 | Train Loss=0.2867, Acc=0.8948 | Val Loss=0.3622, Acc=0.8521 | LR=0.000003
2025-06-02 23:37:50,380 - INFO - Epoch 044 | Train Loss=0.2882, Acc=0.8952 | Val Loss=0.3740, Acc=0.8427 | LR=0.000003
2025-06-02 23:37:50,767 - INFO - Epoch 045 | Train Loss=0.2824, Acc=0.8986 | Val Loss=0.3383, Acc=0.8615 | LR=0.000003
2025-06-02 23:37:51,170 - INFO - Epoch 046 | Train Loss=0.2841, Acc=0.8977 | Val Loss=0.3410, Acc=0.8615 | LR=0.000002
2025-06-02 23:37:51,170 - INFO - Early stopping triggered at epoch 46
2025-06-02 23:37:51,171 - INFO - === Fine-tuning selesai ===
2025-06-02 23:38:03,806 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 23:38:17,070 - INFO - Validation MSE: 6.642942
2025-06-02 23:38:17,071 - INFO - Total training time: 126.08s
2025-06-02 23:38:17,071 - INFO - Validation MCC: 0.3561, AUC: 0.7936
2025-06-02 23:38:17,071 - INFO - Test       MCC: 0.2961, AUC: 0.7961
2025-06-02 23:44:17,596 - INFO - Training DBN...
2025-06-02 23:44:18,362 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-02 23:44:18,362 - INFO - --> Pre-training RBM layer 1/3
2025-06-02 23:44:19,055 - INFO -   - RBM1 Epoch   0: ReconLoss=1.587993
2025-06-02 23:44:21,426 - INFO -   - RBM1 Epoch  10: ReconLoss=1.148167
2025-06-02 23:44:25,711 - INFO -   - RBM1 Epoch  20: ReconLoss=1.102510
2025-06-02 23:44:28,054 - INFO -   - RBM1 Epoch  30: ReconLoss=1.107141
2025-06-02 23:44:32,049 - INFO -   - RBM1 Epoch  40: ReconLoss=1.103013
2025-06-02 23:44:35,418 - INFO -   - RBM1 Epoch  50: ReconLoss=1.126490
2025-06-02 23:44:39,566 - INFO -   - RBM1 Epoch  60: ReconLoss=1.124695
2025-06-02 23:44:41,849 - INFO -   - RBM1 Epoch  70: ReconLoss=1.134449
2025-06-02 23:44:44,072 - INFO -   - RBM1 Epoch  80: ReconLoss=1.141544
2025-06-02 23:44:46,081 - INFO -   - RBM1 Epoch  90: ReconLoss=1.148117
2025-06-02 23:44:48,116 - INFO - --> Pre-training RBM layer 2/3
2025-06-02 23:44:48,504 - INFO -   - RBM2 Epoch   0: ReconLoss=0.456212
2025-06-02 23:44:49,909 - INFO -   - RBM2 Epoch  10: ReconLoss=0.428080
2025-06-02 23:44:53,023 - INFO -   - RBM2 Epoch  20: ReconLoss=0.410074
2025-06-02 23:44:54,739 - INFO -   - RBM2 Epoch  30: ReconLoss=0.396773
2025-06-02 23:44:55,959 - INFO -   - RBM2 Epoch  40: ReconLoss=0.384246
2025-06-02 23:44:57,843 - INFO -   - RBM2 Epoch  50: ReconLoss=0.376523
2025-06-02 23:45:00,216 - INFO -   - RBM2 Epoch  60: ReconLoss=0.370126
2025-06-02 23:45:02,018 - INFO -   - RBM2 Epoch  70: ReconLoss=0.368323
2025-06-02 23:45:04,261 - INFO -   - RBM2 Epoch  80: ReconLoss=0.364955
2025-06-02 23:45:05,934 - INFO -   - RBM2 Epoch  90: ReconLoss=0.362117
2025-06-02 23:45:07,912 - INFO - --> Pre-training RBM layer 3/3
2025-06-02 23:45:08,018 - INFO -   - RBM3 Epoch   0: ReconLoss=0.401064
2025-06-02 23:45:08,744 - INFO -   - RBM3 Epoch  10: ReconLoss=0.231252
2025-06-02 23:45:09,514 - INFO -   - RBM3 Epoch  20: ReconLoss=0.199152
2025-06-02 23:45:10,201 - INFO -   - RBM3 Epoch  30: ReconLoss=0.194701
2025-06-02 23:45:11,156 - INFO -   - RBM3 Epoch  40: ReconLoss=0.190670
2025-06-02 23:45:11,895 - INFO -   - RBM3 Epoch  50: ReconLoss=0.189905
2025-06-02 23:45:12,488 - INFO -   - RBM3 Epoch  60: ReconLoss=0.190078
2025-06-02 23:45:13,210 - INFO -   - RBM3 Epoch  70: ReconLoss=0.187453
2025-06-02 23:45:13,817 - INFO -   - RBM3 Epoch  80: ReconLoss=0.187371
2025-06-02 23:45:14,574 - INFO -   - RBM3 Epoch  90: ReconLoss=0.187359
2025-06-02 23:45:15,342 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-02 23:45:41,676 - INFO - Epoch 000 | Train Loss=0.7063, Acc=0.5397 | Val Loss=0.7106, Acc=0.0728 | LR=0.000100
2025-06-02 23:45:41,966 - INFO - Epoch 001 | Train Loss=0.7010, Acc=0.5325 | Val Loss=0.7021, Acc=0.4624 | LR=0.000100
2025-06-02 23:45:42,246 - INFO - Epoch 002 | Train Loss=0.6840, Acc=0.5727 | Val Loss=0.6838, Acc=0.5211 | LR=0.000100
2025-06-02 23:45:42,565 - INFO - Epoch 003 | Train Loss=0.6805, Acc=0.5811 | Val Loss=0.6763, Acc=0.5446 | LR=0.000100
2025-06-02 23:45:42,836 - INFO - Epoch 004 | Train Loss=0.6662, Acc=0.5938 | Val Loss=0.6733, Acc=0.4883 | LR=0.000100
2025-06-02 23:45:43,114 - INFO - Epoch 005 | Train Loss=0.6460, Acc=0.6327 | Val Loss=0.6827, Acc=0.4249 | LR=0.000100
2025-06-02 23:45:43,412 - INFO - Epoch 006 | Train Loss=0.6334, Acc=0.6627 | Val Loss=0.7156, Acc=0.4085 | LR=0.000100
2025-06-02 23:45:43,686 - INFO - Epoch 007 | Train Loss=0.6043, Acc=0.6986 | Val Loss=0.7758, Acc=0.3991 | LR=0.000100
2025-06-02 23:45:44,191 - INFO - Epoch 008 | Train Loss=0.5680, Acc=0.7363 | Val Loss=0.6710, Acc=0.5681 | LR=0.000100
2025-06-02 23:45:44,491 - INFO - Epoch 009 | Train Loss=0.5240, Acc=0.7675 | Val Loss=0.8851, Acc=0.5376 | LR=0.000100
2025-06-02 23:45:44,785 - INFO - Epoch 010 | Train Loss=0.4935, Acc=0.7836 | Val Loss=0.9046, Acc=0.5869 | LR=0.000100
2025-06-02 23:45:45,076 - INFO - Epoch 011 | Train Loss=0.4602, Acc=0.8081 | Val Loss=0.5642, Acc=0.6831 | LR=0.000100
2025-06-02 23:45:45,374 - INFO - Epoch 012 | Train Loss=0.4380, Acc=0.8191 | Val Loss=0.5538, Acc=0.6925 | LR=0.000100
2025-06-02 23:45:45,660 - INFO - Epoch 013 | Train Loss=0.4068, Acc=0.8462 | Val Loss=0.8406, Acc=0.6549 | LR=0.000100
2025-06-02 23:45:45,925 - INFO - Epoch 014 | Train Loss=0.3932, Acc=0.8487 | Val Loss=0.6502, Acc=0.6995 | LR=0.000100
2025-06-02 23:45:46,208 - INFO - Epoch 015 | Train Loss=0.3745, Acc=0.8512 | Val Loss=0.4615, Acc=0.7629 | LR=0.000100
2025-06-02 23:45:46,512 - INFO - Epoch 016 | Train Loss=0.3565, Acc=0.8635 | Val Loss=0.4517, Acc=0.7629 | LR=0.000100
2025-06-02 23:45:46,794 - INFO - Epoch 017 | Train Loss=0.3462, Acc=0.8694 | Val Loss=0.7905, Acc=0.6690 | LR=0.000100
2025-06-02 23:45:47,105 - INFO - Epoch 018 | Train Loss=0.3334, Acc=0.8728 | Val Loss=0.4894, Acc=0.7512 | LR=0.000100
2025-06-02 23:45:47,410 - INFO - Epoch 019 | Train Loss=0.3260, Acc=0.8817 | Val Loss=1.0321, Acc=0.6502 | LR=0.000100
2025-06-02 23:45:47,723 - INFO - Epoch 020 | Train Loss=0.3334, Acc=0.8702 | Val Loss=0.3965, Acc=0.8521 | LR=0.000100
2025-06-02 23:45:48,039 - INFO - Epoch 021 | Train Loss=0.3055, Acc=0.8838 | Val Loss=0.5640, Acc=0.7418 | LR=0.000100
2025-06-02 23:45:48,375 - INFO - Epoch 022 | Train Loss=0.2946, Acc=0.8897 | Val Loss=0.3251, Acc=0.8920 | LR=0.000100
2025-06-02 23:45:48,672 - INFO - Epoch 023 | Train Loss=0.2838, Acc=0.8964 | Val Loss=0.3472, Acc=0.8545 | LR=0.000100
2025-06-02 23:45:48,965 - INFO - Epoch 024 | Train Loss=0.2766, Acc=0.9019 | Val Loss=0.4220, Acc=0.7911 | LR=0.000100
2025-06-02 23:45:49,306 - INFO - Epoch 025 | Train Loss=0.2648, Acc=0.9049 | Val Loss=0.7843, Acc=0.6972 | LR=0.000100
2025-06-02 23:45:49,622 - INFO - Epoch 026 | Train Loss=0.2572, Acc=0.9142 | Val Loss=0.9461, Acc=0.6714 | LR=0.000050
2025-06-02 23:45:49,897 - INFO - Epoch 027 | Train Loss=0.2396, Acc=0.9146 | Val Loss=0.4375, Acc=0.7958 | LR=0.000050
2025-06-02 23:45:50,216 - INFO - Epoch 028 | Train Loss=0.2361, Acc=0.9210 | Val Loss=0.6316, Acc=0.7512 | LR=0.000050
2025-06-02 23:45:50,573 - INFO - Epoch 029 | Train Loss=0.2335, Acc=0.9201 | Val Loss=0.3242, Acc=0.8521 | LR=0.000050
2025-06-02 23:45:50,875 - INFO - Epoch 030 | Train Loss=0.2323, Acc=0.9197 | Val Loss=0.4323, Acc=0.8005 | LR=0.000050
2025-06-02 23:45:51,188 - INFO - Epoch 031 | Train Loss=0.2240, Acc=0.9273 | Val Loss=0.5057, Acc=0.7840 | LR=0.000050
2025-06-02 23:45:51,597 - INFO - Epoch 032 | Train Loss=0.2164, Acc=0.9328 | Val Loss=0.6767, Acc=0.7559 | LR=0.000050
2025-06-02 23:45:51,974 - INFO - Epoch 033 | Train Loss=0.2133, Acc=0.9290 | Val Loss=0.2323, Acc=0.9390 | LR=0.000050
2025-06-02 23:45:52,330 - INFO - Epoch 034 | Train Loss=0.2259, Acc=0.9269 | Val Loss=0.4751, Acc=0.7958 | LR=0.000050
2025-06-02 23:45:52,729 - INFO - Epoch 035 | Train Loss=0.1999, Acc=0.9383 | Val Loss=0.5320, Acc=0.7840 | LR=0.000050
2025-06-02 23:45:53,036 - INFO - Epoch 036 | Train Loss=0.2075, Acc=0.9324 | Val Loss=0.2897, Acc=0.9038 | LR=0.000050
2025-06-02 23:45:53,345 - INFO - Epoch 037 | Train Loss=0.2036, Acc=0.9362 | Val Loss=0.6772, Acc=0.7606 | LR=0.000025
2025-06-02 23:45:53,663 - INFO - Epoch 038 | Train Loss=0.2053, Acc=0.9320 | Val Loss=0.2469, Acc=0.9249 | LR=0.000025
2025-06-02 23:45:54,069 - INFO - Epoch 039 | Train Loss=0.1972, Acc=0.9362 | Val Loss=0.3470, Acc=0.8592 | LR=0.000025
2025-06-02 23:45:54,382 - INFO - Epoch 040 | Train Loss=0.2021, Acc=0.9315 | Val Loss=0.3510, Acc=0.8662 | LR=0.000025
2025-06-02 23:45:54,750 - INFO - Epoch 041 | Train Loss=0.1895, Acc=0.9387 | Val Loss=0.5353, Acc=0.7958 | LR=0.000013
2025-06-02 23:45:55,095 - INFO - Epoch 042 | Train Loss=0.1929, Acc=0.9379 | Val Loss=0.2695, Acc=0.9131 | LR=0.000013
2025-06-02 23:45:55,452 - INFO - Epoch 043 | Train Loss=0.1845, Acc=0.9442 | Val Loss=0.3289, Acc=0.8779 | LR=0.000013
2025-06-02 23:45:55,861 - INFO - Epoch 044 | Train Loss=0.1891, Acc=0.9370 | Val Loss=0.4053, Acc=0.8474 | LR=0.000013
2025-06-02 23:45:56,375 - INFO - Epoch 045 | Train Loss=0.1828, Acc=0.9404 | Val Loss=0.2893, Acc=0.8967 | LR=0.000006
2025-06-02 23:45:56,785 - INFO - Epoch 046 | Train Loss=0.1833, Acc=0.9400 | Val Loss=0.3032, Acc=0.8944 | LR=0.000006
2025-06-02 23:45:57,160 - INFO - Epoch 047 | Train Loss=0.1853, Acc=0.9374 | Val Loss=0.3085, Acc=0.8944 | LR=0.000006
2025-06-02 23:45:57,506 - INFO - Epoch 048 | Train Loss=0.1852, Acc=0.9417 | Val Loss=0.3408, Acc=0.8732 | LR=0.000006
2025-06-02 23:45:57,893 - INFO - Epoch 049 | Train Loss=0.1835, Acc=0.9396 | Val Loss=0.2997, Acc=0.8944 | LR=0.000003
2025-06-02 23:45:58,331 - INFO - Epoch 050 | Train Loss=0.1827, Acc=0.9434 | Val Loss=0.2863, Acc=0.9038 | LR=0.000003
2025-06-02 23:45:58,757 - INFO - Epoch 051 | Train Loss=0.1896, Acc=0.9408 | Val Loss=0.3289, Acc=0.8897 | LR=0.000003
2025-06-02 23:45:59,166 - INFO - Epoch 052 | Train Loss=0.1821, Acc=0.9417 | Val Loss=0.3649, Acc=0.8732 | LR=0.000003
2025-06-02 23:45:59,572 - INFO - Epoch 053 | Train Loss=0.1789, Acc=0.9425 | Val Loss=0.3561, Acc=0.8709 | LR=0.000002
2025-06-02 23:45:59,572 - INFO - Early stopping triggered at epoch 53
2025-06-02 23:45:59,573 - INFO - === Fine-tuning selesai ===
2025-06-02 23:46:22,039 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 23:46:49,406 - INFO - Validation MSE: 9.976283
2025-06-02 23:46:49,406 - INFO - Total training time: 151.81s
2025-06-02 23:46:49,407 - INFO - Validation MCC: 0.4311, AUC: 0.8065
2025-06-02 23:46:49,407 - INFO - Test       MCC: 0.3752, AUC: 0.7946
2025-06-02 23:47:54,366 - INFO - Training DBN...
2025-06-02 23:47:54,677 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-02 23:47:54,677 - INFO - --> Pre-training RBM layer 1/3
2025-06-02 23:47:54,962 - INFO -   - RBM1 Epoch   0: ReconLoss=1.607818
2025-06-02 23:47:56,480 - INFO -   - RBM1 Epoch  10: ReconLoss=1.149987
2025-06-02 23:47:58,078 - INFO -   - RBM1 Epoch  20: ReconLoss=1.129460
2025-06-02 23:47:59,764 - INFO -   - RBM1 Epoch  30: ReconLoss=1.112530
2025-06-02 23:48:02,018 - INFO -   - RBM1 Epoch  40: ReconLoss=1.105274
2025-06-02 23:48:05,211 - INFO -   - RBM1 Epoch  50: ReconLoss=1.121353
2025-06-02 23:48:07,603 - INFO -   - RBM1 Epoch  60: ReconLoss=1.142231
2025-06-02 23:48:10,204 - INFO -   - RBM1 Epoch  70: ReconLoss=1.123459
2025-06-02 23:48:12,925 - INFO -   - RBM1 Epoch  80: ReconLoss=1.152350
2025-06-02 23:48:15,912 - INFO -   - RBM1 Epoch  90: ReconLoss=1.137805
2025-06-02 23:48:19,350 - INFO - --> Pre-training RBM layer 2/3
2025-06-02 23:48:19,663 - INFO -   - RBM2 Epoch   0: ReconLoss=0.457519
2025-06-02 23:48:23,494 - INFO -   - RBM2 Epoch  10: ReconLoss=0.428697
2025-06-02 23:48:25,977 - INFO -   - RBM2 Epoch  20: ReconLoss=0.409577
2025-06-02 23:48:28,569 - INFO -   - RBM2 Epoch  30: ReconLoss=0.393321
2025-06-02 23:48:30,634 - INFO -   - RBM2 Epoch  40: ReconLoss=0.383778
2025-06-02 23:48:32,219 - INFO -   - RBM2 Epoch  50: ReconLoss=0.376290
2025-06-02 23:48:33,557 - INFO -   - RBM2 Epoch  60: ReconLoss=0.371718
2025-06-02 23:48:34,891 - INFO -   - RBM2 Epoch  70: ReconLoss=0.367253
2025-06-02 23:48:37,637 - INFO -   - RBM2 Epoch  80: ReconLoss=0.364528
2025-06-02 23:48:40,363 - INFO -   - RBM2 Epoch  90: ReconLoss=0.361502
2025-06-02 23:48:41,722 - INFO - --> Pre-training RBM layer 3/3
2025-06-02 23:48:41,803 - INFO -   - RBM3 Epoch   0: ReconLoss=0.402038
2025-06-02 23:48:43,762 - INFO -   - RBM3 Epoch  10: ReconLoss=0.231256
2025-06-02 23:48:45,526 - INFO -   - RBM3 Epoch  20: ReconLoss=0.198550
2025-06-02 23:48:46,490 - INFO -   - RBM3 Epoch  30: ReconLoss=0.193874
2025-06-02 23:48:47,544 - INFO -   - RBM3 Epoch  40: ReconLoss=0.190242
2025-06-02 23:48:48,277 - INFO -   - RBM3 Epoch  50: ReconLoss=0.189294
2025-06-02 23:48:49,110 - INFO -   - RBM3 Epoch  60: ReconLoss=0.188410
2025-06-02 23:48:49,976 - INFO -   - RBM3 Epoch  70: ReconLoss=0.185578
2025-06-02 23:48:50,766 - INFO -   - RBM3 Epoch  80: ReconLoss=0.186604
2025-06-02 23:48:51,717 - INFO -   - RBM3 Epoch  90: ReconLoss=0.185292
2025-06-02 23:48:52,659 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-02 23:49:19,278 - INFO - Epoch 000 | Train Loss=0.7018, Acc=0.5321 | Val Loss=0.6889, Acc=0.2676 | LR=0.000100
2025-06-02 23:49:19,562 - INFO - Epoch 001 | Train Loss=0.6989, Acc=0.5583 | Val Loss=0.6845, Acc=0.4718 | LR=0.000100
2025-06-02 23:49:19,833 - INFO - Epoch 002 | Train Loss=0.6909, Acc=0.5617 | Val Loss=0.6721, Acc=0.5540 | LR=0.000100
2025-06-02 23:49:20,151 - INFO - Epoch 003 | Train Loss=0.6880, Acc=0.5841 | Val Loss=0.6444, Acc=0.7676 | LR=0.000100
2025-06-02 23:49:20,432 - INFO - Epoch 004 | Train Loss=0.6824, Acc=0.5943 | Val Loss=0.6332, Acc=0.5775 | LR=0.000100
2025-06-02 23:49:20,744 - INFO - Epoch 005 | Train Loss=0.6718, Acc=0.5976 | Val Loss=0.6187, Acc=0.5728 | LR=0.000100
2025-06-02 23:49:21,047 - INFO - Epoch 006 | Train Loss=0.6489, Acc=0.6378 | Val Loss=0.6435, Acc=0.4531 | LR=0.000100
2025-06-02 23:49:21,372 - INFO - Epoch 007 | Train Loss=0.6282, Acc=0.6581 | Val Loss=0.6951, Acc=0.4531 | LR=0.000100
2025-06-02 23:49:21,728 - INFO - Epoch 008 | Train Loss=0.6029, Acc=0.7063 | Val Loss=0.8172, Acc=0.4507 | LR=0.000100
2025-06-02 23:49:22,104 - INFO - Epoch 009 | Train Loss=0.5599, Acc=0.7384 | Val Loss=0.8167, Acc=0.5211 | LR=0.000050
2025-06-02 23:49:22,544 - INFO - Epoch 010 | Train Loss=0.5258, Acc=0.7718 | Val Loss=0.6424, Acc=0.6150 | LR=0.000050
2025-06-02 23:49:22,871 - INFO - Epoch 011 | Train Loss=0.4981, Acc=0.7891 | Val Loss=0.6003, Acc=0.6455 | LR=0.000050
2025-06-02 23:49:23,394 - INFO - Epoch 012 | Train Loss=0.4844, Acc=0.7963 | Val Loss=0.5716, Acc=0.6573 | LR=0.000050
2025-06-02 23:49:23,750 - INFO - Epoch 013 | Train Loss=0.4711, Acc=0.8026 | Val Loss=0.5938, Acc=0.6643 | LR=0.000050
2025-06-02 23:49:24,065 - INFO - Epoch 014 | Train Loss=0.4560, Acc=0.8128 | Val Loss=0.6414, Acc=0.6643 | LR=0.000050
2025-06-02 23:49:24,373 - INFO - Epoch 015 | Train Loss=0.4408, Acc=0.8238 | Val Loss=0.4120, Acc=0.7981 | LR=0.000050
2025-06-02 23:49:24,690 - INFO - Epoch 016 | Train Loss=0.4164, Acc=0.8385 | Val Loss=0.7524, Acc=0.6620 | LR=0.000050
2025-06-02 23:49:25,000 - INFO - Epoch 017 | Train Loss=0.4124, Acc=0.8390 | Val Loss=0.4521, Acc=0.7723 | LR=0.000050
2025-06-02 23:49:25,332 - INFO - Epoch 018 | Train Loss=0.4080, Acc=0.8423 | Val Loss=0.4850, Acc=0.7254 | LR=0.000050
2025-06-02 23:49:25,646 - INFO - Epoch 019 | Train Loss=0.3954, Acc=0.8415 | Val Loss=0.4325, Acc=0.7535 | LR=0.000025
2025-06-02 23:49:25,967 - INFO - Epoch 020 | Train Loss=0.3829, Acc=0.8555 | Val Loss=0.4656, Acc=0.7347 | LR=0.000025
2025-06-02 23:49:26,307 - INFO - Epoch 021 | Train Loss=0.3823, Acc=0.8538 | Val Loss=0.3816, Acc=0.8075 | LR=0.000025
2025-06-02 23:49:26,632 - INFO - Epoch 022 | Train Loss=0.3722, Acc=0.8601 | Val Loss=0.4733, Acc=0.7606 | LR=0.000025
2025-06-02 23:49:26,965 - INFO - Epoch 023 | Train Loss=0.3680, Acc=0.8588 | Val Loss=0.3248, Acc=0.9014 | LR=0.000025
2025-06-02 23:49:27,296 - INFO - Epoch 024 | Train Loss=0.3680, Acc=0.8652 | Val Loss=0.4800, Acc=0.7629 | LR=0.000025
2025-06-02 23:49:27,592 - INFO - Epoch 025 | Train Loss=0.3603, Acc=0.8652 | Val Loss=0.4075, Acc=0.8052 | LR=0.000025
2025-06-02 23:49:27,901 - INFO - Epoch 026 | Train Loss=0.3576, Acc=0.8614 | Val Loss=0.4308, Acc=0.7958 | LR=0.000025
2025-06-02 23:49:28,242 - INFO - Epoch 027 | Train Loss=0.3485, Acc=0.8673 | Val Loss=0.4103, Acc=0.7981 | LR=0.000013
2025-06-02 23:49:28,548 - INFO - Epoch 028 | Train Loss=0.3493, Acc=0.8740 | Val Loss=0.4224, Acc=0.7911 | LR=0.000013
2025-06-02 23:49:28,878 - INFO - Epoch 029 | Train Loss=0.3479, Acc=0.8702 | Val Loss=0.4030, Acc=0.8075 | LR=0.000013
2025-06-02 23:49:29,230 - INFO - Epoch 030 | Train Loss=0.3452, Acc=0.8719 | Val Loss=0.3264, Acc=0.8826 | LR=0.000013
2025-06-02 23:49:29,555 - INFO - Epoch 031 | Train Loss=0.3387, Acc=0.8740 | Val Loss=0.3783, Acc=0.8404 | LR=0.000006
2025-06-02 23:49:29,876 - INFO - Epoch 032 | Train Loss=0.3417, Acc=0.8732 | Val Loss=0.3912, Acc=0.8333 | LR=0.000006
2025-06-02 23:49:30,204 - INFO - Epoch 033 | Train Loss=0.3409, Acc=0.8728 | Val Loss=0.3870, Acc=0.8380 | LR=0.000006
2025-06-02 23:49:30,511 - INFO - Epoch 034 | Train Loss=0.3423, Acc=0.8728 | Val Loss=0.3764, Acc=0.8427 | LR=0.000006
2025-06-02 23:49:30,828 - INFO - Epoch 035 | Train Loss=0.3404, Acc=0.8736 | Val Loss=0.3506, Acc=0.8545 | LR=0.000003
2025-06-02 23:49:31,144 - INFO - Epoch 036 | Train Loss=0.3378, Acc=0.8732 | Val Loss=0.3727, Acc=0.8521 | LR=0.000003
2025-06-02 23:49:31,478 - INFO - Epoch 037 | Train Loss=0.3355, Acc=0.8774 | Val Loss=0.3733, Acc=0.8521 | LR=0.000003
2025-06-02 23:49:31,798 - INFO - Epoch 038 | Train Loss=0.3353, Acc=0.8745 | Val Loss=0.3734, Acc=0.8545 | LR=0.000003
2025-06-02 23:49:32,118 - INFO - Epoch 039 | Train Loss=0.3444, Acc=0.8736 | Val Loss=0.3655, Acc=0.8545 | LR=0.000002
2025-06-02 23:49:32,428 - INFO - Epoch 040 | Train Loss=0.3351, Acc=0.8770 | Val Loss=0.3789, Acc=0.8474 | LR=0.000002
2025-06-02 23:49:32,841 - INFO - Epoch 041 | Train Loss=0.3362, Acc=0.8762 | Val Loss=0.3900, Acc=0.8427 | LR=0.000002
2025-06-02 23:49:33,158 - INFO - Epoch 042 | Train Loss=0.3392, Acc=0.8766 | Val Loss=0.3675, Acc=0.8545 | LR=0.000002
2025-06-02 23:49:33,482 - INFO - Epoch 043 | Train Loss=0.3359, Acc=0.8724 | Val Loss=0.3852, Acc=0.8451 | LR=0.000001
2025-06-02 23:49:33,483 - INFO - Early stopping triggered at epoch 43
2025-06-02 23:49:33,483 - INFO - === Fine-tuning selesai ===
2025-06-02 23:49:43,526 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 23:49:57,731 - INFO - Validation MSE: 5.245890
2025-06-02 23:49:57,732 - INFO - Total training time: 123.37s
2025-06-02 23:49:57,732 - INFO - Validation MCC: 0.3325, AUC: 0.7800
2025-06-02 23:49:57,732 - INFO - Test       MCC: 0.3457, AUC: 0.8042
2025-06-02 23:50:47,555 - INFO - Training DBN...
2025-06-02 23:50:47,878 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-02 23:50:47,879 - INFO - --> Pre-training RBM layer 1/3
2025-06-02 23:50:48,125 - INFO -   - RBM1 Epoch   0: ReconLoss=1.590222
2025-06-02 23:50:49,708 - INFO -   - RBM1 Epoch  10: ReconLoss=1.168990
2025-06-02 23:50:51,512 - INFO -   - RBM1 Epoch  20: ReconLoss=1.116804
2025-06-02 23:50:53,771 - INFO -   - RBM1 Epoch  30: ReconLoss=1.109655
2025-06-02 23:50:55,621 - INFO -   - RBM1 Epoch  40: ReconLoss=1.122603
2025-06-02 23:50:57,693 - INFO -   - RBM1 Epoch  50: ReconLoss=1.120301
2025-06-02 23:51:00,152 - INFO -   - RBM1 Epoch  60: ReconLoss=1.140194
2025-06-02 23:51:02,454 - INFO -   - RBM1 Epoch  70: ReconLoss=1.132821
2025-06-02 23:51:05,141 - INFO -   - RBM1 Epoch  80: ReconLoss=1.142839
2025-06-02 23:51:07,875 - INFO -   - RBM1 Epoch  90: ReconLoss=1.151183
2025-06-02 23:51:09,913 - INFO - --> Pre-training RBM layer 2/3
2025-06-02 23:51:10,197 - INFO -   - RBM2 Epoch   0: ReconLoss=0.456311
2025-06-02 23:51:11,504 - INFO -   - RBM2 Epoch  10: ReconLoss=0.427700
2025-06-02 23:51:13,366 - INFO -   - RBM2 Epoch  20: ReconLoss=0.415519
2025-06-02 23:51:14,788 - INFO -   - RBM2 Epoch  30: ReconLoss=0.400121
2025-06-02 23:51:16,356 - INFO -   - RBM2 Epoch  40: ReconLoss=0.387242
2025-06-02 23:51:17,791 - INFO -   - RBM2 Epoch  50: ReconLoss=0.377562
2025-06-02 23:51:19,970 - INFO -   - RBM2 Epoch  60: ReconLoss=0.373301
2025-06-02 23:51:22,590 - INFO -   - RBM2 Epoch  70: ReconLoss=0.368417
2025-06-02 23:51:24,263 - INFO -   - RBM2 Epoch  80: ReconLoss=0.365168
2025-06-02 23:51:25,965 - INFO -   - RBM2 Epoch  90: ReconLoss=0.364820
2025-06-02 23:51:27,128 - INFO - --> Pre-training RBM layer 3/3
2025-06-02 23:51:27,221 - INFO -   - RBM3 Epoch   0: ReconLoss=0.400546
2025-06-02 23:51:27,628 - INFO -   - RBM3 Epoch  10: ReconLoss=0.232019
2025-06-02 23:51:28,113 - INFO -   - RBM3 Epoch  20: ReconLoss=0.200998
2025-06-02 23:51:28,630 - INFO -   - RBM3 Epoch  30: ReconLoss=0.195929
2025-06-02 23:51:29,159 - INFO -   - RBM3 Epoch  40: ReconLoss=0.193476
2025-06-02 23:51:29,691 - INFO -   - RBM3 Epoch  50: ReconLoss=0.192345
2025-06-02 23:51:30,687 - INFO -   - RBM3 Epoch  60: ReconLoss=0.190910
2025-06-02 23:51:31,300 - INFO -   - RBM3 Epoch  70: ReconLoss=0.190175
2025-06-02 23:51:31,976 - INFO -   - RBM3 Epoch  80: ReconLoss=0.190034
2025-06-02 23:51:32,876 - INFO -   - RBM3 Epoch  90: ReconLoss=0.188974
2025-06-02 23:51:33,458 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-02 23:51:58,416 - INFO - Epoch 000 | Train Loss=0.7101, Acc=0.5262 | Val Loss=0.7634, Acc=0.0728 | LR=0.000100
2025-06-02 23:51:58,705 - INFO - Epoch 001 | Train Loss=0.7011, Acc=0.5558 | Val Loss=0.7497, Acc=0.0728 | LR=0.000100
2025-06-02 23:51:59,006 - INFO - Epoch 002 | Train Loss=0.6935, Acc=0.5571 | Val Loss=0.7228, Acc=0.0728 | LR=0.000100
2025-06-02 23:51:59,308 - INFO - Epoch 003 | Train Loss=0.6865, Acc=0.5647 | Val Loss=0.7042, Acc=0.3146 | LR=0.000100
2025-06-02 23:51:59,594 - INFO - Epoch 004 | Train Loss=0.6723, Acc=0.5841 | Val Loss=0.6759, Acc=0.3826 | LR=0.000100
2025-06-02 23:51:59,888 - INFO - Epoch 005 | Train Loss=0.6719, Acc=0.6023 | Val Loss=0.6673, Acc=0.3920 | LR=0.000100
2025-06-02 23:52:00,310 - INFO - Epoch 006 | Train Loss=0.6485, Acc=0.6255 | Val Loss=0.6972, Acc=0.3756 | LR=0.000100
2025-06-02 23:52:00,645 - INFO - Epoch 007 | Train Loss=0.6327, Acc=0.6636 | Val Loss=0.7614, Acc=0.4085 | LR=0.000100
2025-06-02 23:52:00,968 - INFO - Epoch 008 | Train Loss=0.6001, Acc=0.6961 | Val Loss=0.7135, Acc=0.5329 | LR=0.000100
2025-06-02 23:52:01,317 - INFO - Epoch 009 | Train Loss=0.5629, Acc=0.7439 | Val Loss=0.8967, Acc=0.4531 | LR=0.000050
2025-06-02 23:52:01,689 - INFO - Epoch 010 | Train Loss=0.5345, Acc=0.7549 | Val Loss=0.6936, Acc=0.6009 | LR=0.000050
2025-06-02 23:52:02,057 - INFO - Epoch 011 | Train Loss=0.5167, Acc=0.7701 | Val Loss=0.6959, Acc=0.6150 | LR=0.000050
2025-06-02 23:52:02,449 - INFO - Epoch 012 | Train Loss=0.4902, Acc=0.7908 | Val Loss=0.5452, Acc=0.6784 | LR=0.000050
2025-06-02 23:52:02,839 - INFO - Epoch 013 | Train Loss=0.4707, Acc=0.7980 | Val Loss=0.6315, Acc=0.6573 | LR=0.000050
2025-06-02 23:52:03,173 - INFO - Epoch 014 | Train Loss=0.4589, Acc=0.8077 | Val Loss=0.4450, Acc=0.7559 | LR=0.000050
2025-06-02 23:52:03,488 - INFO - Epoch 015 | Train Loss=0.4377, Acc=0.8208 | Val Loss=0.5427, Acc=0.6925 | LR=0.000050
2025-06-02 23:52:03,772 - INFO - Epoch 016 | Train Loss=0.4234, Acc=0.8199 | Val Loss=0.3533, Acc=0.8991 | LR=0.000050
2025-06-02 23:52:04,077 - INFO - Epoch 017 | Train Loss=0.4189, Acc=0.8288 | Val Loss=0.5099, Acc=0.7089 | LR=0.000050
2025-06-02 23:52:04,406 - INFO - Epoch 018 | Train Loss=0.4122, Acc=0.8360 | Val Loss=0.3988, Acc=0.8099 | LR=0.000050
2025-06-02 23:52:04,725 - INFO - Epoch 019 | Train Loss=0.3925, Acc=0.8483 | Val Loss=0.6169, Acc=0.6972 | LR=0.000050
2025-06-02 23:52:05,054 - INFO - Epoch 020 | Train Loss=0.3838, Acc=0.8478 | Val Loss=0.3779, Acc=0.8521 | LR=0.000025
2025-06-02 23:52:05,390 - INFO - Epoch 021 | Train Loss=0.3813, Acc=0.8508 | Val Loss=0.5058, Acc=0.7277 | LR=0.000025
2025-06-02 23:52:05,702 - INFO - Epoch 022 | Train Loss=0.3780, Acc=0.8542 | Val Loss=0.4376, Acc=0.7746 | LR=0.000025
2025-06-02 23:52:06,017 - INFO - Epoch 023 | Train Loss=0.3677, Acc=0.8559 | Val Loss=0.4573, Acc=0.7653 | LR=0.000025
2025-06-02 23:52:06,419 - INFO - Epoch 024 | Train Loss=0.3673, Acc=0.8555 | Val Loss=0.4293, Acc=0.7864 | LR=0.000013
2025-06-02 23:52:07,044 - INFO - Epoch 025 | Train Loss=0.3604, Acc=0.8635 | Val Loss=0.4582, Acc=0.7770 | LR=0.000013
2025-06-02 23:52:07,520 - INFO - Epoch 026 | Train Loss=0.3585, Acc=0.8576 | Val Loss=0.3892, Acc=0.8239 | LR=0.000013
2025-06-02 23:52:07,945 - INFO - Epoch 027 | Train Loss=0.3598, Acc=0.8614 | Val Loss=0.4378, Acc=0.7817 | LR=0.000013
2025-06-02 23:52:08,425 - INFO - Epoch 028 | Train Loss=0.3537, Acc=0.8681 | Val Loss=0.3644, Acc=0.8451 | LR=0.000006
2025-06-02 23:52:08,895 - INFO - Epoch 029 | Train Loss=0.3548, Acc=0.8664 | Val Loss=0.4168, Acc=0.8122 | LR=0.000006
2025-06-02 23:52:09,314 - INFO - Epoch 030 | Train Loss=0.3548, Acc=0.8652 | Val Loss=0.4441, Acc=0.7911 | LR=0.000006
2025-06-02 23:52:09,905 - INFO - Epoch 031 | Train Loss=0.3531, Acc=0.8639 | Val Loss=0.3970, Acc=0.8286 | LR=0.000006
2025-06-02 23:52:10,459 - INFO - Epoch 032 | Train Loss=0.3541, Acc=0.8664 | Val Loss=0.3822, Acc=0.8404 | LR=0.000003
2025-06-02 23:52:11,000 - INFO - Epoch 033 | Train Loss=0.3500, Acc=0.8686 | Val Loss=0.4231, Acc=0.8075 | LR=0.000003
2025-06-02 23:52:11,477 - INFO - Epoch 034 | Train Loss=0.3491, Acc=0.8728 | Val Loss=0.4257, Acc=0.8052 | LR=0.000003
2025-06-02 23:52:12,092 - INFO - Epoch 035 | Train Loss=0.3503, Acc=0.8702 | Val Loss=0.4134, Acc=0.8169 | LR=0.000003
2025-06-02 23:52:12,615 - INFO - Epoch 036 | Train Loss=0.3484, Acc=0.8664 | Val Loss=0.4010, Acc=0.8263 | LR=0.000002
2025-06-02 23:52:12,616 - INFO - Early stopping triggered at epoch 36
2025-06-02 23:52:12,616 - INFO - === Fine-tuning selesai ===
2025-06-02 23:52:32,254 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-02 23:52:40,399 - INFO - Validation MSE: 5.803793
2025-06-02 23:52:40,399 - INFO - Total training time: 112.84s
2025-06-02 23:52:40,400 - INFO - Validation MCC: 0.3063, AUC: 0.7741
2025-06-02 23:52:40,401 - INFO - Test       MCC: 0.3542, AUC: 0.8022
2025-06-02 23:53:55,105 - INFO - Training DBN...
2025-06-02 23:53:55,415 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-02 23:53:55,415 - INFO - --> Pre-training RBM layer 1/3
2025-06-02 23:53:55,644 - INFO -   - RBM1 Epoch   0: ReconLoss=1.585794
2025-06-02 23:53:57,390 - INFO -   - RBM1 Epoch  10: ReconLoss=1.154921
2025-06-02 23:53:59,223 - INFO -   - RBM1 Epoch  20: ReconLoss=1.107976
2025-06-02 23:54:01,210 - INFO -   - RBM1 Epoch  30: ReconLoss=1.101966
2025-06-02 23:54:03,995 - INFO -   - RBM1 Epoch  40: ReconLoss=1.098852
2025-06-02 23:54:06,191 - INFO -   - RBM1 Epoch  50: ReconLoss=1.127525
2025-06-02 23:54:10,053 - INFO -   - RBM1 Epoch  60: ReconLoss=1.146765
2025-06-02 23:54:12,821 - INFO -   - RBM1 Epoch  70: ReconLoss=1.128128
2025-06-02 23:54:15,081 - INFO -   - RBM1 Epoch  80: ReconLoss=1.151496
2025-06-02 23:54:17,355 - INFO -   - RBM1 Epoch  90: ReconLoss=1.137889
2025-06-02 23:54:19,562 - INFO - --> Pre-training RBM layer 2/3
2025-06-02 23:54:19,825 - INFO -   - RBM2 Epoch   0: ReconLoss=0.456383
2025-06-02 23:54:22,775 - INFO -   - RBM2 Epoch  10: ReconLoss=0.426419
2025-06-02 23:54:24,515 - INFO -   - RBM2 Epoch  20: ReconLoss=0.415966
2025-06-02 23:54:26,036 - INFO -   - RBM2 Epoch  30: ReconLoss=0.400900
2025-06-02 23:54:27,741 - INFO -   - RBM2 Epoch  40: ReconLoss=0.387907
2025-06-02 23:54:29,465 - INFO -   - RBM2 Epoch  50: ReconLoss=0.380012
2025-06-02 23:54:30,842 - INFO -   - RBM2 Epoch  60: ReconLoss=0.375773
2025-06-02 23:54:32,040 - INFO -   - RBM2 Epoch  70: ReconLoss=0.371458
2025-06-02 23:54:33,981 - INFO -   - RBM2 Epoch  80: ReconLoss=0.368322
2025-06-02 23:54:35,924 - INFO -   - RBM2 Epoch  90: ReconLoss=0.367075
2025-06-02 23:54:38,096 - INFO - --> Pre-training RBM layer 3/3
2025-06-02 23:54:38,390 - INFO -   - RBM3 Epoch   0: ReconLoss=0.394992
2025-06-02 23:54:40,498 - INFO -   - RBM3 Epoch  10: ReconLoss=0.232571
2025-06-02 23:54:41,767 - INFO -   - RBM3 Epoch  20: ReconLoss=0.203982
2025-06-02 23:54:42,613 - INFO -   - RBM3 Epoch  30: ReconLoss=0.197581
2025-06-02 23:54:43,172 - INFO -   - RBM3 Epoch  40: ReconLoss=0.197239
2025-06-02 23:54:43,749 - INFO -   - RBM3 Epoch  50: ReconLoss=0.195157
2025-06-02 23:54:44,284 - INFO -   - RBM3 Epoch  60: ReconLoss=0.194776
2025-06-02 23:54:44,984 - INFO -   - RBM3 Epoch  70: ReconLoss=0.193789
2025-06-02 23:54:45,705 - INFO -   - RBM3 Epoch  80: ReconLoss=0.193214
2025-06-02 23:54:46,265 - INFO -   - RBM3 Epoch  90: ReconLoss=0.192058
2025-06-02 23:54:47,072 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-02 23:55:12,484 - INFO - Epoch 000 | Train Loss=0.7142, Acc=0.5046 | Val Loss=0.6968, Acc=0.3474 | LR=0.000100
2025-06-02 23:55:12,803 - INFO - Epoch 001 | Train Loss=0.6984, Acc=0.5516 | Val Loss=0.6591, Acc=0.5117 | LR=0.000100
2025-06-02 23:55:13,114 - INFO - Epoch 002 | Train Loss=0.6817, Acc=0.5731 | Val Loss=0.6334, Acc=0.6667 | LR=0.000100
2025-06-02 23:55:13,456 - INFO - Epoch 003 | Train Loss=0.6829, Acc=0.5833 | Val Loss=0.6219, Acc=0.7254 | LR=0.000100
2025-06-02 23:55:13,808 - INFO - Epoch 004 | Train Loss=0.6780, Acc=0.5909 | Val Loss=0.6109, Acc=0.7958 | LR=0.000100
2025-06-02 23:55:14,134 - INFO - Epoch 005 | Train Loss=0.6635, Acc=0.6099 | Val Loss=0.6452, Acc=0.4859 | LR=0.000100
2025-06-02 23:55:14,476 - INFO - Epoch 006 | Train Loss=0.6503, Acc=0.6298 | Val Loss=0.6823, Acc=0.4272 | LR=0.000100
2025-06-02 23:55:14,851 - INFO - Epoch 007 | Train Loss=0.6222, Acc=0.6822 | Val Loss=0.8004, Acc=0.3709 | LR=0.000100
2025-06-02 23:55:15,158 - INFO - Epoch 008 | Train Loss=0.5873, Acc=0.7143 | Val Loss=0.8378, Acc=0.4577 | LR=0.000050
2025-06-02 23:55:15,494 - INFO - Epoch 009 | Train Loss=0.5574, Acc=0.7409 | Val Loss=0.6650, Acc=0.5845 | LR=0.000050
2025-06-02 23:55:15,838 - INFO - Epoch 010 | Train Loss=0.5305, Acc=0.7667 | Val Loss=0.7028, Acc=0.5822 | LR=0.000050
2025-06-02 23:55:16,166 - INFO - Epoch 011 | Train Loss=0.5155, Acc=0.7815 | Val Loss=0.5368, Acc=0.6714 | LR=0.000050
2025-06-02 23:55:16,531 - INFO - Epoch 012 | Train Loss=0.4939, Acc=0.7853 | Val Loss=0.7174, Acc=0.6408 | LR=0.000050
2025-06-02 23:55:16,869 - INFO - Epoch 013 | Train Loss=0.4814, Acc=0.7992 | Val Loss=0.5648, Acc=0.6831 | LR=0.000050
2025-06-02 23:55:17,230 - INFO - Epoch 014 | Train Loss=0.4597, Acc=0.8157 | Val Loss=0.5631, Acc=0.6808 | LR=0.000050
2025-06-02 23:55:17,568 - INFO - Epoch 015 | Train Loss=0.4456, Acc=0.8208 | Val Loss=0.4682, Acc=0.7254 | LR=0.000050
2025-06-02 23:55:17,920 - INFO - Epoch 016 | Train Loss=0.4287, Acc=0.8297 | Val Loss=0.6701, Acc=0.6854 | LR=0.000050
2025-06-02 23:55:18,249 - INFO - Epoch 017 | Train Loss=0.4147, Acc=0.8381 | Val Loss=0.5965, Acc=0.6901 | LR=0.000050
2025-06-02 23:55:18,611 - INFO - Epoch 018 | Train Loss=0.4038, Acc=0.8398 | Val Loss=0.5433, Acc=0.7042 | LR=0.000050
2025-06-02 23:55:18,971 - INFO - Epoch 019 | Train Loss=0.3897, Acc=0.8428 | Val Loss=0.4064, Acc=0.7723 | LR=0.000050
2025-06-02 23:55:19,357 - INFO - Epoch 020 | Train Loss=0.3825, Acc=0.8605 | Val Loss=0.4984, Acc=0.7300 | LR=0.000050
2025-06-02 23:55:19,763 - INFO - Epoch 021 | Train Loss=0.3751, Acc=0.8576 | Val Loss=0.5061, Acc=0.7347 | LR=0.000050
2025-06-02 23:55:20,300 - INFO - Epoch 022 | Train Loss=0.3698, Acc=0.8660 | Val Loss=0.7767, Acc=0.6737 | LR=0.000050
2025-06-02 23:55:20,682 - INFO - Epoch 023 | Train Loss=0.3608, Acc=0.8605 | Val Loss=0.3534, Acc=0.8474 | LR=0.000050
2025-06-02 23:55:21,056 - INFO - Epoch 024 | Train Loss=0.3539, Acc=0.8652 | Val Loss=0.3874, Acc=0.8028 | LR=0.000050
2025-06-02 23:55:21,470 - INFO - Epoch 025 | Train Loss=0.3427, Acc=0.8779 | Val Loss=0.9101, Acc=0.6549 | LR=0.000050
2025-06-02 23:55:22,018 - INFO - Epoch 026 | Train Loss=0.3385, Acc=0.8732 | Val Loss=0.3650, Acc=0.8451 | LR=0.000050
2025-06-02 23:55:22,466 - INFO - Epoch 027 | Train Loss=0.3320, Acc=0.8766 | Val Loss=0.4136, Acc=0.7840 | LR=0.000025
2025-06-02 23:55:22,928 - INFO - Epoch 028 | Train Loss=0.3293, Acc=0.8821 | Val Loss=0.4238, Acc=0.7817 | LR=0.000025
2025-06-02 23:55:23,332 - INFO - Epoch 029 | Train Loss=0.3202, Acc=0.8800 | Val Loss=0.3558, Acc=0.8592 | LR=0.000025
2025-06-02 23:55:23,706 - INFO - Epoch 030 | Train Loss=0.3142, Acc=0.8842 | Val Loss=0.5641, Acc=0.7512 | LR=0.000025
2025-06-02 23:55:24,133 - INFO - Epoch 031 | Train Loss=0.3202, Acc=0.8783 | Val Loss=0.2792, Acc=0.9343 | LR=0.000025
2025-06-02 23:55:24,544 - INFO - Epoch 032 | Train Loss=0.3108, Acc=0.8893 | Val Loss=0.4827, Acc=0.7700 | LR=0.000025
2025-06-02 23:55:24,964 - INFO - Epoch 033 | Train Loss=0.3022, Acc=0.8876 | Val Loss=0.2870, Acc=0.9319 | LR=0.000025
2025-06-02 23:55:25,469 - INFO - Epoch 034 | Train Loss=0.3077, Acc=0.8863 | Val Loss=0.4978, Acc=0.7606 | LR=0.000025
2025-06-02 23:55:26,228 - INFO - Epoch 035 | Train Loss=0.2980, Acc=0.8859 | Val Loss=0.2807, Acc=0.9319 | LR=0.000013
2025-06-02 23:55:26,882 - INFO - Epoch 036 | Train Loss=0.3006, Acc=0.8931 | Val Loss=0.4273, Acc=0.8052 | LR=0.000013
2025-06-02 23:55:27,479 - INFO - Epoch 037 | Train Loss=0.3016, Acc=0.8926 | Val Loss=0.3611, Acc=0.8427 | LR=0.000013
2025-06-02 23:55:28,318 - INFO - Epoch 038 | Train Loss=0.2918, Acc=0.8884 | Val Loss=0.3277, Acc=0.8568 | LR=0.000013
2025-06-02 23:55:28,973 - INFO - Epoch 039 | Train Loss=0.2880, Acc=0.8939 | Val Loss=0.3453, Acc=0.8521 | LR=0.000006
2025-06-02 23:55:29,620 - INFO - Epoch 040 | Train Loss=0.2888, Acc=0.8964 | Val Loss=0.3183, Acc=0.8779 | LR=0.000006
2025-06-02 23:55:30,106 - INFO - Epoch 041 | Train Loss=0.2873, Acc=0.8952 | Val Loss=0.3497, Acc=0.8498 | LR=0.000006
2025-06-02 23:55:30,613 - INFO - Epoch 042 | Train Loss=0.2838, Acc=0.8969 | Val Loss=0.3710, Acc=0.8404 | LR=0.000006
2025-06-02 23:55:31,103 - INFO - Epoch 043 | Train Loss=0.2851, Acc=0.8973 | Val Loss=0.3400, Acc=0.8545 | LR=0.000003
2025-06-02 23:55:31,555 - INFO - Epoch 044 | Train Loss=0.2885, Acc=0.8977 | Val Loss=0.3276, Acc=0.8685 | LR=0.000003
2025-06-02 23:55:31,943 - INFO - Epoch 045 | Train Loss=0.2811, Acc=0.8981 | Val Loss=0.3481, Acc=0.8498 | LR=0.000003
2025-06-02 23:55:32,347 - INFO - Epoch 046 | Train Loss=0.2869, Acc=0.8990 | Val Loss=0.3579, Acc=0.8451 | LR=0.000003
2025-06-02 23:55:32,744 - INFO - Epoch 047 | Train Loss=0.2865, Acc=0.8969 | Val Loss=0.3653, Acc=0.8404 | LR=0.000002
2025-06-02 23:55:33,112 - INFO - Epoch 048 | Train Loss=0.2921, Acc=0.8943 | Val Loss=0.3364, Acc=0.8662 | LR=0.000002
2025-06-02 23:55:33,475 - INFO - Epoch 049 | Train Loss=0.2857, Acc=0.8952 | Val Loss=0.3500, Acc=0.8498 | LR=0.000002
2025-06-02 23:55:33,909 - INFO - Epoch 050 | Train Loss=0.2824, Acc=0.8948 | Val Loss=0.3741, Acc=0.8404 | LR=0.000002
2025-06-02 23:55:34,262 - INFO - Epoch 051 | Train Loss=0.2815, Acc=0.8973 | Val Loss=0.3571, Acc=0.8498 | LR=0.000001
2025-06-02 23:55:34,263 - INFO - Early stopping triggered at epoch 51
2025-06-02 23:55:34,263 - INFO - === Fine-tuning selesai ===
2025-06-03 00:00:04,623 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-03 00:00:21,902 - INFO - Validation MSE: 7.020483
2025-06-03 00:00:21,906 - INFO - Total training time: 386.80s
2025-06-03 00:00:21,906 - INFO - Validation MCC: 0.3142, AUC: 0.7988
2025-06-03 00:00:21,907 - INFO - Test       MCC: 0.3003, AUC: 0.8058
2025-06-03 00:04:39,927 - INFO - Training CNN...
2025-06-03 00:05:12,732 - INFO - Model dan scaler tersimpan (cnn_final.pth, scalercnn.pkl)
2025-06-03 00:05:12,795 - INFO - Total training time: 32.87s
2025-06-03 00:05:12,795 - INFO - Validation MCC: 0.5611, AUC: 0.9045
2025-06-03 00:05:12,795 - INFO - Test       MCC: 0.3907, AUC: 0.8862
2025-06-03 00:17:55,868 - INFO - Training DBN...
2025-06-03 00:17:56,573 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-03 00:17:56,573 - INFO - --> Pre-training RBM layer 1/3
2025-06-03 00:17:57,280 - INFO -   - RBM1 Epoch   0: ReconLoss=1.455707
2025-06-03 00:17:58,976 - INFO -   - RBM1 Epoch  10: ReconLoss=1.054492
2025-06-03 00:18:01,358 - INFO -   - RBM1 Epoch  20: ReconLoss=1.007313
2025-06-03 00:18:04,077 - INFO -   - RBM1 Epoch  30: ReconLoss=1.028428
2025-06-03 00:18:06,728 - INFO -   - RBM1 Epoch  40: ReconLoss=1.019378
2025-06-03 00:18:09,772 - INFO -   - RBM1 Epoch  50: ReconLoss=1.033040
2025-06-03 00:18:11,655 - INFO -   - RBM1 Epoch  60: ReconLoss=1.029356
2025-06-03 00:18:13,551 - INFO -   - RBM1 Epoch  70: ReconLoss=1.036993
2025-06-03 00:18:16,475 - INFO -   - RBM1 Epoch  80: ReconLoss=1.039261
2025-06-03 00:18:18,656 - INFO -   - RBM1 Epoch  90: ReconLoss=1.035975
2025-06-03 00:18:20,880 - INFO - --> Pre-training RBM layer 2/3
2025-06-03 00:18:21,083 - INFO -   - RBM2 Epoch   0: ReconLoss=0.439592
2025-06-03 00:18:23,461 - INFO -   - RBM2 Epoch  10: ReconLoss=0.412275
2025-06-03 00:18:25,768 - INFO -   - RBM2 Epoch  20: ReconLoss=0.401566
2025-06-03 00:18:27,608 - INFO -   - RBM2 Epoch  30: ReconLoss=0.395662
2025-06-03 00:18:29,863 - INFO -   - RBM2 Epoch  40: ReconLoss=0.390344
2025-06-03 00:18:31,503 - INFO -   - RBM2 Epoch  50: ReconLoss=0.388694
2025-06-03 00:18:33,687 - INFO -   - RBM2 Epoch  60: ReconLoss=0.384174
2025-06-03 00:18:36,333 - INFO -   - RBM2 Epoch  70: ReconLoss=0.383541
2025-06-03 00:18:41,232 - INFO -   - RBM2 Epoch  80: ReconLoss=0.380813
2025-06-03 00:18:44,529 - INFO -   - RBM2 Epoch  90: ReconLoss=0.376766
2025-06-03 00:18:46,697 - INFO - --> Pre-training RBM layer 3/3
2025-06-03 00:18:46,870 - INFO -   - RBM3 Epoch   0: ReconLoss=0.399787
2025-06-03 00:18:48,396 - INFO -   - RBM3 Epoch  10: ReconLoss=0.227280
2025-06-03 00:18:49,998 - INFO -   - RBM3 Epoch  20: ReconLoss=0.178700
2025-06-03 00:18:51,426 - INFO -   - RBM3 Epoch  30: ReconLoss=0.166600
2025-06-03 00:18:52,898 - INFO -   - RBM3 Epoch  40: ReconLoss=0.161814
2025-06-03 00:18:53,946 - INFO -   - RBM3 Epoch  50: ReconLoss=0.159323
2025-06-03 00:18:54,857 - INFO -   - RBM3 Epoch  60: ReconLoss=0.156079
2025-06-03 00:18:55,752 - INFO -   - RBM3 Epoch  70: ReconLoss=0.156730
2025-06-03 00:18:56,518 - INFO -   - RBM3 Epoch  80: ReconLoss=0.153363
2025-06-03 00:18:57,208 - INFO -   - RBM3 Epoch  90: ReconLoss=0.154162
2025-06-03 00:18:57,803 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-03 00:19:22,287 - INFO - Epoch 000 | Train Loss=0.6628, Acc=0.5866 | Val Loss=0.7171, Acc=0.0986 | LR=0.000100
2025-06-03 00:19:22,626 - INFO - Epoch 001 | Train Loss=0.5890, Acc=0.6927 | Val Loss=0.7071, Acc=0.3380 | LR=0.000100
2025-06-03 00:19:22,899 - INFO - Epoch 002 | Train Loss=0.5553, Acc=0.7396 | Val Loss=0.6564, Acc=0.5493 | LR=0.000100
2025-06-03 00:19:23,180 - INFO - Epoch 003 | Train Loss=0.5193, Acc=0.7599 | Val Loss=0.5746, Acc=0.6901 | LR=0.000100
2025-06-03 00:19:23,433 - INFO - Epoch 004 | Train Loss=0.4798, Acc=0.7899 | Val Loss=0.5002, Acc=0.7723 | LR=0.000100
2025-06-03 00:19:23,694 - INFO - Epoch 005 | Train Loss=0.4565, Acc=0.7997 | Val Loss=0.4234, Acc=0.8146 | LR=0.000100
2025-06-03 00:19:23,972 - INFO - Epoch 006 | Train Loss=0.4172, Acc=0.8318 | Val Loss=0.4064, Acc=0.8075 | LR=0.000100
2025-06-03 00:19:24,215 - INFO - Epoch 007 | Train Loss=0.3930, Acc=0.8377 | Val Loss=0.3345, Acc=0.8592 | LR=0.000100
2025-06-03 00:19:24,467 - INFO - Epoch 008 | Train Loss=0.3649, Acc=0.8584 | Val Loss=0.3622, Acc=0.8216 | LR=0.000100
2025-06-03 00:19:24,725 - INFO - Epoch 009 | Train Loss=0.3344, Acc=0.8779 | Val Loss=0.2618, Acc=0.9131 | LR=0.000100
2025-06-03 00:19:25,016 - INFO - Epoch 010 | Train Loss=0.3112, Acc=0.8863 | Val Loss=0.3307, Acc=0.8310 | LR=0.000100
2025-06-03 00:19:25,254 - INFO - Epoch 011 | Train Loss=0.2846, Acc=0.9019 | Val Loss=0.2806, Acc=0.8756 | LR=0.000100
2025-06-03 00:19:25,509 - INFO - Epoch 012 | Train Loss=0.2646, Acc=0.9117 | Val Loss=0.3270, Acc=0.8404 | LR=0.000100
2025-06-03 00:19:25,754 - INFO - Epoch 013 | Train Loss=0.2463, Acc=0.9193 | Val Loss=0.1979, Acc=0.9437 | LR=0.000100
2025-06-03 00:19:26,033 - INFO - Epoch 014 | Train Loss=0.2309, Acc=0.9281 | Val Loss=0.2929, Acc=0.8662 | LR=0.000100
2025-06-03 00:19:26,263 - INFO - Epoch 015 | Train Loss=0.2103, Acc=0.9328 | Val Loss=0.2402, Acc=0.9014 | LR=0.000100
2025-06-03 00:19:26,527 - INFO - Epoch 016 | Train Loss=0.1962, Acc=0.9408 | Val Loss=0.2639, Acc=0.8897 | LR=0.000100
2025-06-03 00:19:26,783 - INFO - Epoch 017 | Train Loss=0.1942, Acc=0.9408 | Val Loss=0.1837, Acc=0.9413 | LR=0.000100
2025-06-03 00:19:27,075 - INFO - Epoch 018 | Train Loss=0.1815, Acc=0.9514 | Val Loss=0.1860, Acc=0.9390 | LR=0.000100
2025-06-03 00:19:27,326 - INFO - Epoch 019 | Train Loss=0.1759, Acc=0.9518 | Val Loss=0.3152, Acc=0.8685 | LR=0.000100
2025-06-03 00:19:27,603 - INFO - Epoch 020 | Train Loss=0.1603, Acc=0.9586 | Val Loss=0.1986, Acc=0.9202 | LR=0.000100
2025-06-03 00:19:27,864 - INFO - Epoch 021 | Train Loss=0.1498, Acc=0.9598 | Val Loss=0.3481, Acc=0.8474 | LR=0.000050
2025-06-03 00:19:28,205 - INFO - Epoch 022 | Train Loss=0.1443, Acc=0.9632 | Val Loss=0.1813, Acc=0.9413 | LR=0.000050
2025-06-03 00:19:28,458 - INFO - Epoch 023 | Train Loss=0.1424, Acc=0.9637 | Val Loss=0.2127, Acc=0.9155 | LR=0.000050
2025-06-03 00:19:28,732 - INFO - Epoch 024 | Train Loss=0.1332, Acc=0.9649 | Val Loss=0.2051, Acc=0.9155 | LR=0.000050
2025-06-03 00:19:29,008 - INFO - Epoch 025 | Train Loss=0.1270, Acc=0.9734 | Val Loss=0.2733, Acc=0.8944 | LR=0.000050
2025-06-03 00:19:29,278 - INFO - Epoch 026 | Train Loss=0.1253, Acc=0.9679 | Val Loss=0.1809, Acc=0.9366 | LR=0.000050
2025-06-03 00:19:29,565 - INFO - Epoch 027 | Train Loss=0.1203, Acc=0.9734 | Val Loss=0.2839, Acc=0.8967 | LR=0.000050
2025-06-03 00:19:29,845 - INFO - Epoch 028 | Train Loss=0.1170, Acc=0.9691 | Val Loss=0.1782, Acc=0.9413 | LR=0.000050
2025-06-03 00:19:30,122 - INFO - Epoch 029 | Train Loss=0.1134, Acc=0.9755 | Val Loss=0.3012, Acc=0.8873 | LR=0.000050
2025-06-03 00:19:30,365 - INFO - Epoch 030 | Train Loss=0.1083, Acc=0.9734 | Val Loss=0.1779, Acc=0.9413 | LR=0.000050
2025-06-03 00:19:30,628 - INFO - Epoch 031 | Train Loss=0.1128, Acc=0.9734 | Val Loss=0.2854, Acc=0.8967 | LR=0.000050
2025-06-03 00:19:30,904 - INFO - Epoch 032 | Train Loss=0.1130, Acc=0.9755 | Val Loss=0.3681, Acc=0.8615 | LR=0.000050
2025-06-03 00:19:31,217 - INFO - Epoch 033 | Train Loss=0.1081, Acc=0.9704 | Val Loss=0.1725, Acc=0.9460 | LR=0.000050
2025-06-03 00:19:31,545 - INFO - Epoch 034 | Train Loss=0.1037, Acc=0.9776 | Val Loss=0.3359, Acc=0.8709 | LR=0.000050
2025-06-03 00:19:31,889 - INFO - Epoch 035 | Train Loss=0.1081, Acc=0.9755 | Val Loss=0.2148, Acc=0.9085 | LR=0.000050
2025-06-03 00:19:32,277 - INFO - Epoch 036 | Train Loss=0.1062, Acc=0.9734 | Val Loss=0.2302, Acc=0.9155 | LR=0.000050
2025-06-03 00:19:32,728 - INFO - Epoch 037 | Train Loss=0.0996, Acc=0.9784 | Val Loss=0.3065, Acc=0.8944 | LR=0.000025
2025-06-03 00:19:33,110 - INFO - Epoch 038 | Train Loss=0.0919, Acc=0.9772 | Val Loss=0.1953, Acc=0.9249 | LR=0.000025
2025-06-03 00:19:33,543 - INFO - Epoch 039 | Train Loss=0.0969, Acc=0.9793 | Val Loss=0.2123, Acc=0.9131 | LR=0.000025
2025-06-03 00:19:34,009 - INFO - Epoch 040 | Train Loss=0.0899, Acc=0.9806 | Val Loss=0.2703, Acc=0.9014 | LR=0.000025
2025-06-03 00:19:34,455 - INFO - Epoch 041 | Train Loss=0.0958, Acc=0.9734 | Val Loss=0.2042, Acc=0.9202 | LR=0.000013
2025-06-03 00:19:34,847 - INFO - Epoch 042 | Train Loss=0.0875, Acc=0.9789 | Val Loss=0.2509, Acc=0.9085 | LR=0.000013
2025-06-03 00:19:35,304 - INFO - Epoch 043 | Train Loss=0.0875, Acc=0.9793 | Val Loss=0.2107, Acc=0.9202 | LR=0.000013
2025-06-03 00:19:35,704 - INFO - Epoch 044 | Train Loss=0.0892, Acc=0.9793 | Val Loss=0.2327, Acc=0.9108 | LR=0.000013
2025-06-03 00:19:36,077 - INFO - Epoch 045 | Train Loss=0.0891, Acc=0.9784 | Val Loss=0.2199, Acc=0.9131 | LR=0.000006
2025-06-03 00:19:36,643 - INFO - Epoch 046 | Train Loss=0.0895, Acc=0.9801 | Val Loss=0.2447, Acc=0.9108 | LR=0.000006
2025-06-03 00:19:37,106 - INFO - Epoch 047 | Train Loss=0.0867, Acc=0.9797 | Val Loss=0.2373, Acc=0.9108 | LR=0.000006
2025-06-03 00:19:37,648 - INFO - Epoch 048 | Train Loss=0.0847, Acc=0.9797 | Val Loss=0.2371, Acc=0.9108 | LR=0.000006
2025-06-03 00:19:38,104 - INFO - Epoch 049 | Train Loss=0.0852, Acc=0.9789 | Val Loss=0.2276, Acc=0.9131 | LR=0.000003
2025-06-03 00:19:38,657 - INFO - Epoch 050 | Train Loss=0.0835, Acc=0.9810 | Val Loss=0.2274, Acc=0.9131 | LR=0.000003
2025-06-03 00:19:39,084 - INFO - Epoch 051 | Train Loss=0.0839, Acc=0.9789 | Val Loss=0.2341, Acc=0.9108 | LR=0.000003
2025-06-03 00:19:39,521 - INFO - Epoch 052 | Train Loss=0.0822, Acc=0.9797 | Val Loss=0.2232, Acc=0.9155 | LR=0.000003
2025-06-03 00:19:39,900 - INFO - Epoch 053 | Train Loss=0.0864, Acc=0.9789 | Val Loss=0.2231, Acc=0.9155 | LR=0.000002
2025-06-03 00:19:39,901 - INFO - Early stopping triggered at epoch 53
2025-06-03 00:19:39,901 - INFO - === Fine-tuning selesai ===
2025-06-03 00:19:49,039 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-03 00:20:15,604 - INFO - Validation MSE: 11.953657
2025-06-03 00:20:15,724 - INFO - Total training time: 139.86s
2025-06-03 00:20:15,726 - INFO - Validation MCC: 0.4672, AUC: 0.8947
2025-06-03 00:20:15,727 - INFO - Test       MCC: 0.3738, AUC: 0.8272
2025-06-03 00:32:04,489 - INFO - Training DBN...
2025-06-03 00:32:05,188 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-03 00:32:05,189 - INFO - --> Pre-training RBM layer 1/3
2025-06-03 00:32:05,975 - INFO -   - RBM1 Epoch   0: ReconLoss=1.476859
2025-06-03 00:32:07,501 - INFO -   - RBM1 Epoch  10: ReconLoss=1.049157
2025-06-03 00:32:09,019 - INFO -   - RBM1 Epoch  20: ReconLoss=1.032138
2025-06-03 00:32:10,310 - INFO -   - RBM1 Epoch  30: ReconLoss=1.017163
2025-06-03 00:32:12,292 - INFO -   - RBM1 Epoch  40: ReconLoss=1.005114
2025-06-03 00:32:13,667 - INFO -   - RBM1 Epoch  50: ReconLoss=1.019380
2025-06-03 00:32:15,165 - INFO -   - RBM1 Epoch  60: ReconLoss=1.024688
2025-06-03 00:32:16,770 - INFO -   - RBM1 Epoch  70: ReconLoss=1.047829
2025-06-03 00:32:18,243 - INFO -   - RBM1 Epoch  80: ReconLoss=1.025132
2025-06-03 00:32:20,663 - INFO -   - RBM1 Epoch  90: ReconLoss=1.050864
2025-06-03 00:32:22,783 - INFO - --> Pre-training RBM layer 2/3
2025-06-03 00:32:23,156 - INFO -   - RBM2 Epoch   0: ReconLoss=0.437996
2025-06-03 00:32:24,710 - INFO -   - RBM2 Epoch  10: ReconLoss=0.410659
2025-06-03 00:32:26,290 - INFO -   - RBM2 Epoch  20: ReconLoss=0.398664
2025-06-03 00:32:28,399 - INFO -   - RBM2 Epoch  30: ReconLoss=0.392568
2025-06-03 00:32:30,478 - INFO -   - RBM2 Epoch  40: ReconLoss=0.389609
2025-06-03 00:32:31,967 - INFO -   - RBM2 Epoch  50: ReconLoss=0.387475
2025-06-03 00:32:33,373 - INFO -   - RBM2 Epoch  60: ReconLoss=0.384827
2025-06-03 00:32:34,619 - INFO -   - RBM2 Epoch  70: ReconLoss=0.379767
2025-06-03 00:32:36,638 - INFO -   - RBM2 Epoch  80: ReconLoss=0.378991
2025-06-03 00:32:38,600 - INFO -   - RBM2 Epoch  90: ReconLoss=0.375836
2025-06-03 00:32:40,060 - INFO - --> Pre-training RBM layer 3/3
2025-06-03 00:32:40,126 - INFO -   - RBM3 Epoch   0: ReconLoss=0.413505
2025-06-03 00:32:40,850 - INFO -   - RBM3 Epoch  10: ReconLoss=0.230417
2025-06-03 00:32:41,572 - INFO -   - RBM3 Epoch  20: ReconLoss=0.175942
2025-06-03 00:32:42,621 - INFO -   - RBM3 Epoch  30: ReconLoss=0.163053
2025-06-03 00:32:43,405 - INFO -   - RBM3 Epoch  40: ReconLoss=0.157635
2025-06-03 00:32:44,363 - INFO -   - RBM3 Epoch  50: ReconLoss=0.154286
2025-06-03 00:32:45,227 - INFO -   - RBM3 Epoch  60: ReconLoss=0.151164
2025-06-03 00:32:46,081 - INFO -   - RBM3 Epoch  70: ReconLoss=0.148852
2025-06-03 00:32:46,898 - INFO -   - RBM3 Epoch  80: ReconLoss=0.148968
2025-06-03 00:32:47,710 - INFO -   - RBM3 Epoch  90: ReconLoss=0.147359
2025-06-03 00:32:48,414 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-03 00:33:15,112 - INFO - Epoch 000 | Train Loss=0.7059, Acc=0.5042 | Val Loss=0.7459, Acc=0.0728 | LR=0.000100
2025-06-03 00:33:16,610 - INFO - Epoch 001 | Train Loss=0.6933, Acc=0.5473 | Val Loss=0.7084, Acc=0.0728 | LR=0.000100
2025-06-03 00:33:18,103 - INFO - Epoch 002 | Train Loss=0.6829, Acc=0.5566 | Val Loss=0.6657, Acc=0.9272 | LR=0.000100
2025-06-03 00:33:19,614 - INFO - Epoch 003 | Train Loss=0.6752, Acc=0.5757 | Val Loss=0.6243, Acc=0.9272 | LR=0.000100
2025-06-03 00:33:21,582 - INFO - Epoch 004 | Train Loss=0.6604, Acc=0.6014 | Val Loss=0.5950, Acc=0.9272 | LR=0.000100
2025-06-03 00:33:23,803 - INFO - Epoch 005 | Train Loss=0.6494, Acc=0.6044 | Val Loss=0.5804, Acc=0.9178 | LR=0.000100
2025-06-03 00:33:25,778 - INFO - Epoch 006 | Train Loss=0.6269, Acc=0.6323 | Val Loss=0.5290, Acc=0.8474 | LR=0.000100
2025-06-03 00:33:27,639 - INFO - Epoch 007 | Train Loss=0.6187, Acc=0.6538 | Val Loss=0.4548, Acc=0.8239 | LR=0.000100
2025-06-03 00:33:29,480 - INFO - Epoch 008 | Train Loss=0.5958, Acc=0.6830 | Val Loss=0.3619, Acc=0.9319 | LR=0.000100
2025-06-03 00:33:31,214 - INFO - Epoch 009 | Train Loss=0.5662, Acc=0.7287 | Val Loss=0.2367, Acc=0.9272 | LR=0.000100
2025-06-03 00:33:33,059 - INFO - Epoch 010 | Train Loss=0.5231, Acc=0.7781 | Val Loss=0.2274, Acc=0.9272 | LR=0.000100
2025-06-03 00:33:35,029 - INFO - Epoch 011 | Train Loss=0.4846, Acc=0.8077 | Val Loss=0.3114, Acc=0.8662 | LR=0.000100
2025-06-03 00:33:37,214 - INFO - Epoch 012 | Train Loss=0.4479, Acc=0.8246 | Val Loss=0.6501, Acc=0.6714 | LR=0.000100
2025-06-03 00:33:39,748 - INFO - Epoch 013 | Train Loss=0.4089, Acc=0.8411 | Val Loss=0.4490, Acc=0.7629 | LR=0.000100
2025-06-03 00:33:41,809 - INFO - Epoch 014 | Train Loss=0.3815, Acc=0.8593 | Val Loss=0.5628, Acc=0.7136 | LR=0.000050
2025-06-03 00:33:43,618 - INFO - Epoch 015 | Train Loss=0.3568, Acc=0.8673 | Val Loss=0.3198, Acc=0.8451 | LR=0.000050
2025-06-03 00:33:45,423 - INFO - Epoch 016 | Train Loss=0.3442, Acc=0.8736 | Val Loss=0.2549, Acc=0.9038 | LR=0.000050
2025-06-03 00:33:47,138 - INFO - Epoch 017 | Train Loss=0.3250, Acc=0.8884 | Val Loss=0.2694, Acc=0.9014 | LR=0.000050
2025-06-03 00:33:48,940 - INFO - Epoch 018 | Train Loss=0.3127, Acc=0.8977 | Val Loss=0.2480, Acc=0.9249 | LR=0.000025
2025-06-03 00:33:50,778 - INFO - Epoch 019 | Train Loss=0.3017, Acc=0.9028 | Val Loss=0.3663, Acc=0.8545 | LR=0.000025
2025-06-03 00:33:52,757 - INFO - Epoch 020 | Train Loss=0.2918, Acc=0.9074 | Val Loss=0.3669, Acc=0.8498 | LR=0.000025
2025-06-03 00:33:54,663 - INFO - Epoch 021 | Train Loss=0.2909, Acc=0.9096 | Val Loss=0.3102, Acc=0.8803 | LR=0.000025
2025-06-03 00:33:56,404 - INFO - Epoch 022 | Train Loss=0.2827, Acc=0.9134 | Val Loss=0.2661, Acc=0.9131 | LR=0.000013
2025-06-03 00:33:58,047 - INFO - Epoch 023 | Train Loss=0.2780, Acc=0.9197 | Val Loss=0.3398, Acc=0.8826 | LR=0.000013
2025-06-03 00:33:59,743 - INFO - Epoch 024 | Train Loss=0.2798, Acc=0.9146 | Val Loss=0.4001, Acc=0.8310 | LR=0.000013
2025-06-03 00:34:01,515 - INFO - Epoch 025 | Train Loss=0.2681, Acc=0.9193 | Val Loss=0.3353, Acc=0.8826 | LR=0.000013
2025-06-03 00:34:03,720 - INFO - Epoch 026 | Train Loss=0.2715, Acc=0.9201 | Val Loss=0.2954, Acc=0.8944 | LR=0.000006
2025-06-03 00:34:05,547 - INFO - Epoch 027 | Train Loss=0.2699, Acc=0.9197 | Val Loss=0.3439, Acc=0.8826 | LR=0.000006
2025-06-03 00:34:07,587 - INFO - Epoch 028 | Train Loss=0.2718, Acc=0.9218 | Val Loss=0.3470, Acc=0.8826 | LR=0.000006
2025-06-03 00:34:09,519 - INFO - Epoch 029 | Train Loss=0.2679, Acc=0.9197 | Val Loss=0.3439, Acc=0.8803 | LR=0.000006
2025-06-03 00:34:11,284 - INFO - Epoch 030 | Train Loss=0.2637, Acc=0.9239 | Val Loss=0.3404, Acc=0.8803 | LR=0.000003
2025-06-03 00:34:11,284 - INFO - Early stopping triggered at epoch 30
2025-06-03 00:34:11,285 - INFO - === Fine-tuning selesai ===
2025-06-03 00:34:21,370 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-03 00:34:29,434 - INFO - Validation MSE: 3.409821
2025-06-03 00:34:29,434 - INFO - Total training time: 144.94s
2025-06-03 00:34:29,435 - INFO - Validation MCC: 0.4208, AUC: 0.8359
2025-06-03 00:34:29,435 - INFO - Test       MCC: 0.3805, AUC: 0.8592
2025-06-03 01:26:10,247 - INFO - Training DBN...
2025-06-03 01:26:11,041 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-03 01:26:11,041 - INFO - --> Pre-training RBM layer 1/3
2025-06-03 01:26:11,694 - INFO -   - RBM1 Epoch   0: ReconLoss=1.476974
2025-06-03 01:26:12,827 - INFO -   - RBM1 Epoch  10: ReconLoss=1.048619
2025-06-03 01:26:14,143 - INFO -   - RBM1 Epoch  20: ReconLoss=1.028878
2025-06-03 01:26:15,396 - INFO -   - RBM1 Epoch  30: ReconLoss=1.016863
2025-06-03 01:26:16,943 - INFO -   - RBM1 Epoch  40: ReconLoss=1.020792
2025-06-03 01:26:18,256 - INFO -   - RBM1 Epoch  50: ReconLoss=1.014506
2025-06-03 01:26:19,820 - INFO -   - RBM1 Epoch  60: ReconLoss=1.026218
2025-06-03 01:26:21,530 - INFO -   - RBM1 Epoch  70: ReconLoss=1.037483
2025-06-03 01:26:23,086 - INFO -   - RBM1 Epoch  80: ReconLoss=1.051960
2025-06-03 01:26:24,823 - INFO -   - RBM1 Epoch  90: ReconLoss=1.047518
2025-06-03 01:26:26,722 - INFO - --> Pre-training RBM layer 2/3
2025-06-03 01:26:26,858 - INFO -   - RBM2 Epoch   0: ReconLoss=0.436382
2025-06-03 01:26:28,025 - INFO -   - RBM2 Epoch  10: ReconLoss=0.410543
2025-06-03 01:26:29,406 - INFO -   - RBM2 Epoch  20: ReconLoss=0.401028
2025-06-03 01:26:30,517 - INFO -   - RBM2 Epoch  30: ReconLoss=0.394582
2025-06-03 01:26:31,952 - INFO -   - RBM2 Epoch  40: ReconLoss=0.389416
2025-06-03 01:26:33,470 - INFO -   - RBM2 Epoch  50: ReconLoss=0.388245
2025-06-03 01:26:35,215 - INFO -   - RBM2 Epoch  60: ReconLoss=0.385871
2025-06-03 01:26:37,133 - INFO -   - RBM2 Epoch  70: ReconLoss=0.382134
2025-06-03 01:26:38,516 - INFO -   - RBM2 Epoch  80: ReconLoss=0.381718
2025-06-03 01:26:40,261 - INFO -   - RBM2 Epoch  90: ReconLoss=0.377891
2025-06-03 01:26:41,528 - INFO - --> Pre-training RBM layer 3/3
2025-06-03 01:26:41,668 - INFO -   - RBM3 Epoch   0: ReconLoss=0.421325
2025-06-03 01:26:42,290 - INFO -   - RBM3 Epoch  10: ReconLoss=0.237334
2025-06-03 01:26:42,792 - INFO -   - RBM3 Epoch  20: ReconLoss=0.175983
2025-06-03 01:26:43,266 - INFO -   - RBM3 Epoch  30: ReconLoss=0.162865
2025-06-03 01:26:43,784 - INFO -   - RBM3 Epoch  40: ReconLoss=0.157052
2025-06-03 01:26:44,539 - INFO -   - RBM3 Epoch  50: ReconLoss=0.153633
2025-06-03 01:26:45,439 - INFO -   - RBM3 Epoch  60: ReconLoss=0.150739
2025-06-03 01:26:46,727 - INFO -   - RBM3 Epoch  70: ReconLoss=0.148735
2025-06-03 01:26:47,422 - INFO -   - RBM3 Epoch  80: ReconLoss=0.148961
2025-06-03 01:26:48,210 - INFO -   - RBM3 Epoch  90: ReconLoss=0.146598
2025-06-03 01:26:48,850 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-03 01:31:54,541 - INFO - Training DBN...
2025-06-03 01:31:55,036 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-03 01:31:55,036 - INFO - --> Pre-training RBM layer 1/3
2025-06-03 01:31:55,291 - INFO -   - RBM1 Epoch   0: ReconLoss=1.474554
2025-06-03 01:31:56,547 - INFO -   - RBM1 Epoch  10: ReconLoss=1.054924
2025-06-03 01:31:58,182 - INFO -   - RBM1 Epoch  20: ReconLoss=1.026331
2025-06-03 01:31:59,743 - INFO -   - RBM1 Epoch  30: ReconLoss=1.026977
2025-06-03 01:32:01,204 - INFO -   - RBM1 Epoch  40: ReconLoss=1.016911
2025-06-03 01:32:02,990 - INFO -   - RBM1 Epoch  50: ReconLoss=1.019755
2025-06-03 01:32:04,542 - INFO -   - RBM1 Epoch  60: ReconLoss=1.029448
2025-06-03 01:32:06,157 - INFO -   - RBM1 Epoch  70: ReconLoss=1.033955
2025-06-03 01:32:07,496 - INFO -   - RBM1 Epoch  80: ReconLoss=1.029932
2025-06-03 01:32:09,290 - INFO -   - RBM1 Epoch  90: ReconLoss=1.044305
2025-06-03 01:32:10,992 - INFO - --> Pre-training RBM layer 2/3
2025-06-03 01:32:11,072 - INFO -   - RBM2 Epoch   0: ReconLoss=0.437656
2025-06-03 01:32:12,073 - INFO -   - RBM2 Epoch  10: ReconLoss=0.411553
2025-06-03 01:32:14,375 - INFO -   - RBM2 Epoch  20: ReconLoss=0.398753
2025-06-03 01:32:16,528 - INFO -   - RBM2 Epoch  30: ReconLoss=0.395836
2025-06-03 01:32:18,131 - INFO -   - RBM2 Epoch  40: ReconLoss=0.391762
2025-06-03 01:32:19,373 - INFO -   - RBM2 Epoch  50: ReconLoss=0.387332
2025-06-03 01:32:20,926 - INFO -   - RBM2 Epoch  60: ReconLoss=0.385615
2025-06-03 01:32:22,978 - INFO -   - RBM2 Epoch  70: ReconLoss=0.380703
2025-06-03 01:32:24,363 - INFO -   - RBM2 Epoch  80: ReconLoss=0.379144
2025-06-03 01:32:26,405 - INFO -   - RBM2 Epoch  90: ReconLoss=0.377142
2025-06-03 01:32:28,277 - INFO - --> Pre-training RBM layer 3/3
2025-06-03 01:32:28,394 - INFO -   - RBM3 Epoch   0: ReconLoss=0.410057
2025-06-03 01:32:29,151 - INFO -   - RBM3 Epoch  10: ReconLoss=0.234654
2025-06-03 01:32:29,868 - INFO -   - RBM3 Epoch  20: ReconLoss=0.180977
2025-06-03 01:32:30,927 - INFO -   - RBM3 Epoch  30: ReconLoss=0.169703
2025-06-03 01:32:32,057 - INFO -   - RBM3 Epoch  40: ReconLoss=0.164788
2025-06-03 01:32:32,855 - INFO -   - RBM3 Epoch  50: ReconLoss=0.160643
2025-06-03 01:32:33,655 - INFO -   - RBM3 Epoch  60: ReconLoss=0.159398
2025-06-03 01:32:34,536 - INFO -   - RBM3 Epoch  70: ReconLoss=0.157455
2025-06-03 01:32:35,422 - INFO -   - RBM3 Epoch  80: ReconLoss=0.154548
2025-06-03 01:32:36,188 - INFO -   - RBM3 Epoch  90: ReconLoss=0.154042
2025-06-03 01:32:37,156 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-03 01:33:06,480 - INFO - Epoch 000 | Train Loss=0.7116, Acc=0.5224 | Val Loss=0.6725, Acc=0.9272 | LR=0.000100
2025-06-03 01:33:10,522 - INFO - Epoch 001 | Train Loss=0.6879, Acc=0.5689 | Val Loss=0.6659, Acc=0.5587 | LR=0.000100
2025-06-03 01:33:16,355 - INFO - Epoch 002 | Train Loss=0.6723, Acc=0.5951 | Val Loss=0.6374, Acc=0.6221 | LR=0.000100
2025-06-03 01:33:21,376 - INFO - Epoch 003 | Train Loss=0.6437, Acc=0.6230 | Val Loss=0.5863, Acc=0.6831 | LR=0.000100
2025-06-03 01:33:26,373 - INFO - Epoch 004 | Train Loss=0.6257, Acc=0.6623 | Val Loss=0.5339, Acc=0.6972 | LR=0.000100
2025-06-03 01:33:31,353 - INFO - Epoch 005 | Train Loss=0.5931, Acc=0.6889 | Val Loss=0.4850, Acc=0.7207 | LR=0.000100
2025-06-03 01:33:36,304 - INFO - Epoch 006 | Train Loss=0.5641, Acc=0.7291 | Val Loss=0.4598, Acc=0.7277 | LR=0.000100
2025-06-03 01:33:41,211 - INFO - Epoch 007 | Train Loss=0.5403, Acc=0.7468 | Val Loss=0.4234, Acc=0.7700 | LR=0.000100
2025-06-03 01:33:45,806 - INFO - Epoch 008 | Train Loss=0.5074, Acc=0.7747 | Val Loss=0.3947, Acc=0.8052 | LR=0.000100
2025-06-03 01:33:50,793 - INFO - Epoch 009 | Train Loss=0.4869, Acc=0.7870 | Val Loss=0.3768, Acc=0.8169 | LR=0.000100
2025-06-03 01:33:55,636 - INFO - Epoch 010 | Train Loss=0.4481, Acc=0.8153 | Val Loss=0.3488, Acc=0.8498 | LR=0.000100
2025-06-03 01:34:00,290 - INFO - Epoch 011 | Train Loss=0.4241, Acc=0.8263 | Val Loss=0.3485, Acc=0.8451 | LR=0.000100
2025-06-03 01:34:05,013 - INFO - Epoch 012 | Train Loss=0.3963, Acc=0.8440 | Val Loss=0.3211, Acc=0.8709 | LR=0.000100
2025-06-03 01:34:09,725 - INFO - Epoch 013 | Train Loss=0.3745, Acc=0.8538 | Val Loss=0.2849, Acc=0.9014 | LR=0.000100
2025-06-03 01:34:14,655 - INFO - Epoch 014 | Train Loss=0.3450, Acc=0.8829 | Val Loss=0.2922, Acc=0.8920 | LR=0.000100
2025-06-03 01:34:19,470 - INFO - Epoch 015 | Train Loss=0.3208, Acc=0.8910 | Val Loss=0.2819, Acc=0.8944 | LR=0.000100
2025-06-03 01:34:24,198 - INFO - Epoch 016 | Train Loss=0.2961, Acc=0.9091 | Val Loss=0.2750, Acc=0.8897 | LR=0.000100
2025-06-03 01:34:28,772 - INFO - Epoch 017 | Train Loss=0.2781, Acc=0.9159 | Val Loss=0.2533, Acc=0.8920 | LR=0.000100
2025-06-03 01:34:33,742 - INFO - Epoch 018 | Train Loss=0.2617, Acc=0.9218 | Val Loss=0.2390, Acc=0.8991 | LR=0.000100
2025-06-03 01:34:38,648 - INFO - Epoch 019 | Train Loss=0.2395, Acc=0.9362 | Val Loss=0.2445, Acc=0.8991 | LR=0.000100
2025-06-03 01:34:43,336 - INFO - Epoch 020 | Train Loss=0.2304, Acc=0.9370 | Val Loss=0.2195, Acc=0.9108 | LR=0.000100
2025-06-03 01:34:48,112 - INFO - Epoch 021 | Train Loss=0.2154, Acc=0.9417 | Val Loss=0.3090, Acc=0.8568 | LR=0.000100
2025-06-03 01:34:52,854 - INFO - Epoch 022 | Train Loss=0.2032, Acc=0.9467 | Val Loss=0.2402, Acc=0.9014 | LR=0.000100
2025-06-03 01:34:57,593 - INFO - Epoch 023 | Train Loss=0.1863, Acc=0.9548 | Val Loss=0.2081, Acc=0.9272 | LR=0.000100
2025-06-03 01:35:02,578 - INFO - Epoch 024 | Train Loss=0.1789, Acc=0.9577 | Val Loss=0.2207, Acc=0.9178 | LR=0.000100
2025-06-03 01:35:07,234 - INFO - Epoch 025 | Train Loss=0.1726, Acc=0.9598 | Val Loss=0.2122, Acc=0.9249 | LR=0.000100
2025-06-03 01:35:11,917 - INFO - Epoch 026 | Train Loss=0.1609, Acc=0.9624 | Val Loss=0.1838, Acc=0.9390 | LR=0.000100
2025-06-03 01:35:16,501 - INFO - Epoch 027 | Train Loss=0.1535, Acc=0.9658 | Val Loss=0.2746, Acc=0.9014 | LR=0.000100
2025-06-03 01:35:21,337 - INFO - Epoch 028 | Train Loss=0.1429, Acc=0.9700 | Val Loss=0.1951, Acc=0.9296 | LR=0.000100
2025-06-03 01:35:26,335 - INFO - Epoch 029 | Train Loss=0.1356, Acc=0.9725 | Val Loss=0.2362, Acc=0.9178 | LR=0.000100
2025-06-03 01:35:32,369 - INFO - Epoch 030 | Train Loss=0.1278, Acc=0.9734 | Val Loss=0.2251, Acc=0.9249 | LR=0.000050
2025-06-03 01:35:38,712 - INFO - Epoch 031 | Train Loss=0.1264, Acc=0.9725 | Val Loss=0.2147, Acc=0.9319 | LR=0.000050
2025-06-03 01:35:43,722 - INFO - Epoch 032 | Train Loss=0.1240, Acc=0.9755 | Val Loss=0.2019, Acc=0.9296 | LR=0.000050
2025-06-03 01:35:48,361 - INFO - Epoch 033 | Train Loss=0.1233, Acc=0.9768 | Val Loss=0.1968, Acc=0.9319 | LR=0.000050
2025-06-03 01:35:53,016 - INFO - Epoch 034 | Train Loss=0.1143, Acc=0.9776 | Val Loss=0.2198, Acc=0.9296 | LR=0.000025
2025-06-03 01:35:57,850 - INFO - Epoch 035 | Train Loss=0.1145, Acc=0.9763 | Val Loss=0.2141, Acc=0.9296 | LR=0.000025
2025-06-03 01:36:02,516 - INFO - Epoch 036 | Train Loss=0.1148, Acc=0.9780 | Val Loss=0.2198, Acc=0.9296 | LR=0.000025
2025-06-03 01:36:07,353 - INFO - Epoch 037 | Train Loss=0.1096, Acc=0.9784 | Val Loss=0.2043, Acc=0.9272 | LR=0.000025
2025-06-03 01:36:11,861 - INFO - Epoch 038 | Train Loss=0.1097, Acc=0.9780 | Val Loss=0.2023, Acc=0.9272 | LR=0.000013
2025-06-03 01:36:16,454 - INFO - Epoch 039 | Train Loss=0.1060, Acc=0.9822 | Val Loss=0.2110, Acc=0.9296 | LR=0.000013
2025-06-03 01:36:20,898 - INFO - Epoch 040 | Train Loss=0.1110, Acc=0.9784 | Val Loss=0.2169, Acc=0.9296 | LR=0.000013
2025-06-03 01:36:25,428 - INFO - Epoch 041 | Train Loss=0.1109, Acc=0.9793 | Val Loss=0.2087, Acc=0.9272 | LR=0.000013
2025-06-03 01:36:30,009 - INFO - Epoch 042 | Train Loss=0.1068, Acc=0.9784 | Val Loss=0.2129, Acc=0.9296 | LR=0.000006
2025-06-03 01:36:34,739 - INFO - Epoch 043 | Train Loss=0.1091, Acc=0.9755 | Val Loss=0.2065, Acc=0.9272 | LR=0.000006
2025-06-03 01:36:39,434 - INFO - Epoch 044 | Train Loss=0.1101, Acc=0.9763 | Val Loss=0.2128, Acc=0.9272 | LR=0.000006
2025-06-03 01:36:43,933 - INFO - Epoch 045 | Train Loss=0.1078, Acc=0.9780 | Val Loss=0.2121, Acc=0.9272 | LR=0.000006
2025-06-03 01:36:48,543 - INFO - Epoch 046 | Train Loss=0.1048, Acc=0.9806 | Val Loss=0.2116, Acc=0.9272 | LR=0.000003
2025-06-03 01:36:48,543 - INFO - Early stopping triggered at epoch 46
2025-06-03 01:36:48,544 - INFO - === Fine-tuning selesai ===
2025-06-03 01:37:00,692 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-03 01:37:14,944 - INFO - Validation MSE: 7.912059
2025-06-03 01:37:14,944 - INFO - Total training time: 320.40s
2025-06-03 01:37:14,944 - INFO - Validation MCC: 0.5085, AUC: 0.8816
2025-06-03 01:37:14,946 - INFO - Test       MCC: 0.3633, AUC: 0.8452
2025-06-03 01:41:34,502 - INFO - Training DBN...
2025-06-03 01:41:35,243 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-03 01:41:35,244 - INFO - --> Pre-training RBM layer 1/3
2025-06-03 01:41:35,938 - INFO -   - RBM1 Epoch   0: ReconLoss=1.482942
2025-06-03 01:41:37,560 - INFO -   - RBM1 Epoch  10: ReconLoss=1.039865
2025-06-03 01:41:39,576 - INFO -   - RBM1 Epoch  20: ReconLoss=1.011568
2025-06-03 01:41:41,551 - INFO -   - RBM1 Epoch  30: ReconLoss=1.029435
2025-06-03 01:41:43,605 - INFO -   - RBM1 Epoch  40: ReconLoss=1.019238
2025-06-03 01:41:45,250 - INFO -   - RBM1 Epoch  50: ReconLoss=1.025208
2025-06-03 01:41:47,751 - INFO -   - RBM1 Epoch  60: ReconLoss=1.045226
2025-06-03 01:41:49,936 - INFO -   - RBM1 Epoch  70: ReconLoss=1.032245
2025-06-03 01:41:51,942 - INFO -   - RBM1 Epoch  80: ReconLoss=1.026097
2025-06-03 01:41:53,675 - INFO -   - RBM1 Epoch  90: ReconLoss=1.023151
2025-06-03 01:41:56,184 - INFO - --> Pre-training RBM layer 2/3
2025-06-03 01:41:56,322 - INFO -   - RBM2 Epoch   0: ReconLoss=0.435244
2025-06-03 01:41:57,480 - INFO -   - RBM2 Epoch  10: ReconLoss=0.411298
2025-06-03 01:41:59,116 - INFO -   - RBM2 Epoch  20: ReconLoss=0.401639
2025-06-03 01:42:00,674 - INFO -   - RBM2 Epoch  30: ReconLoss=0.396471
2025-06-03 01:42:01,965 - INFO -   - RBM2 Epoch  40: ReconLoss=0.390151
2025-06-03 01:42:03,196 - INFO -   - RBM2 Epoch  50: ReconLoss=0.387165
2025-06-03 01:42:04,230 - INFO -   - RBM2 Epoch  60: ReconLoss=0.384945
2025-06-03 01:42:05,665 - INFO -   - RBM2 Epoch  70: ReconLoss=0.381826
2025-06-03 01:42:06,773 - INFO -   - RBM2 Epoch  80: ReconLoss=0.378262
2025-06-03 01:42:08,068 - INFO -   - RBM2 Epoch  90: ReconLoss=0.374967
2025-06-03 01:42:09,144 - INFO - --> Pre-training RBM layer 3/3
2025-06-03 01:42:09,254 - INFO -   - RBM3 Epoch   0: ReconLoss=0.409078
2025-06-03 01:42:10,219 - INFO -   - RBM3 Epoch  10: ReconLoss=0.229580
2025-06-03 01:42:10,884 - INFO -   - RBM3 Epoch  20: ReconLoss=0.177810
2025-06-03 01:42:11,795 - INFO -   - RBM3 Epoch  30: ReconLoss=0.167208
2025-06-03 01:42:12,684 - INFO -   - RBM3 Epoch  40: ReconLoss=0.162923
2025-06-03 01:42:13,423 - INFO -   - RBM3 Epoch  50: ReconLoss=0.157991
2025-06-03 01:42:14,105 - INFO -   - RBM3 Epoch  60: ReconLoss=0.157255
2025-06-03 01:42:14,795 - INFO -   - RBM3 Epoch  70: ReconLoss=0.154963
2025-06-03 01:42:15,536 - INFO -   - RBM3 Epoch  80: ReconLoss=0.154442
2025-06-03 01:42:16,507 - INFO -   - RBM3 Epoch  90: ReconLoss=0.152261
2025-06-03 01:42:17,398 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-03 01:42:46,929 - INFO - Epoch 000 | Train Loss=0.7144, Acc=0.5156 | Val Loss=0.6130, Acc=0.9272 | LR=0.000100
2025-06-03 01:42:51,500 - INFO - Epoch 001 | Train Loss=0.6931, Acc=0.5490 | Val Loss=0.6035, Acc=0.9272 | LR=0.000100
2025-06-03 01:42:57,066 - INFO - Epoch 002 | Train Loss=0.6807, Acc=0.5680 | Val Loss=0.5957, Acc=0.9272 | LR=0.000100
2025-06-03 01:43:02,279 - INFO - Epoch 003 | Train Loss=0.6613, Acc=0.6019 | Val Loss=0.5555, Acc=0.9272 | LR=0.000100
2025-06-03 01:43:07,644 - INFO - Epoch 004 | Train Loss=0.6414, Acc=0.6310 | Val Loss=0.5096, Acc=0.8991 | LR=0.000100
2025-06-03 01:43:12,688 - INFO - Epoch 005 | Train Loss=0.6092, Acc=0.6665 | Val Loss=0.4761, Acc=0.7653 | LR=0.000100
2025-06-03 01:43:17,830 - INFO - Epoch 006 | Train Loss=0.5741, Acc=0.7067 | Val Loss=0.4415, Acc=0.7230 | LR=0.000100
2025-06-03 01:43:23,324 - INFO - Epoch 007 | Train Loss=0.5442, Acc=0.7426 | Val Loss=0.4010, Acc=0.7441 | LR=0.000100
2025-06-03 01:43:28,235 - INFO - Epoch 008 | Train Loss=0.5071, Acc=0.7815 | Val Loss=0.3801, Acc=0.7653 | LR=0.000100
2025-06-03 01:43:33,311 - INFO - Epoch 009 | Train Loss=0.4770, Acc=0.7954 | Val Loss=0.3635, Acc=0.7934 | LR=0.000100
2025-06-03 01:43:38,614 - INFO - Epoch 010 | Train Loss=0.4525, Acc=0.8085 | Val Loss=0.3628, Acc=0.7981 | LR=0.000100
2025-06-03 01:43:44,511 - INFO - Epoch 011 | Train Loss=0.4224, Acc=0.8390 | Val Loss=0.3749, Acc=0.7958 | LR=0.000100
2025-06-03 01:43:49,766 - INFO - Epoch 012 | Train Loss=0.3954, Acc=0.8453 | Val Loss=0.3366, Acc=0.8310 | LR=0.000100
2025-06-03 01:43:55,115 - INFO - Epoch 013 | Train Loss=0.3684, Acc=0.8588 | Val Loss=0.3099, Acc=0.8545 | LR=0.000100
2025-06-03 01:44:00,581 - INFO - Epoch 014 | Train Loss=0.3396, Acc=0.8795 | Val Loss=0.3114, Acc=0.8615 | LR=0.000100
2025-06-03 01:44:06,363 - INFO - Epoch 015 | Train Loss=0.3189, Acc=0.8948 | Val Loss=0.2762, Acc=0.8850 | LR=0.000100
2025-06-03 01:44:11,356 - INFO - Epoch 016 | Train Loss=0.2886, Acc=0.9142 | Val Loss=0.2865, Acc=0.8779 | LR=0.000100
2025-06-03 01:44:16,274 - INFO - Epoch 017 | Train Loss=0.2718, Acc=0.9214 | Val Loss=0.2870, Acc=0.8756 | LR=0.000100
2025-06-03 01:44:21,238 - INFO - Epoch 018 | Train Loss=0.2534, Acc=0.9260 | Val Loss=0.2446, Acc=0.9014 | LR=0.000100
2025-06-03 01:44:26,184 - INFO - Epoch 019 | Train Loss=0.2366, Acc=0.9311 | Val Loss=0.2918, Acc=0.8732 | LR=0.000100
2025-06-03 01:44:30,993 - INFO - Epoch 020 | Train Loss=0.2230, Acc=0.9358 | Val Loss=0.2129, Acc=0.9131 | LR=0.000100
2025-06-03 01:44:35,614 - INFO - Epoch 021 | Train Loss=0.2055, Acc=0.9446 | Val Loss=0.2568, Acc=0.8944 | LR=0.000100
2025-06-03 01:44:40,467 - INFO - Epoch 022 | Train Loss=0.2008, Acc=0.9484 | Val Loss=0.2282, Acc=0.9108 | LR=0.000100
2025-06-03 01:44:45,345 - INFO - Epoch 023 | Train Loss=0.1826, Acc=0.9489 | Val Loss=0.1904, Acc=0.9319 | LR=0.000100
2025-06-03 01:44:50,155 - INFO - Epoch 024 | Train Loss=0.1724, Acc=0.9607 | Val Loss=0.2577, Acc=0.8991 | LR=0.000100
2025-06-03 01:44:55,442 - INFO - Epoch 025 | Train Loss=0.1604, Acc=0.9632 | Val Loss=0.1943, Acc=0.9272 | LR=0.000100
2025-06-03 01:45:01,440 - INFO - Epoch 026 | Train Loss=0.1489, Acc=0.9675 | Val Loss=0.1962, Acc=0.9272 | LR=0.000100
2025-06-03 01:45:07,215 - INFO - Epoch 027 | Train Loss=0.1449, Acc=0.9700 | Val Loss=0.2498, Acc=0.9061 | LR=0.000050
2025-06-03 01:45:12,736 - INFO - Epoch 028 | Train Loss=0.1400, Acc=0.9704 | Val Loss=0.2152, Acc=0.9202 | LR=0.000050
2025-06-03 01:45:18,085 - INFO - Epoch 029 | Train Loss=0.1350, Acc=0.9725 | Val Loss=0.2079, Acc=0.9178 | LR=0.000050
2025-06-03 01:45:22,963 - INFO - Epoch 030 | Train Loss=0.1277, Acc=0.9759 | Val Loss=0.2130, Acc=0.9178 | LR=0.000050
2025-06-03 01:45:27,863 - INFO - Epoch 031 | Train Loss=0.1332, Acc=0.9679 | Val Loss=0.1842, Acc=0.9366 | LR=0.000050
2025-06-03 01:45:32,825 - INFO - Epoch 032 | Train Loss=0.1306, Acc=0.9721 | Val Loss=0.2475, Acc=0.9108 | LR=0.000050
2025-06-03 01:45:37,637 - INFO - Epoch 033 | Train Loss=0.1193, Acc=0.9751 | Val Loss=0.1967, Acc=0.9249 | LR=0.000050
2025-06-03 01:45:42,357 - INFO - Epoch 034 | Train Loss=0.1184, Acc=0.9763 | Val Loss=0.2371, Acc=0.9061 | LR=0.000050
2025-06-03 01:45:47,147 - INFO - Epoch 035 | Train Loss=0.1178, Acc=0.9759 | Val Loss=0.2214, Acc=0.9131 | LR=0.000025
2025-06-03 01:45:51,880 - INFO - Epoch 036 | Train Loss=0.1152, Acc=0.9751 | Val Loss=0.2065, Acc=0.9225 | LR=0.000025
2025-06-03 01:45:56,419 - INFO - Epoch 037 | Train Loss=0.1104, Acc=0.9763 | Val Loss=0.2124, Acc=0.9202 | LR=0.000025
2025-06-03 01:46:01,266 - INFO - Epoch 038 | Train Loss=0.1109, Acc=0.9784 | Val Loss=0.2034, Acc=0.9225 | LR=0.000025
2025-06-03 01:46:06,632 - INFO - Epoch 039 | Train Loss=0.1112, Acc=0.9797 | Val Loss=0.2058, Acc=0.9225 | LR=0.000013
2025-06-03 01:46:12,105 - INFO - Epoch 040 | Train Loss=0.1117, Acc=0.9759 | Val Loss=0.2245, Acc=0.9108 | LR=0.000013
2025-06-03 01:46:16,886 - INFO - Epoch 041 | Train Loss=0.1103, Acc=0.9763 | Val Loss=0.2089, Acc=0.9202 | LR=0.000013
2025-06-03 01:46:21,631 - INFO - Epoch 042 | Train Loss=0.1087, Acc=0.9784 | Val Loss=0.2096, Acc=0.9225 | LR=0.000013
2025-06-03 01:46:26,365 - INFO - Epoch 043 | Train Loss=0.1102, Acc=0.9776 | Val Loss=0.2061, Acc=0.9225 | LR=0.000006
2025-06-03 01:46:31,127 - INFO - Epoch 044 | Train Loss=0.1147, Acc=0.9772 | Val Loss=0.2165, Acc=0.9178 | LR=0.000006
2025-06-03 01:46:35,598 - INFO - Epoch 045 | Train Loss=0.1115, Acc=0.9772 | Val Loss=0.2158, Acc=0.9178 | LR=0.000006
2025-06-03 01:46:40,409 - INFO - Epoch 046 | Train Loss=0.1074, Acc=0.9780 | Val Loss=0.2100, Acc=0.9225 | LR=0.000006
2025-06-03 01:46:45,124 - INFO - Epoch 047 | Train Loss=0.1116, Acc=0.9776 | Val Loss=0.2074, Acc=0.9225 | LR=0.000003
2025-06-03 01:46:49,600 - INFO - Epoch 048 | Train Loss=0.1077, Acc=0.9780 | Val Loss=0.2045, Acc=0.9249 | LR=0.000003
2025-06-03 01:46:54,076 - INFO - Epoch 049 | Train Loss=0.1084, Acc=0.9772 | Val Loss=0.2117, Acc=0.9202 | LR=0.000003
2025-06-03 01:46:58,653 - INFO - Epoch 050 | Train Loss=0.1083, Acc=0.9784 | Val Loss=0.2181, Acc=0.9155 | LR=0.000003
2025-06-03 01:47:03,375 - INFO - Epoch 051 | Train Loss=0.1026, Acc=0.9797 | Val Loss=0.2100, Acc=0.9225 | LR=0.000002
2025-06-03 01:47:03,376 - INFO - Early stopping triggered at epoch 51
2025-06-03 01:47:03,376 - INFO - === Fine-tuning selesai ===
2025-06-03 01:47:19,079 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-03 01:47:35,177 - INFO - Validation MSE: 9.297414
2025-06-03 01:47:35,179 - INFO - Total training time: 360.68s
2025-06-03 01:47:35,180 - INFO - Validation MCC: 0.4997, AUC: 0.8893
2025-06-03 01:47:35,181 - INFO - Test       MCC: 0.3390, AUC: 0.8331
2025-06-03 11:33:14,027 - INFO - Training DBN...
2025-06-03 11:33:14,939 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-03 11:33:14,939 - INFO - --> Pre-training RBM layer 1/3
2025-06-03 11:33:15,637 - INFO -   - RBM1 Epoch   0: ReconLoss=1.476246
2025-06-03 11:33:18,193 - INFO -   - RBM1 Epoch  10: ReconLoss=1.041024
2025-06-03 11:33:22,245 - INFO -   - RBM1 Epoch  20: ReconLoss=1.018485
2025-06-03 11:33:27,541 - INFO -   - RBM1 Epoch  30: ReconLoss=1.031649
2025-06-03 11:33:29,782 - INFO -   - RBM1 Epoch  40: ReconLoss=1.022287
2025-06-03 11:33:31,820 - INFO -   - RBM1 Epoch  50: ReconLoss=1.027065
2025-06-03 11:33:33,846 - INFO -   - RBM1 Epoch  60: ReconLoss=1.022408
2025-06-03 11:33:37,106 - INFO -   - RBM1 Epoch  70: ReconLoss=1.043357
2025-06-03 11:33:40,064 - INFO -   - RBM1 Epoch  80: ReconLoss=1.042179
2025-06-03 11:33:43,097 - INFO -   - RBM1 Epoch  90: ReconLoss=1.038551
2025-06-03 11:33:46,828 - INFO - --> Pre-training RBM layer 2/3
2025-06-03 11:33:47,336 - INFO -   - RBM2 Epoch   0: ReconLoss=0.439359
2025-06-03 11:33:49,470 - INFO -   - RBM2 Epoch  10: ReconLoss=0.410095
2025-06-03 11:33:53,694 - INFO -   - RBM2 Epoch  20: ReconLoss=0.398413
2025-06-03 11:33:58,065 - INFO -   - RBM2 Epoch  30: ReconLoss=0.393393
2025-06-03 11:34:00,716 - INFO -   - RBM2 Epoch  40: ReconLoss=0.388993
2025-06-03 11:34:03,515 - INFO -   - RBM2 Epoch  50: ReconLoss=0.385467
2025-06-03 11:34:06,342 - INFO -   - RBM2 Epoch  60: ReconLoss=0.381824
2025-06-03 11:34:14,627 - INFO -   - RBM2 Epoch  70: ReconLoss=0.380569
2025-06-03 11:34:20,046 - INFO -   - RBM2 Epoch  80: ReconLoss=0.378327
2025-06-03 11:34:23,207 - INFO -   - RBM2 Epoch  90: ReconLoss=0.374072
2025-06-03 11:34:26,915 - INFO - --> Pre-training RBM layer 3/3
2025-06-03 11:34:27,143 - INFO -   - RBM3 Epoch   0: ReconLoss=0.404182
2025-06-03 11:34:29,649 - INFO -   - RBM3 Epoch  10: ReconLoss=0.223983
2025-06-03 11:34:31,617 - INFO -   - RBM3 Epoch  20: ReconLoss=0.172824
2025-06-03 11:34:33,594 - INFO -   - RBM3 Epoch  30: ReconLoss=0.162087
2025-06-03 11:34:35,152 - INFO -   - RBM3 Epoch  40: ReconLoss=0.155411
2025-06-03 11:34:37,446 - INFO -   - RBM3 Epoch  50: ReconLoss=0.153289
2025-06-03 11:34:41,224 - INFO -   - RBM3 Epoch  60: ReconLoss=0.151360
2025-06-03 11:34:44,184 - INFO -   - RBM3 Epoch  70: ReconLoss=0.148481
2025-06-03 11:34:46,237 - INFO -   - RBM3 Epoch  80: ReconLoss=0.147403
2025-06-03 11:34:48,035 - INFO -   - RBM3 Epoch  90: ReconLoss=0.144747
2025-06-03 11:34:49,343 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-03 11:35:59,228 - INFO - Epoch 000 | Train Loss=0.7066, Acc=0.5139 | Val Loss=0.7045, Acc=0.0728 | LR=0.000100
2025-06-03 11:36:37,910 - INFO - Epoch 001 | Train Loss=0.6831, Acc=0.5533 | Val Loss=0.7012, Acc=0.0728 | LR=0.000100
2025-06-03 11:36:45,948 - INFO - Epoch 002 | Train Loss=0.6718, Acc=0.5731 | Val Loss=0.6760, Acc=0.0751 | LR=0.000100
2025-06-03 11:36:52,714 - INFO - Epoch 003 | Train Loss=0.6579, Acc=0.5959 | Val Loss=0.6284, Acc=0.2981 | LR=0.000100
2025-06-03 11:37:00,620 - INFO - Epoch 004 | Train Loss=0.6358, Acc=0.6302 | Val Loss=0.5725, Acc=0.3732 | LR=0.000100
2025-06-03 11:37:11,156 - INFO - Epoch 005 | Train Loss=0.6172, Acc=0.6407 | Val Loss=0.5220, Acc=0.4742 | LR=0.000100
2025-06-03 11:37:22,067 - INFO - Epoch 006 | Train Loss=0.5889, Acc=0.6699 | Val Loss=0.4750, Acc=0.5610 | LR=0.000100
2025-06-03 11:38:13,628 - INFO - Epoch 007 | Train Loss=0.5538, Acc=0.7063 | Val Loss=0.4340, Acc=0.6221 | LR=0.000100
2025-06-03 11:38:48,780 - INFO - Epoch 008 | Train Loss=0.5204, Acc=0.7350 | Val Loss=0.4036, Acc=0.6596 | LR=0.000100
2025-06-03 11:39:24,535 - INFO - Epoch 009 | Train Loss=0.4953, Acc=0.7460 | Val Loss=0.4018, Acc=0.6737 | LR=0.000100
2025-06-03 11:40:25,456 - INFO - Epoch 010 | Train Loss=0.4641, Acc=0.7853 | Val Loss=0.3914, Acc=0.6948 | LR=0.000100
2025-06-03 11:40:34,492 - INFO - Epoch 011 | Train Loss=0.4400, Acc=0.8052 | Val Loss=0.3621, Acc=0.7418 | LR=0.000100
2025-06-03 11:40:41,158 - INFO - Epoch 012 | Train Loss=0.4032, Acc=0.8246 | Val Loss=0.3613, Acc=0.7535 | LR=0.000100
2025-06-03 11:40:47,181 - INFO - Epoch 013 | Train Loss=0.3828, Acc=0.8377 | Val Loss=0.3290, Acc=0.7981 | LR=0.000100
2025-06-03 11:40:53,545 - INFO - Epoch 014 | Train Loss=0.3566, Acc=0.8584 | Val Loss=0.3428, Acc=0.7723 | LR=0.000100
2025-06-03 11:41:00,517 - INFO - Epoch 015 | Train Loss=0.3299, Acc=0.8724 | Val Loss=0.2889, Acc=0.8521 | LR=0.000100
2025-06-03 11:41:07,784 - INFO - Epoch 016 | Train Loss=0.3087, Acc=0.8833 | Val Loss=0.3081, Acc=0.8239 | LR=0.000100
2025-06-03 11:41:15,078 - INFO - Epoch 017 | Train Loss=0.2915, Acc=0.8943 | Val Loss=0.2532, Acc=0.8873 | LR=0.000100
2025-06-03 11:41:21,880 - INFO - Epoch 018 | Train Loss=0.2698, Acc=0.9104 | Val Loss=0.3148, Acc=0.8286 | LR=0.000100
2025-06-03 11:41:30,691 - INFO - Epoch 019 | Train Loss=0.2517, Acc=0.9155 | Val Loss=0.2277, Acc=0.8967 | LR=0.000100
2025-06-03 11:41:41,027 - INFO - Epoch 020 | Train Loss=0.2377, Acc=0.9252 | Val Loss=0.2808, Acc=0.8709 | LR=0.000100
2025-06-03 11:41:53,253 - INFO - Epoch 021 | Train Loss=0.2224, Acc=0.9303 | Val Loss=0.2439, Acc=0.8944 | LR=0.000100
2025-06-03 11:42:11,931 - INFO - Epoch 022 | Train Loss=0.2084, Acc=0.9379 | Val Loss=0.2143, Acc=0.9178 | LR=0.000100
2025-06-03 11:42:20,635 - INFO - Epoch 023 | Train Loss=0.1968, Acc=0.9446 | Val Loss=0.2431, Acc=0.9014 | LR=0.000100
2025-06-03 11:42:27,924 - INFO - Epoch 024 | Train Loss=0.1870, Acc=0.9484 | Val Loss=0.2025, Acc=0.9225 | LR=0.000100
2025-06-03 11:42:37,500 - INFO - Epoch 025 | Train Loss=0.1750, Acc=0.9539 | Val Loss=0.1868, Acc=0.9343 | LR=0.000100
2025-06-03 11:43:07,288 - INFO - Epoch 026 | Train Loss=0.1662, Acc=0.9611 | Val Loss=0.2482, Acc=0.9061 | LR=0.000100
2025-06-03 11:43:16,219 - INFO - Epoch 027 | Train Loss=0.1565, Acc=0.9615 | Val Loss=0.2692, Acc=0.8920 | LR=0.000100
2025-06-03 11:43:24,709 - INFO - Epoch 028 | Train Loss=0.1525, Acc=0.9620 | Val Loss=0.2289, Acc=0.9178 | LR=0.000100
2025-06-03 11:43:32,247 - INFO - Epoch 029 | Train Loss=0.1445, Acc=0.9666 | Val Loss=0.1859, Acc=0.9366 | LR=0.000100
2025-06-03 11:43:41,173 - INFO - Epoch 030 | Train Loss=0.1397, Acc=0.9700 | Val Loss=0.2107, Acc=0.9225 | LR=0.000100
2025-06-03 11:43:52,421 - INFO - Epoch 031 | Train Loss=0.1297, Acc=0.9717 | Val Loss=0.1893, Acc=0.9319 | LR=0.000100
2025-06-03 11:44:07,487 - INFO - Epoch 032 | Train Loss=0.1255, Acc=0.9734 | Val Loss=0.2431, Acc=0.9131 | LR=0.000100
2025-06-03 11:44:14,504 - INFO - Epoch 033 | Train Loss=0.1171, Acc=0.9759 | Val Loss=0.2810, Acc=0.8991 | LR=0.000050
2025-06-03 11:44:23,353 - INFO - Epoch 034 | Train Loss=0.1165, Acc=0.9734 | Val Loss=0.1939, Acc=0.9296 | LR=0.000050
2025-06-03 11:44:33,648 - INFO - Epoch 035 | Train Loss=0.1145, Acc=0.9759 | Val Loss=0.2319, Acc=0.9202 | LR=0.000050
2025-06-03 11:44:56,377 - INFO - Epoch 036 | Train Loss=0.1114, Acc=0.9755 | Val Loss=0.2021, Acc=0.9249 | LR=0.000050
2025-06-03 11:45:06,111 - INFO - Epoch 037 | Train Loss=0.1068, Acc=0.9789 | Val Loss=0.2201, Acc=0.9272 | LR=0.000025
2025-06-03 11:45:47,840 - INFO - Epoch 038 | Train Loss=0.1053, Acc=0.9784 | Val Loss=0.2155, Acc=0.9272 | LR=0.000025
2025-06-03 11:45:57,545 - INFO - Epoch 039 | Train Loss=0.1061, Acc=0.9784 | Val Loss=0.2017, Acc=0.9296 | LR=0.000025
2025-06-03 11:46:23,652 - INFO - Epoch 040 | Train Loss=0.1038, Acc=0.9780 | Val Loss=0.2239, Acc=0.9249 | LR=0.000025
2025-06-03 11:46:46,687 - INFO - Epoch 041 | Train Loss=0.1025, Acc=0.9784 | Val Loss=0.2029, Acc=0.9272 | LR=0.000013
2025-06-03 11:46:57,188 - INFO - Epoch 042 | Train Loss=0.1041, Acc=0.9780 | Val Loss=0.2046, Acc=0.9296 | LR=0.000013
2025-06-03 11:47:36,015 - INFO - Epoch 043 | Train Loss=0.1026, Acc=0.9784 | Val Loss=0.2230, Acc=0.9272 | LR=0.000013
2025-06-03 11:47:43,497 - INFO - Epoch 044 | Train Loss=0.0999, Acc=0.9784 | Val Loss=0.2283, Acc=0.9225 | LR=0.000013
2025-06-03 11:47:52,128 - INFO - Epoch 045 | Train Loss=0.0993, Acc=0.9772 | Val Loss=0.2097, Acc=0.9272 | LR=0.000006
2025-06-03 11:48:29,214 - INFO - Epoch 046 | Train Loss=0.0977, Acc=0.9784 | Val Loss=0.2060, Acc=0.9272 | LR=0.000006
2025-06-03 11:48:38,996 - INFO - Epoch 047 | Train Loss=0.0998, Acc=0.9789 | Val Loss=0.2129, Acc=0.9272 | LR=0.000006
2025-06-03 11:48:46,921 - INFO - Epoch 048 | Train Loss=0.0984, Acc=0.9806 | Val Loss=0.2216, Acc=0.9225 | LR=0.000006
2025-06-03 11:48:53,549 - INFO - Epoch 049 | Train Loss=0.0965, Acc=0.9789 | Val Loss=0.2175, Acc=0.9272 | LR=0.000003
2025-06-03 11:48:53,550 - INFO - Early stopping triggered at epoch 49
2025-06-03 11:48:53,551 - INFO - === Fine-tuning selesai ===
2025-06-03 11:51:23,116 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-03 11:51:52,402 - INFO - Validation MSE: 9.889358
2025-06-03 11:51:52,404 - INFO - Total training time: 1118.38s
2025-06-03 11:51:52,404 - INFO - Validation MCC: 0.5378, AUC: 0.8324
2025-06-03 11:51:52,405 - INFO - Test       MCC: 0.3467, AUC: 0.8165
2025-06-03 11:52:51,199 - INFO - Training CNN...
2025-06-03 11:53:24,009 - INFO - Model dan scaler tersimpan (cnn_final.pth, scalercnn.pkl)
2025-06-03 11:53:29,850 - INFO - Validation MSE: 0.052766
2025-06-03 11:53:29,850 - INFO - Total training time: 38.65s
2025-06-03 11:53:29,850 - INFO - Validation MCC: 0.5825, AUC: 0.8862
2025-06-03 11:53:29,850 - INFO - Test       MCC: 0.4299, AUC: 0.8799
2025-06-03 11:58:55,298 - INFO - Training Random Forest...
2025-06-03 11:58:55,487 - INFO - Training Random Forest...
2025-06-03 11:58:56,154 - INFO - Model dan scaler tersimpan (rf_final.pkl, scalerrf.pkl)
2025-06-03 12:01:09,325 - INFO - Training Random Forest...
2025-06-03 12:01:09,356 - INFO - Training Random Forest...
2025-06-03 12:01:10,303 - INFO - Model dan scaler tersimpan (rf_final.pkl, scalerrf.pkl)
2025-06-04 00:13:42,393 - INFO - Training DBN...
2025-06-04 00:13:43,100 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-04 00:13:43,100 - INFO - --> Pre-training RBM layer 1/3
2025-06-04 00:13:43,687 - INFO -   - RBM1 Epoch   0: ReconLoss=1.478823
2025-06-04 00:13:44,688 - INFO -   - RBM1 Epoch  10: ReconLoss=1.064931
2025-06-04 00:13:45,779 - INFO -   - RBM1 Epoch  20: ReconLoss=1.023459
2025-06-04 00:13:46,977 - INFO -   - RBM1 Epoch  30: ReconLoss=1.019033
2025-06-04 00:13:48,002 - INFO -   - RBM1 Epoch  40: ReconLoss=1.012100
2025-06-04 00:13:49,223 - INFO -   - RBM1 Epoch  50: ReconLoss=1.027540
2025-06-04 00:13:50,394 - INFO -   - RBM1 Epoch  60: ReconLoss=1.028445
2025-06-04 00:13:52,093 - INFO -   - RBM1 Epoch  70: ReconLoss=1.034796
2025-06-04 00:13:54,898 - INFO -   - RBM1 Epoch  80: ReconLoss=1.048766
2025-06-04 00:13:56,902 - INFO -   - RBM1 Epoch  90: ReconLoss=1.033866
2025-06-04 00:13:58,553 - INFO - --> Pre-training RBM layer 2/3
2025-06-04 00:13:58,670 - INFO -   - RBM2 Epoch   0: ReconLoss=0.437627
2025-06-04 00:13:59,649 - INFO -   - RBM2 Epoch  10: ReconLoss=0.413718
2025-06-04 00:14:00,789 - INFO -   - RBM2 Epoch  20: ReconLoss=0.403059
2025-06-04 00:14:02,350 - INFO -   - RBM2 Epoch  30: ReconLoss=0.394920
2025-06-04 00:14:03,945 - INFO -   - RBM2 Epoch  40: ReconLoss=0.391651
2025-06-04 00:14:05,709 - INFO -   - RBM2 Epoch  50: ReconLoss=0.388969
2025-06-04 00:14:06,880 - INFO -   - RBM2 Epoch  60: ReconLoss=0.385401
2025-06-04 00:14:08,900 - INFO -   - RBM2 Epoch  70: ReconLoss=0.382951
2025-06-04 00:14:10,564 - INFO -   - RBM2 Epoch  80: ReconLoss=0.379979
2025-06-04 00:14:11,752 - INFO -   - RBM2 Epoch  90: ReconLoss=0.378622
2025-06-04 00:14:12,764 - INFO - --> Pre-training RBM layer 3/3
2025-06-04 00:14:12,834 - INFO -   - RBM3 Epoch   0: ReconLoss=0.402834
2025-06-04 00:14:13,365 - INFO -   - RBM3 Epoch  10: ReconLoss=0.225096
2025-06-04 00:14:13,945 - INFO -   - RBM3 Epoch  20: ReconLoss=0.175047
2025-06-04 00:14:14,680 - INFO -   - RBM3 Epoch  30: ReconLoss=0.165727
2025-06-04 00:14:15,256 - INFO -   - RBM3 Epoch  40: ReconLoss=0.161085
2025-06-04 00:14:15,717 - INFO -   - RBM3 Epoch  50: ReconLoss=0.158279
2025-06-04 00:14:16,316 - INFO -   - RBM3 Epoch  60: ReconLoss=0.154368
2025-06-04 00:14:17,121 - INFO -   - RBM3 Epoch  70: ReconLoss=0.152703
2025-06-04 00:14:18,143 - INFO -   - RBM3 Epoch  80: ReconLoss=0.151235
2025-06-04 00:14:19,003 - INFO -   - RBM3 Epoch  90: ReconLoss=0.150121
2025-06-04 00:14:19,671 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-04 00:14:56,362 - INFO - Epoch 000 | Train Loss=0.6919, Acc=0.5368 | Val Loss=0.6471, Acc=0.0728 | LR=0.000100
2025-06-04 00:15:01,997 - INFO - Epoch 001 | Train Loss=0.6665, Acc=0.5816 | Val Loss=0.6161, Acc=0.2042 | LR=0.000100
2025-06-04 00:15:06,728 - INFO - Epoch 002 | Train Loss=0.6383, Acc=0.6319 | Val Loss=0.5687, Acc=0.4061 | LR=0.000100
2025-06-04 00:15:11,354 - INFO - Epoch 003 | Train Loss=0.6130, Acc=0.6424 | Val Loss=0.4880, Acc=0.5798 | LR=0.000100
2025-06-04 00:15:15,499 - INFO - Epoch 004 | Train Loss=0.5869, Acc=0.6775 | Val Loss=0.4230, Acc=0.6737 | LR=0.000100
2025-06-04 00:15:19,578 - INFO - Epoch 005 | Train Loss=0.5530, Acc=0.7168 | Val Loss=0.4007, Acc=0.6995 | LR=0.000100
2025-06-04 00:15:24,050 - INFO - Epoch 006 | Train Loss=0.5307, Acc=0.7329 | Val Loss=0.3768, Acc=0.7230 | LR=0.000100
2025-06-04 00:15:28,134 - INFO - Epoch 007 | Train Loss=0.5025, Acc=0.7523 | Val Loss=0.3465, Acc=0.7793 | LR=0.000100
2025-06-04 00:15:32,429 - INFO - Epoch 008 | Train Loss=0.4742, Acc=0.7790 | Val Loss=0.3497, Acc=0.7723 | LR=0.000100
2025-06-04 00:15:37,114 - INFO - Epoch 009 | Train Loss=0.4523, Acc=0.7967 | Val Loss=0.3503, Acc=0.7653 | LR=0.000100
2025-06-04 00:15:41,794 - INFO - Epoch 010 | Train Loss=0.4238, Acc=0.8123 | Val Loss=0.3455, Acc=0.7700 | LR=0.000100
2025-06-04 00:15:46,217 - INFO - Epoch 011 | Train Loss=0.3971, Acc=0.8373 | Val Loss=0.3160, Acc=0.8075 | LR=0.000100
2025-06-04 00:15:50,835 - INFO - Epoch 012 | Train Loss=0.3755, Acc=0.8567 | Val Loss=0.3013, Acc=0.8216 | LR=0.000100
2025-06-04 00:15:55,540 - INFO - Epoch 013 | Train Loss=0.3518, Acc=0.8711 | Val Loss=0.2605, Acc=0.8873 | LR=0.000100
2025-06-04 00:15:59,883 - INFO - Epoch 014 | Train Loss=0.3246, Acc=0.8855 | Val Loss=0.2683, Acc=0.8779 | LR=0.000100
2025-06-04 00:16:05,099 - INFO - Epoch 015 | Train Loss=0.2986, Acc=0.8952 | Val Loss=0.2403, Acc=0.8944 | LR=0.000100
2025-06-04 00:16:10,387 - INFO - Epoch 016 | Train Loss=0.2797, Acc=0.9066 | Val Loss=0.2162, Acc=0.9225 | LR=0.000100
2025-06-04 00:16:15,659 - INFO - Epoch 017 | Train Loss=0.2666, Acc=0.9163 | Val Loss=0.2142, Acc=0.9131 | LR=0.000100
2025-06-04 00:16:20,950 - INFO - Epoch 018 | Train Loss=0.2464, Acc=0.9265 | Val Loss=0.2685, Acc=0.8756 | LR=0.000100
2025-06-04 00:16:25,925 - INFO - Epoch 019 | Train Loss=0.2341, Acc=0.9336 | Val Loss=0.2439, Acc=0.8897 | LR=0.000100
2025-06-04 00:16:30,733 - INFO - Epoch 020 | Train Loss=0.2152, Acc=0.9421 | Val Loss=0.2564, Acc=0.8897 | LR=0.000100
2025-06-04 00:16:36,848 - INFO - Epoch 021 | Train Loss=0.2054, Acc=0.9438 | Val Loss=0.2038, Acc=0.9272 | LR=0.000100
2025-06-04 00:16:41,950 - INFO - Epoch 022 | Train Loss=0.1929, Acc=0.9527 | Val Loss=0.2234, Acc=0.9131 | LR=0.000100
2025-06-04 00:16:46,198 - INFO - Epoch 023 | Train Loss=0.1811, Acc=0.9548 | Val Loss=0.1916, Acc=0.9343 | LR=0.000100
2025-06-04 00:16:50,463 - INFO - Epoch 024 | Train Loss=0.1726, Acc=0.9594 | Val Loss=0.1916, Acc=0.9296 | LR=0.000100
2025-06-04 00:16:54,979 - INFO - Epoch 025 | Train Loss=0.1609, Acc=0.9637 | Val Loss=0.2279, Acc=0.9061 | LR=0.000100
2025-06-04 00:17:00,117 - INFO - Epoch 026 | Train Loss=0.1551, Acc=0.9641 | Val Loss=0.2078, Acc=0.9178 | LR=0.000100
2025-06-04 00:17:08,141 - INFO - Epoch 027 | Train Loss=0.1486, Acc=0.9683 | Val Loss=0.2042, Acc=0.9225 | LR=0.000050
2025-06-04 00:17:14,937 - INFO - Epoch 028 | Train Loss=0.1414, Acc=0.9696 | Val Loss=0.2242, Acc=0.9108 | LR=0.000050
2025-06-04 00:17:20,884 - INFO - Epoch 029 | Train Loss=0.1345, Acc=0.9725 | Val Loss=0.2244, Acc=0.9108 | LR=0.000050
2025-06-04 00:17:27,033 - INFO - Epoch 030 | Train Loss=0.1317, Acc=0.9734 | Val Loss=0.2369, Acc=0.9061 | LR=0.000050
2025-06-04 00:17:35,810 - INFO - Epoch 031 | Train Loss=0.1326, Acc=0.9742 | Val Loss=0.1918, Acc=0.9319 | LR=0.000025
2025-06-04 00:17:42,785 - INFO - Epoch 032 | Train Loss=0.1289, Acc=0.9742 | Val Loss=0.2310, Acc=0.9061 | LR=0.000025
2025-06-04 00:17:48,706 - INFO - Epoch 033 | Train Loss=0.1258, Acc=0.9759 | Val Loss=0.2206, Acc=0.9178 | LR=0.000025
2025-06-04 00:17:54,641 - INFO - Epoch 034 | Train Loss=0.1280, Acc=0.9755 | Val Loss=0.2212, Acc=0.9202 | LR=0.000025
2025-06-04 00:18:00,111 - INFO - Epoch 035 | Train Loss=0.1200, Acc=0.9780 | Val Loss=0.2176, Acc=0.9202 | LR=0.000013
2025-06-04 00:18:05,783 - INFO - Epoch 036 | Train Loss=0.1201, Acc=0.9772 | Val Loss=0.2233, Acc=0.9178 | LR=0.000013
2025-06-04 00:18:13,509 - INFO - Epoch 037 | Train Loss=0.1222, Acc=0.9776 | Val Loss=0.2161, Acc=0.9202 | LR=0.000013
2025-06-04 00:18:21,294 - INFO - Epoch 038 | Train Loss=0.1179, Acc=0.9784 | Val Loss=0.2129, Acc=0.9225 | LR=0.000013
2025-06-04 00:18:28,809 - INFO - Epoch 039 | Train Loss=0.1170, Acc=0.9772 | Val Loss=0.2195, Acc=0.9178 | LR=0.000006
2025-06-04 00:18:33,132 - INFO - Epoch 040 | Train Loss=0.1175, Acc=0.9784 | Val Loss=0.2170, Acc=0.9178 | LR=0.000006
2025-06-04 00:18:37,567 - INFO - Epoch 041 | Train Loss=0.1200, Acc=0.9759 | Val Loss=0.2290, Acc=0.9131 | LR=0.000006
2025-06-04 00:18:42,747 - INFO - Epoch 042 | Train Loss=0.1178, Acc=0.9776 | Val Loss=0.2173, Acc=0.9178 | LR=0.000006
2025-06-04 00:18:47,967 - INFO - Epoch 043 | Train Loss=0.1167, Acc=0.9772 | Val Loss=0.2167, Acc=0.9178 | LR=0.000003
2025-06-04 00:18:47,968 - INFO - Early stopping triggered at epoch 43
2025-06-04 00:18:47,968 - INFO - === Fine-tuning selesai ===
2025-06-04 00:19:00,011 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-04 02:21:52,378 - INFO - Training DBN...
2025-06-04 02:21:53,212 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-04 02:21:53,213 - INFO - --> Pre-training RBM layer 1/3
2025-06-04 02:21:53,950 - INFO -   - RBM1 Epoch   0: ReconLoss=1.470848
2025-06-04 02:21:56,351 - INFO -   - RBM1 Epoch  10: ReconLoss=1.042478
2025-06-04 02:22:00,741 - INFO -   - RBM1 Epoch  20: ReconLoss=1.017117
2025-06-04 02:22:03,854 - INFO -   - RBM1 Epoch  30: ReconLoss=1.020322
2025-06-04 02:22:05,917 - INFO -   - RBM1 Epoch  40: ReconLoss=1.018982
2025-06-04 02:22:08,683 - INFO -   - RBM1 Epoch  50: ReconLoss=1.032591
2025-06-04 02:22:10,711 - INFO -   - RBM1 Epoch  60: ReconLoss=1.031296
2025-06-04 02:22:13,318 - INFO -   - RBM1 Epoch  70: ReconLoss=1.045755
2025-06-04 02:22:16,676 - INFO -   - RBM1 Epoch  80: ReconLoss=1.049939
2025-06-04 02:22:20,901 - INFO -   - RBM1 Epoch  90: ReconLoss=1.043212
2025-06-04 02:22:26,517 - INFO - --> Pre-training RBM layer 2/3
2025-06-04 02:22:27,188 - INFO -   - RBM2 Epoch   0: ReconLoss=0.438234
2025-06-04 02:22:32,078 - INFO -   - RBM2 Epoch  10: ReconLoss=0.413179
2025-06-04 02:22:33,815 - INFO -   - RBM2 Epoch  20: ReconLoss=0.402381
2025-06-04 02:22:36,225 - INFO -   - RBM2 Epoch  30: ReconLoss=0.394172
2025-06-04 02:22:38,956 - INFO -   - RBM2 Epoch  40: ReconLoss=0.389510
2025-06-04 02:22:41,582 - INFO -   - RBM2 Epoch  50: ReconLoss=0.387232
2025-06-04 02:22:43,335 - INFO -   - RBM2 Epoch  60: ReconLoss=0.385209
2025-06-04 02:22:45,720 - INFO -   - RBM2 Epoch  70: ReconLoss=0.381647
2025-06-04 02:22:49,186 - INFO -   - RBM2 Epoch  80: ReconLoss=0.378388
2025-06-04 02:22:53,401 - INFO -   - RBM2 Epoch  90: ReconLoss=0.377295
2025-06-04 02:23:18,884 - INFO - --> Pre-training RBM layer 3/3
2025-06-04 02:23:19,931 - INFO -   - RBM3 Epoch   0: ReconLoss=0.399901
2025-06-04 02:23:24,412 - INFO -   - RBM3 Epoch  10: ReconLoss=0.218749
2025-06-04 02:23:28,351 - INFO -   - RBM3 Epoch  20: ReconLoss=0.172271
2025-06-04 02:23:31,212 - INFO -   - RBM3 Epoch  30: ReconLoss=0.162447
2025-06-04 02:23:33,245 - INFO -   - RBM3 Epoch  40: ReconLoss=0.157063
2025-06-04 02:23:34,482 - INFO -   - RBM3 Epoch  50: ReconLoss=0.153582
2025-06-04 02:23:35,888 - INFO -   - RBM3 Epoch  60: ReconLoss=0.153333
2025-06-04 02:23:37,865 - INFO -   - RBM3 Epoch  70: ReconLoss=0.152448
2025-06-04 02:23:40,451 - INFO -   - RBM3 Epoch  80: ReconLoss=0.150275
2025-06-04 02:23:42,091 - INFO -   - RBM3 Epoch  90: ReconLoss=0.148480
2025-06-04 02:23:44,295 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-04 02:24:39,637 - INFO - Epoch 000 | Train Loss=0.7209, Acc=0.5199 | Val Loss=0.7501, Acc=0.0728 | LR=0.000100
2025-06-04 02:24:46,821 - INFO - Epoch 001 | Train Loss=0.6834, Acc=0.5495 | Val Loss=0.7287, Acc=0.0728 | LR=0.000100
2025-06-04 02:24:55,739 - INFO - Epoch 002 | Train Loss=0.6606, Acc=0.5592 | Val Loss=0.6791, Acc=0.1784 | LR=0.000100
2025-06-04 02:25:22,161 - INFO - Epoch 003 | Train Loss=0.6308, Acc=0.5858 | Val Loss=0.5931, Acc=0.3850 | LR=0.000100
2025-06-04 02:25:41,292 - INFO - Epoch 004 | Train Loss=0.5912, Acc=0.6382 | Val Loss=0.5178, Acc=0.5094 | LR=0.000100
2025-06-04 02:26:02,443 - INFO - Epoch 005 | Train Loss=0.5629, Acc=0.6762 | Val Loss=0.4650, Acc=0.6103 | LR=0.000100
2025-06-04 02:26:13,985 - INFO - Epoch 006 | Train Loss=0.5276, Acc=0.7079 | Val Loss=0.4242, Acc=0.6667 | LR=0.000100
2025-06-04 02:26:23,170 - INFO - Epoch 007 | Train Loss=0.5105, Acc=0.7316 | Val Loss=0.4180, Acc=0.6643 | LR=0.000100
2025-06-04 02:26:37,234 - INFO - Epoch 008 | Train Loss=0.4815, Acc=0.7549 | Val Loss=0.3972, Acc=0.6901 | LR=0.000100
2025-06-04 02:26:53,225 - INFO - Epoch 009 | Train Loss=0.4528, Acc=0.7802 | Val Loss=0.3966, Acc=0.6972 | LR=0.000100
2025-06-04 02:27:05,909 - INFO - Epoch 010 | Train Loss=0.4266, Acc=0.7988 | Val Loss=0.3798, Acc=0.7207 | LR=0.000100
2025-06-04 02:27:14,177 - INFO - Epoch 011 | Train Loss=0.3956, Acc=0.8225 | Val Loss=0.3435, Acc=0.7770 | LR=0.000100
2025-06-04 02:27:23,139 - INFO - Epoch 012 | Train Loss=0.3768, Acc=0.8436 | Val Loss=0.3478, Acc=0.7793 | LR=0.000100
2025-06-04 02:28:00,252 - INFO - Epoch 013 | Train Loss=0.3507, Acc=0.8533 | Val Loss=0.3052, Acc=0.8263 | LR=0.000100
2025-06-04 02:28:14,042 - INFO - Epoch 014 | Train Loss=0.3288, Acc=0.8698 | Val Loss=0.3001, Acc=0.8333 | LR=0.000100
2025-06-04 02:28:53,822 - INFO - Epoch 015 | Train Loss=0.2977, Acc=0.8910 | Val Loss=0.2485, Acc=0.8803 | LR=0.000100
2025-06-04 02:29:01,546 - INFO - Epoch 016 | Train Loss=0.2796, Acc=0.8986 | Val Loss=0.2378, Acc=0.8944 | LR=0.000100
2025-06-04 02:29:11,665 - INFO - Epoch 017 | Train Loss=0.2622, Acc=0.9104 | Val Loss=0.2644, Acc=0.8756 | LR=0.000100
2025-06-04 02:29:21,287 - INFO - Epoch 018 | Train Loss=0.2408, Acc=0.9205 | Val Loss=0.2324, Acc=0.8920 | LR=0.000100
2025-06-04 02:29:35,354 - INFO - Epoch 019 | Train Loss=0.2284, Acc=0.9290 | Val Loss=0.2181, Acc=0.9085 | LR=0.000100
2025-06-04 02:29:49,561 - INFO - Epoch 020 | Train Loss=0.2150, Acc=0.9311 | Val Loss=0.2299, Acc=0.8967 | LR=0.000100
2025-06-04 02:29:56,198 - INFO - Epoch 021 | Train Loss=0.1965, Acc=0.9429 | Val Loss=0.2435, Acc=0.8967 | LR=0.000100
2025-06-04 02:30:08,938 - INFO - Epoch 022 | Train Loss=0.1931, Acc=0.9446 | Val Loss=0.2527, Acc=0.8991 | LR=0.000100
2025-06-04 02:30:36,017 - INFO - Epoch 023 | Train Loss=0.1804, Acc=0.9497 | Val Loss=0.2183, Acc=0.9131 | LR=0.000050
2025-06-04 02:30:42,773 - INFO - Epoch 024 | Train Loss=0.1698, Acc=0.9539 | Val Loss=0.2491, Acc=0.9038 | LR=0.000050
2025-06-04 02:30:48,939 - INFO - Epoch 025 | Train Loss=0.1619, Acc=0.9577 | Val Loss=0.2145, Acc=0.9131 | LR=0.000050
2025-06-04 02:31:26,272 - INFO - Epoch 026 | Train Loss=0.1610, Acc=0.9594 | Val Loss=0.2275, Acc=0.9108 | LR=0.000050
2025-06-04 02:31:37,990 - INFO - Epoch 027 | Train Loss=0.1525, Acc=0.9607 | Val Loss=0.2103, Acc=0.9178 | LR=0.000050
2025-06-04 02:31:45,554 - INFO - Epoch 028 | Train Loss=0.1527, Acc=0.9637 | Val Loss=0.2056, Acc=0.9178 | LR=0.000050
2025-06-04 02:31:58,155 - INFO - Epoch 029 | Train Loss=0.1473, Acc=0.9675 | Val Loss=0.2245, Acc=0.9108 | LR=0.000050
2025-06-04 02:32:28,775 - INFO - Epoch 030 | Train Loss=0.1456, Acc=0.9649 | Val Loss=0.2237, Acc=0.9155 | LR=0.000050
2025-06-04 02:33:16,818 - INFO - Epoch 031 | Train Loss=0.1362, Acc=0.9683 | Val Loss=0.2432, Acc=0.9061 | LR=0.000050
2025-06-04 02:33:29,888 - INFO - Epoch 032 | Train Loss=0.1362, Acc=0.9649 | Val Loss=0.1907, Acc=0.9319 | LR=0.000050
2025-06-04 02:33:39,812 - INFO - Epoch 033 | Train Loss=0.1336, Acc=0.9687 | Val Loss=0.2515, Acc=0.9038 | LR=0.000050
2025-06-04 02:33:49,659 - INFO - Epoch 034 | Train Loss=0.1296, Acc=0.9683 | Val Loss=0.1927, Acc=0.9343 | LR=0.000050
2025-06-04 02:34:21,165 - INFO - Epoch 035 | Train Loss=0.1298, Acc=0.9725 | Val Loss=0.2604, Acc=0.8991 | LR=0.000050
2025-06-04 02:34:28,372 - INFO - Epoch 036 | Train Loss=0.1222, Acc=0.9704 | Val Loss=0.1933, Acc=0.9343 | LR=0.000025
2025-06-04 02:34:34,606 - INFO - Epoch 037 | Train Loss=0.1208, Acc=0.9730 | Val Loss=0.2354, Acc=0.9108 | LR=0.000025
2025-06-04 02:34:40,816 - INFO - Epoch 038 | Train Loss=0.1206, Acc=0.9738 | Val Loss=0.2222, Acc=0.9178 | LR=0.000025
2025-06-04 02:34:46,960 - INFO - Epoch 039 | Train Loss=0.1155, Acc=0.9742 | Val Loss=0.2193, Acc=0.9155 | LR=0.000025
2025-06-04 02:34:53,466 - INFO - Epoch 040 | Train Loss=0.1165, Acc=0.9742 | Val Loss=0.2180, Acc=0.9155 | LR=0.000013
2025-06-04 02:35:00,346 - INFO - Epoch 041 | Train Loss=0.1151, Acc=0.9742 | Val Loss=0.2152, Acc=0.9202 | LR=0.000013
2025-06-04 02:35:08,162 - INFO - Epoch 042 | Train Loss=0.1152, Acc=0.9759 | Val Loss=0.2292, Acc=0.9155 | LR=0.000013
2025-06-04 02:35:15,239 - INFO - Epoch 043 | Train Loss=0.1174, Acc=0.9734 | Val Loss=0.2259, Acc=0.9178 | LR=0.000013
2025-06-04 02:35:21,833 - INFO - Epoch 044 | Train Loss=0.1116, Acc=0.9776 | Val Loss=0.2143, Acc=0.9225 | LR=0.000006
2025-06-04 02:35:29,303 - INFO - Epoch 045 | Train Loss=0.1151, Acc=0.9751 | Val Loss=0.2173, Acc=0.9202 | LR=0.000006
2025-06-04 02:35:36,384 - INFO - Epoch 046 | Train Loss=0.1133, Acc=0.9751 | Val Loss=0.2203, Acc=0.9155 | LR=0.000006
2025-06-04 02:35:46,059 - INFO - Epoch 047 | Train Loss=0.1104, Acc=0.9738 | Val Loss=0.2257, Acc=0.9155 | LR=0.000006
2025-06-04 02:35:55,968 - INFO - Epoch 048 | Train Loss=0.1139, Acc=0.9717 | Val Loss=0.2222, Acc=0.9178 | LR=0.000003
2025-06-04 02:36:05,156 - INFO - Epoch 049 | Train Loss=0.1107, Acc=0.9759 | Val Loss=0.2190, Acc=0.9202 | LR=0.000003
2025-06-04 02:36:13,014 - INFO - Epoch 050 | Train Loss=0.1091, Acc=0.9742 | Val Loss=0.2186, Acc=0.9202 | LR=0.000003
2025-06-04 02:36:20,512 - INFO - Epoch 051 | Train Loss=0.1114, Acc=0.9742 | Val Loss=0.2258, Acc=0.9155 | LR=0.000003
2025-06-04 02:36:31,983 - INFO - Epoch 052 | Train Loss=0.1126, Acc=0.9725 | Val Loss=0.2211, Acc=0.9178 | LR=0.000002
2025-06-04 02:36:31,986 - INFO - Early stopping triggered at epoch 52
2025-06-04 02:36:31,987 - INFO - === Fine-tuning selesai ===
2025-06-04 02:36:45,273 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-04 03:01:20,573 - INFO - Training DBN...
2025-06-04 03:01:21,265 - INFO - === Starting DBN pre-training (layer-wise RBM) ===
2025-06-04 03:01:21,266 - INFO - --> Pre-training RBM layer 1/3
2025-06-04 03:01:22,049 - INFO -   - RBM1 Epoch   0: ReconLoss=1.484060
2025-06-04 03:01:25,291 - INFO -   - RBM1 Epoch  10: ReconLoss=1.041827
2025-06-04 03:01:27,842 - INFO -   - RBM1 Epoch  20: ReconLoss=1.015246
2025-06-04 03:01:30,499 - INFO -   - RBM1 Epoch  30: ReconLoss=1.003146
2025-06-04 03:01:32,725 - INFO -   - RBM1 Epoch  40: ReconLoss=1.025612
2025-06-04 03:01:35,857 - INFO -   - RBM1 Epoch  50: ReconLoss=1.028179
2025-06-04 03:01:42,168 - INFO -   - RBM1 Epoch  60: ReconLoss=1.031087
2025-06-04 03:01:46,254 - INFO -   - RBM1 Epoch  70: ReconLoss=1.020998
2025-06-04 03:01:50,102 - INFO -   - RBM1 Epoch  80: ReconLoss=1.035314
2025-06-04 03:01:53,902 - INFO -   - RBM1 Epoch  90: ReconLoss=1.041565
2025-06-04 03:01:57,434 - INFO - --> Pre-training RBM layer 2/3
2025-06-04 03:01:57,622 - INFO -   - RBM2 Epoch   0: ReconLoss=0.438286
2025-06-04 03:01:59,794 - INFO -   - RBM2 Epoch  10: ReconLoss=0.409829
2025-06-04 03:02:03,232 - INFO -   - RBM2 Epoch  20: ReconLoss=0.400935
2025-06-04 03:02:06,407 - INFO -   - RBM2 Epoch  30: ReconLoss=0.393631
2025-06-04 03:02:12,368 - INFO -   - RBM2 Epoch  40: ReconLoss=0.388855
2025-06-04 03:02:18,918 - INFO -   - RBM2 Epoch  50: ReconLoss=0.386956
2025-06-04 03:02:22,628 - INFO -   - RBM2 Epoch  60: ReconLoss=0.382587
2025-06-04 03:02:30,458 - INFO -   - RBM2 Epoch  70: ReconLoss=0.381733
2025-06-04 03:03:10,493 - INFO -   - RBM2 Epoch  80: ReconLoss=0.377211
2025-06-04 03:03:18,878 - INFO -   - RBM2 Epoch  90: ReconLoss=0.374285
2025-06-04 03:04:01,914 - INFO - --> Pre-training RBM layer 3/3
2025-06-04 03:04:02,528 - INFO -   - RBM3 Epoch   0: ReconLoss=0.417240
2025-06-04 03:04:04,293 - INFO -   - RBM3 Epoch  10: ReconLoss=0.227369
2025-06-04 03:04:06,161 - INFO -   - RBM3 Epoch  20: ReconLoss=0.170126
2025-06-04 03:04:08,411 - INFO -   - RBM3 Epoch  30: ReconLoss=0.155503
2025-06-04 03:04:10,458 - INFO -   - RBM3 Epoch  40: ReconLoss=0.149805
2025-06-04 03:04:12,290 - INFO -   - RBM3 Epoch  50: ReconLoss=0.146968
2025-06-04 03:04:15,012 - INFO -   - RBM3 Epoch  60: ReconLoss=0.143517
2025-06-04 03:04:19,567 - INFO -   - RBM3 Epoch  70: ReconLoss=0.141510
2025-06-04 03:04:32,173 - INFO -   - RBM3 Epoch  80: ReconLoss=0.140152
2025-06-04 03:04:51,788 - INFO -   - RBM3 Epoch  90: ReconLoss=0.138125
2025-06-04 03:04:54,098 - INFO - === Starting DBN fine-tuning (supervised) ===
2025-06-04 03:05:28,436 - INFO - Epoch 000 | Train Loss=0.6956, Acc=0.5148 | Val Loss=0.6952, Acc=0.0728 | LR=0.000100
2025-06-04 03:05:41,155 - INFO - Epoch 001 | Train Loss=0.6753, Acc=0.5385 | Val Loss=0.6911, Acc=0.0728 | LR=0.000100
2025-06-04 03:06:05,228 - INFO - Epoch 002 | Train Loss=0.6613, Acc=0.5731 | Val Loss=0.6479, Acc=0.2887 | LR=0.000100
2025-06-04 03:06:15,321 - INFO - Epoch 003 | Train Loss=0.6372, Acc=0.5972 | Val Loss=0.5904, Acc=0.3873 | LR=0.000100
2025-06-04 03:06:28,380 - INFO - Epoch 004 | Train Loss=0.6120, Acc=0.6306 | Val Loss=0.5140, Acc=0.5023 | LR=0.000100
2025-06-04 03:06:55,176 - INFO - Epoch 005 | Train Loss=0.5823, Acc=0.6619 | Val Loss=0.4359, Acc=0.6408 | LR=0.000100
2025-06-04 03:07:02,353 - INFO - Epoch 006 | Train Loss=0.5501, Acc=0.6978 | Val Loss=0.3978, Acc=0.6901 | LR=0.000100
2025-06-04 03:07:13,251 - INFO - Epoch 007 | Train Loss=0.5190, Acc=0.7274 | Val Loss=0.3768, Acc=0.7230 | LR=0.000100
2025-06-04 03:07:36,079 - INFO - Epoch 008 | Train Loss=0.4837, Acc=0.7604 | Val Loss=0.3704, Acc=0.7394 | LR=0.000100
2025-06-04 03:07:50,990 - INFO - Epoch 009 | Train Loss=0.4574, Acc=0.7777 | Val Loss=0.3620, Acc=0.7465 | LR=0.000100
2025-06-04 03:07:57,642 - INFO - Epoch 010 | Train Loss=0.4276, Acc=0.8022 | Val Loss=0.3477, Acc=0.7770 | LR=0.000100
2025-06-04 03:08:06,369 - INFO - Epoch 011 | Train Loss=0.3995, Acc=0.8280 | Val Loss=0.3243, Acc=0.8052 | LR=0.000100
2025-06-04 03:08:19,091 - INFO - Epoch 012 | Train Loss=0.3727, Acc=0.8445 | Val Loss=0.3090, Acc=0.8310 | LR=0.000100
2025-06-04 03:08:45,720 - INFO - Epoch 013 | Train Loss=0.3456, Acc=0.8652 | Val Loss=0.2736, Acc=0.8638 | LR=0.000100
2025-06-04 03:08:55,198 - INFO - Epoch 014 | Train Loss=0.3211, Acc=0.8795 | Val Loss=0.2767, Acc=0.8615 | LR=0.000100
2025-06-04 03:09:10,200 - INFO - Epoch 015 | Train Loss=0.2974, Acc=0.8914 | Val Loss=0.2322, Acc=0.9014 | LR=0.000100
2025-06-04 03:09:39,126 - INFO - Epoch 016 | Train Loss=0.2745, Acc=0.9057 | Val Loss=0.2397, Acc=0.8944 | LR=0.000100
2025-06-04 03:09:46,166 - INFO - Epoch 017 | Train Loss=0.2501, Acc=0.9159 | Val Loss=0.2192, Acc=0.9085 | LR=0.000100
2025-06-04 03:09:56,883 - INFO - Epoch 018 | Train Loss=0.2350, Acc=0.9277 | Val Loss=0.2188, Acc=0.9061 | LR=0.000100
2025-06-04 03:10:33,452 - INFO - Epoch 019 | Train Loss=0.2209, Acc=0.9294 | Val Loss=0.2449, Acc=0.8944 | LR=0.000100
2025-06-04 03:10:41,569 - INFO - Epoch 020 | Train Loss=0.2039, Acc=0.9383 | Val Loss=0.1960, Acc=0.9202 | LR=0.000100
2025-06-04 03:11:20,295 - INFO - Epoch 021 | Train Loss=0.1952, Acc=0.9429 | Val Loss=0.1895, Acc=0.9296 | LR=0.000100
2025-06-04 03:11:30,091 - INFO - Epoch 022 | Train Loss=0.1842, Acc=0.9493 | Val Loss=0.1854, Acc=0.9343 | LR=0.000100
2025-06-04 03:11:40,107 - INFO - Epoch 023 | Train Loss=0.1812, Acc=0.9531 | Val Loss=0.2398, Acc=0.8991 | LR=0.000100
2025-06-04 03:12:22,019 - INFO - Epoch 024 | Train Loss=0.1613, Acc=0.9594 | Val Loss=0.2422, Acc=0.9014 | LR=0.000100
2025-06-04 03:12:35,449 - INFO - Epoch 025 | Train Loss=0.1573, Acc=0.9577 | Val Loss=0.1778, Acc=0.9366 | LR=0.000100
2025-06-04 03:13:17,855 - INFO - Epoch 026 | Train Loss=0.1436, Acc=0.9653 | Val Loss=0.2209, Acc=0.9108 | LR=0.000100
2025-06-04 03:13:26,352 - INFO - Epoch 027 | Train Loss=0.1428, Acc=0.9649 | Val Loss=0.2094, Acc=0.9178 | LR=0.000100
2025-06-04 03:13:57,275 - INFO - Epoch 028 | Train Loss=0.1307, Acc=0.9675 | Val Loss=0.1759, Acc=0.9390 | LR=0.000100
2025-06-04 03:14:13,277 - INFO - Epoch 029 | Train Loss=0.1312, Acc=0.9713 | Val Loss=0.2211, Acc=0.9131 | LR=0.000100
2025-06-04 03:14:21,185 - INFO - Epoch 030 | Train Loss=0.1176, Acc=0.9717 | Val Loss=0.2238, Acc=0.9131 | LR=0.000100
2025-06-04 03:14:33,597 - INFO - Epoch 031 | Train Loss=0.1169, Acc=0.9755 | Val Loss=0.2488, Acc=0.9038 | LR=0.000100
2025-06-04 03:14:58,165 - INFO - Epoch 032 | Train Loss=0.1134, Acc=0.9738 | Val Loss=0.1975, Acc=0.9272 | LR=0.000050
2025-06-04 03:15:09,390 - INFO - Epoch 033 | Train Loss=0.1056, Acc=0.9755 | Val Loss=0.1910, Acc=0.9296 | LR=0.000050
2025-06-04 03:15:45,442 - INFO - Epoch 034 | Train Loss=0.1033, Acc=0.9768 | Val Loss=0.1847, Acc=0.9343 | LR=0.000050
2025-06-04 03:15:54,914 - INFO - Epoch 035 | Train Loss=0.0996, Acc=0.9784 | Val Loss=0.1859, Acc=0.9343 | LR=0.000050
2025-06-04 03:16:02,701 - INFO - Epoch 036 | Train Loss=0.1032, Acc=0.9763 | Val Loss=0.1728, Acc=0.9413 | LR=0.000050
2025-06-04 03:16:14,545 - INFO - Epoch 037 | Train Loss=0.1007, Acc=0.9793 | Val Loss=0.2161, Acc=0.9225 | LR=0.000050
2025-06-04 03:16:45,540 - INFO - Epoch 038 | Train Loss=0.1010, Acc=0.9780 | Val Loss=0.1771, Acc=0.9413 | LR=0.000050
2025-06-04 03:16:54,573 - INFO - Epoch 039 | Train Loss=0.0948, Acc=0.9780 | Val Loss=0.1840, Acc=0.9366 | LR=0.000050
2025-06-04 03:17:08,528 - INFO - Epoch 040 | Train Loss=0.0917, Acc=0.9831 | Val Loss=0.2174, Acc=0.9272 | LR=0.000025
2025-06-04 03:17:32,341 - INFO - Epoch 041 | Train Loss=0.0929, Acc=0.9789 | Val Loss=0.1904, Acc=0.9343 | LR=0.000025
2025-06-04 03:17:40,159 - INFO - Epoch 042 | Train Loss=0.0887, Acc=0.9810 | Val Loss=0.1929, Acc=0.9319 | LR=0.000025
2025-06-04 03:17:46,904 - INFO - Epoch 043 | Train Loss=0.0902, Acc=0.9810 | Val Loss=0.2044, Acc=0.9319 | LR=0.000025
2025-06-04 03:17:56,388 - INFO - Epoch 044 | Train Loss=0.0886, Acc=0.9806 | Val Loss=0.1846, Acc=0.9366 | LR=0.000013
2025-06-04 03:18:12,234 - INFO - Epoch 045 | Train Loss=0.0872, Acc=0.9810 | Val Loss=0.2017, Acc=0.9319 | LR=0.000013
2025-06-04 03:18:30,580 - INFO - Epoch 046 | Train Loss=0.0883, Acc=0.9818 | Val Loss=0.2017, Acc=0.9319 | LR=0.000013
2025-06-04 03:18:39,125 - INFO - Epoch 047 | Train Loss=0.0864, Acc=0.9827 | Val Loss=0.1901, Acc=0.9366 | LR=0.000013
2025-06-04 03:18:47,712 - INFO - Epoch 048 | Train Loss=0.0878, Acc=0.9806 | Val Loss=0.1987, Acc=0.9343 | LR=0.000006
2025-06-04 03:18:55,249 - INFO - Epoch 049 | Train Loss=0.0903, Acc=0.9818 | Val Loss=0.1965, Acc=0.9366 | LR=0.000006
2025-06-04 03:19:05,543 - INFO - Epoch 050 | Train Loss=0.0890, Acc=0.9801 | Val Loss=0.2041, Acc=0.9343 | LR=0.000006
2025-06-04 03:19:29,480 - INFO - Epoch 051 | Train Loss=0.0838, Acc=0.9818 | Val Loss=0.1974, Acc=0.9366 | LR=0.000006
2025-06-04 03:19:35,849 - INFO - Epoch 052 | Train Loss=0.0852, Acc=0.9822 | Val Loss=0.1980, Acc=0.9343 | LR=0.000003
2025-06-04 03:19:41,958 - INFO - Epoch 053 | Train Loss=0.0828, Acc=0.9818 | Val Loss=0.1994, Acc=0.9343 | LR=0.000003
2025-06-04 03:19:47,672 - INFO - Epoch 054 | Train Loss=0.0843, Acc=0.9835 | Val Loss=0.1996, Acc=0.9319 | LR=0.000003
2025-06-04 03:19:53,739 - INFO - Epoch 055 | Train Loss=0.0853, Acc=0.9844 | Val Loss=0.1981, Acc=0.9366 | LR=0.000003
2025-06-04 03:19:59,663 - INFO - Epoch 056 | Train Loss=0.0849, Acc=0.9822 | Val Loss=0.1993, Acc=0.9343 | LR=0.000002
2025-06-04 03:19:59,663 - INFO - Early stopping triggered at epoch 56
2025-06-04 03:19:59,665 - INFO - === Fine-tuning selesai ===
2025-06-04 03:20:08,955 - INFO - Model dan scaler tersimpan (dbn_final.pth, scaler.pkl)
2025-06-04 03:20:18,634 - INFO - Validation MSE: 9.624244
2025-06-04 03:20:18,634 - INFO - Total training time: 1138.06s
2025-06-04 03:20:18,635 - INFO - Validation MCC: 0.5373, AUC: 0.8709
2025-06-04 03:20:18,636 - INFO - Test       MCC: 0.3722, AUC: 0.8307
